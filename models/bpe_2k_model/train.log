2025-05-26 18:45:37,821 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_model
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                     cfg.data.train : data/my_lang_pair_bpe_2000/train
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                       cfg.data.dev : data/my_lang_pair_bpe_2000/dev
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                      cfg.data.test : data/my_lang_pair_bpe_2000/test
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe_2000/joint_vocab.txt
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 2000
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenization : None
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/bpe_2000/bpe.codes
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe_2000/joint_vocab.txt
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenization : None
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/bpe_2000/bpe.codes
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-26 18:45:37,821 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -            cfg.training.batch_size : 32
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -            cfg.training.batch_type : sentence
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_model
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-26 18:45:37,822 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-26 18:45:37,824 - INFO - joeynmt.data - Building tokenizer...
2025-05-26 18:45:37,827 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-26 18:45:37,827 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-26 18:45:37,827 - INFO - joeynmt.data - Loading train set...
2025-05-26 18:45:37,923 - INFO - joeynmt.data - Building vocabulary...
2025-05-26 18:45:37,949 - INFO - joeynmt.data - Loading dev set...
2025-05-26 18:45:37,951 - INFO - joeynmt.data - Loading test set...
2025-05-26 18:45:37,953 - INFO - joeynmt.data - Data loaded.
2025-05-26 18:45:37,953 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-26 18:45:37,953 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-26 18:45:37,953 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-26 18:45:37,954 - INFO - joeynmt.data - First training example:
	[SRC] A@@ @@@ @ l G@@ @@@ @ or@@ @@@ @ e over het af@@ @@@ @ wen@@ @@@ @ den van de kl@@ @@@ @ im@@ @@@ @ aat@@ @@@ @ c@@ @@@ @ ris@@ @@@ @ is
	[TRG] A@@ @@@ @ l G@@ @@@ @ or@@ @@@ @ e : Die Ab@@ @@@ @ wen@@ @@@ @ dung der K@@ @@@ @ li@@ @@@ @ ma@@ @@@ @ k@@ @@@ @ at@@ @@@ @ ast@@ @@@ @ rop@@ @@@ @ he
2025-05-26 18:45:37,954 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4)  (5) ! (6) « (7) » (8) # (9) $
2025-05-26 18:45:37,954 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4)  (5) ! (6) « (7) » (8) # (9) $
2025-05-26 18:45:37,954 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 1997
2025-05-26 18:45:37,954 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 1997
2025-05-26 18:45:37,954 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-26 18:45:37,985 - INFO - joeynmt.model - Enc-dec model built.
2025-05-26 18:45:37,986 - INFO - joeynmt.model - Total params: 3410432
2025-05-26 18:45:37,987 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-26 18:45:37,987 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1997),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1997),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-26 18:45:37,987 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-26 18:45:37,987 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-26 18:45:37,987 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 32
	effective batch size (w. parallel & accumulation): 32
2025-05-26 18:45:37,987 - INFO - joeynmt.training - EPOCH 1
2025-05-26 18:46:13,566 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.299191, Batch Acc: 0.422991, Tokens per Sec:     5417, Lr: 0.000300
2025-05-26 18:46:48,874 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.031366, Batch Acc: 0.494704, Tokens per Sec:     5423, Lr: 0.000300
2025-05-26 18:47:26,238 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.029731, Batch Acc: 0.507538, Tokens per Sec:     5230, Lr: 0.000300
2025-05-26 18:48:01,248 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     1.986534, Batch Acc: 0.509860, Tokens per Sec:     5472, Lr: 0.000300
2025-05-26 18:48:35,207 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.019382, Batch Acc: 0.513290, Tokens per Sec:     5618, Lr: 0.000300
2025-05-26 18:48:35,208 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 18:48:35,209 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 18:51:13,072 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.88, acc:   0.52, generation: 157.8530[sec], evaluation: 0.0000[sec]
2025-05-26 18:51:13,076 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 18:51:13,158 - INFO - joeynmt.training - Example #0
2025-05-26 18:51:13,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 18:51:13,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 18:51:13,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ich', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', 'ich', 'ich', 'ich', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', 'ich', 'es', ',', 'dass', 'ich', 'ich', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', ',', 'die', 'K@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Hypothesis: Und ich ich ich , dass ich , dass ich , dass ich , dass ich , dass ich ich ich ich ich , dass ich , dass ich , dass ich ich es , dass ich ich ich es , dass ich es , dass ich , die K<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ t .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - Example #1
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'es', ',', 'dass', 'ich', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', 'dass', 'ich', 'es', ',', '</s>']
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Hypothesis: Und ich es , dass ich , dass ich es , dass ich , dass ich es , dass ich es , dass ich es , dass ich , dass ich es , dass ich es , dass ich es , dass ich es , dass ich , dass ich , dass ich , dass ich , dass ich , dass ich es , dass ich es , dass ich es , dass ich es ,
2025-05-26 18:51:13,159 - INFO - joeynmt.training - Example #2
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'es', ',', 'dass', 'die', 'K@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Hypothesis: Und ich es , dass die K<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ f<unk> @ t .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - Example #3
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 18:51:13,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', ',', 'die', 'K@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 'f@@', '<unk>', '@', 't', ',', 'die', 'K@@', '<unk>', '@', 't', ',', 'die', 'K@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - 	Hypothesis: Und das , die K<unk> @ f<unk> @ f<unk> @ f<unk> @ t , die K<unk> @ t , die K<unk> @ t .
2025-05-26 18:51:13,159 - INFO - joeynmt.training - Example #4
2025-05-26 18:51:13,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 18:51:13,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 18:51:13,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ist', 'das', ',', 'die', 'G@@', '<unk>', '@', 't', ',', 'die', 'G@@', '<unk>', '@', 't', ',', 'die', 'wir', 'es', ',', 'dass', 'ich', 'es', ',', 'die', 'G@@', '<unk>', '@', 't', ',', 'dass', 'es', ',', 'dass', 'ich', 'es', 'ist', ',', 'dass', 'es', ',', 'dass', 'es', ',', '</s>']
2025-05-26 18:51:13,160 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 18:51:13,160 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 18:51:13,160 - INFO - joeynmt.training - 	Hypothesis: Und das ist das , die G<unk> @ t , die G<unk> @ t , die wir es , dass ich es , die G<unk> @ t , dass es , dass ich es ist , dass es , dass es ,
2025-05-26 18:51:48,935 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     1.939214, Batch Acc: 0.514972, Tokens per Sec:     5385, Lr: 0.000300
2025-05-26 18:52:24,013 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     1.905097, Batch Acc: 0.516755, Tokens per Sec:     5436, Lr: 0.000300
2025-05-26 18:53:01,757 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     1.879639, Batch Acc: 0.520793, Tokens per Sec:     5153, Lr: 0.000300
2025-05-26 18:53:36,808 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     1.878189, Batch Acc: 0.522932, Tokens per Sec:     5413, Lr: 0.000300
2025-05-26 18:54:11,900 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     1.839662, Batch Acc: 0.522941, Tokens per Sec:     5452, Lr: 0.000300
2025-05-26 18:54:11,901 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 18:54:11,901 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 18:58:21,534 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.53, acc:   0.52, generation: 249.6237[sec], evaluation: 0.0000[sec]
2025-05-26 18:58:21,537 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 18:58:21,616 - INFO - joeynmt.training - Example #0
2025-05-26 18:58:21,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 18:58:21,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 18:58:21,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', ',', 'dass', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', 'in', 'der', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 'ten', ',', 'die', 'ich', 'die', 'K@@', '<unk>', '@', 'ten', ',', 'die', 'K@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 18:58:21,616 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 18:58:21,616 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 18:58:21,616 - INFO - joeynmt.training - 	Hypothesis: Ich habe , dass ich , die ich , die ich , die ich , die ich , die ich , die ich , die ich , die ich , die ich die ich , die ich , die ich , die ich in der K<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ ten , die ich die K<unk> @ ten , die K<unk> @ ten .
2025-05-26 18:58:21,616 - INFO - joeynmt.training - Example #1
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'die', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 't', ',', 'dass', 'die', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 't', 'nicht', 'nicht', 'nicht', '.', '</s>']
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Hypothesis: Aber die K<unk> @ s<unk> @ s<unk> @ t , dass die K<unk> @ s<unk> @ s<unk> @ t nicht nicht nicht .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - Example #2
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 't@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Hypothesis: Die K<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ k<unk> @ k<unk> @ k<unk> @ t<unk> @ t<unk> @ k<unk> @ k<unk> @ k<unk> @ k<unk> @ k<unk> @ t<unk> @ ten .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - Example #3
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'war', 'die', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - 	Hypothesis: Es war die K<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ s<unk> @ ten .
2025-05-26 18:58:21,617 - INFO - joeynmt.training - Example #4
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 18:58:21,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ein', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 't', ',', 'ich', 'habe', ',', 'ich', 'ein', 'K@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 's@@', '<unk>', '@', 't', ',', '</s>']
2025-05-26 18:58:21,618 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 18:58:21,618 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 18:58:21,618 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ein K<unk> @ s<unk> @ t , ich habe , ich ein K<unk> @ s<unk> @ s<unk> @ s<unk> @ t ,
2025-05-26 18:58:57,697 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     1.826443, Batch Acc: 0.526439, Tokens per Sec:     5354, Lr: 0.000300
2025-05-26 18:59:30,545 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.820876, Batch Acc: 0.528645, Tokens per Sec:     5793, Lr: 0.000300
2025-05-26 19:00:05,677 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     1.822879, Batch Acc: 0.529242, Tokens per Sec:     5413, Lr: 0.000300
2025-05-26 19:00:38,075 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     1.832786, Batch Acc: 0.530448, Tokens per Sec:     5797, Lr: 0.000300
2025-05-26 19:01:12,294 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     1.786522, Batch Acc: 0.533052, Tokens per Sec:     5644, Lr: 0.000300
2025-05-26 19:01:12,295 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:01:12,295 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:06:21,656 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.17, acc:   0.53, generation: 309.3484[sec], evaluation: 0.0000[sec]
2025-05-26 19:06:21,660 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:06:21,739 - INFO - joeynmt.training - Example #0
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', ',', 'dass', 'ich', 'die', 'Jahren', ',', 'die', 'ich', 'in', 'den', 'Jahren', ',', 'die', 'ich', 'in', 'den', 'Jahren', ',', 'die', 'ich', 'in', 'den', 'Jahren', ',', 'die', 'ich', 'in', 'den', 'Jahren', ',', 'die', 'die', 'Menschen', 'in', 'den', 'Jahren', ',', 'die', 'wir', 'in', 'den', 'Jahren', ',', 'die', 'wir', 'in', 'den', 'Jahren', ',', 'die', 'die', 'wir', 'in', 'den', 'Jahren', ',', 'die', 'Jahren', ',', 'die', 'wir', 'in', 'den', 'Jahren', ',', 'die', 'Jahre', 'Jahre', 'Jahre', 'Jahre', 'Jahre', 'Jahre', 'Jahre', 'Jahre', 'von', 'den', 'Jahren', ',', 'die', 'wir', 'in', 'den', 'Jahren', ',', 'die', 'Jahre', 'von', 'den', 'Jahren', 'von', 'den', 'Jahren', 'von', 'den', 'Jahren', 'von', 'den', 'Jahren', ',', 'die', 'wir', 'die', 'Jahren', ',', 'die', 'Menschen', 'in', 'den', 'Jahren', '.', '</s>']
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Hypothesis: Und ich habe , dass ich die Jahren , die ich in den Jahren , die ich in den Jahren , die ich in den Jahren , die ich in den Jahren , die die Menschen in den Jahren , die wir in den Jahren , die wir in den Jahren , die die wir in den Jahren , die Jahren , die wir in den Jahren , die Jahre Jahre Jahre Jahre Jahre Jahre Jahre Jahre von den Jahren , die wir in den Jahren , die Jahre von den Jahren von den Jahren von den Jahren von den Jahren , die wir die Jahren , die Menschen in den Jahren .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - Example #1
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'K@@', '<unk>', '@', 'u@@', '<unk>', '@', 'u@@', '<unk>', '@', 't@@', '<unk>', '@', 'u@@', '<unk>', '@', 't', ',', 'dass', 'es', 'nicht', 'nicht', 'nicht', 'nicht', '.', '</s>']
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die K<unk> @ u<unk> @ u<unk> @ t<unk> @ u<unk> @ t , dass es nicht nicht nicht nicht .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - Example #2
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'P@@', '<unk>', '@', 'u@@', '<unk>', '@', 'u@@', '<unk>', '@', 't@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 't@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'ten', ',', 'die', 'wir', 'die', 'K@@', '<unk>', '@', 'u@@', '<unk>', '@', 'u@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - 	Hypothesis: Die P<unk> @ u<unk> @ u<unk> @ t<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ t<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ ten , die wir die K<unk> @ u<unk> @ u<unk> @ en<unk> @ en<unk> @ en<unk> @ ten .
2025-05-26 19:06:21,740 - INFO - joeynmt.training - Example #3
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:06:21,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'die', 'K@@', '<unk>', '@', 'u@@', '<unk>', '@', 'en@@', '<unk>', '@', 't@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'en@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 19:06:21,741 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:06:21,741 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:06:21,741 - INFO - joeynmt.training - 	Hypothesis: Es ist die K<unk> @ u<unk> @ en<unk> @ t<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ en<unk> @ ten .
2025-05-26 19:06:21,741 - INFO - joeynmt.training - Example #4
2025-05-26 19:06:21,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:06:21,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:06:21,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', '<unk>', '@', 'u@@', '<unk>', '@', 'e', 'ist', ',', 'ich', 'ein', 'K@@', '<unk>', '@', 'u@@', '<unk>', '@', 'u@@', '<unk>', '@', 'u@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 19:06:21,741 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:06:21,741 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:06:21,741 - INFO - joeynmt.training - 	Hypothesis: Die M<unk> @ u<unk> @ e ist , ich ein K<unk> @ u<unk> @ u<unk> @ u<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ t<unk> @ ten .
2025-05-26 19:06:57,513 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     1.786200, Batch Acc: 0.533593, Tokens per Sec:     5383, Lr: 0.000300
2025-05-26 19:07:34,577 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     1.748190, Batch Acc: 0.534652, Tokens per Sec:     5113, Lr: 0.000300
2025-05-26 19:08:07,407 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     1.777441, Batch Acc: 0.538391, Tokens per Sec:     5928, Lr: 0.000300
2025-05-26 19:08:41,708 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.721354, Batch Acc: 0.538612, Tokens per Sec:     5576, Lr: 0.000300
2025-05-26 19:09:15,886 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.754497, Batch Acc: 0.541289, Tokens per Sec:     5669, Lr: 0.000300
2025-05-26 19:09:15,886 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:09:15,886 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:14:26,204 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.54, generation: 310.3047[sec], evaluation: 0.0000[sec]
2025-05-26 19:14:26,207 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:14:26,292 - INFO - joeynmt.training - Example #0
2025-05-26 19:14:26,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:14:26,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:14:26,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'ich', 'mich', ',', 'dass', 'ich', 'mich', 'mich', ',', 'dass', 'ich', 'mich', ',', 'dass', 'ich', 'mich', ',', 'dass', 'ich', 'mich', ',', 'dass', 'ich', 'die', 'F@@', '<unk>', '@', 'ra@@', '<unk>', '@', 't', ',', 'dass', 'ich', 'die', 'F@@', '<unk>', '@', 'ei@@', '<unk>', '@', 't', ',', 'die', 'ich', 'in', 'den', '1@@', '<unk>', '@', '5', 'Jahren', ',', 'die', '1@@', '<unk>', '@', '5', 'Jahre', ',', 'die', '1@@', '<unk>', '@', '5', 'Jahren', ',', 'die', '1@@', '<unk>', '@', '5', 'Jahre', ',', 'die', 'ich', ',', 'dass', 'die', '1@@', '<unk>', '@', '5', 'Jahre', ',', 'die', '1@@', '<unk>', '@', '5', 'Jahre', ',', 'die', '1@@', '<unk>', '@', '5', 'Jahre', ',', '</s>']
2025-05-26 19:14:26,292 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:14:26,292 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:14:26,292 - INFO - joeynmt.training - 	Hypothesis: Und das ich mich , dass ich mich mich , dass ich mich , dass ich mich , dass ich mich , dass ich die F<unk> @ ra<unk> @ t , dass ich die F<unk> @ ei<unk> @ t , die ich in den 1<unk> @ 5 Jahren , die 1<unk> @ 5 Jahre , die 1<unk> @ 5 Jahren , die 1<unk> @ 5 Jahre , die ich , dass die 1<unk> @ 5 Jahre , die 1<unk> @ 5 Jahre , die 1<unk> @ 5 Jahre ,
2025-05-26 19:14:26,292 - INFO - joeynmt.training - Example #1
2025-05-26 19:14:26,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:14:26,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:14:26,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'F@@', '<unk>', '@', 'ei@@', '<unk>', '@', 't', ',', 'dass', 'die', 'Ver@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@', '<unk>', '@', 'zu@@']
2025-05-26 19:14:26,292 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:14:26,292 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:14:26,292 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die F<unk> @ ei<unk> @ t , dass die Ver<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ zu<unk> @ st<unk> @ zu<unk> @ zu<unk> @ zu
2025-05-26 19:14:26,292 - INFO - joeynmt.training - Example #2
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 't', ',', 'die', 'K@@', '<unk>', '@', 'u@@', '<unk>', '@', 'e', 'in', 'der', 'P@@', '<unk>', '@', 'or@@', '<unk>', '@', '-@@', '<unk>', '@', 'P@@', '<unk>', '@', 'or@@', '<unk>', '@', '-@@', '<unk>', '@', 'P@@', '<unk>', '@', 'or@@', '<unk>', '@', 's', 'ist', ',', 'in', 'der', 'wir', 'uns', 'uns', 'uns', 'uns', ',', 'in', 'der', 'wir', 'uns', 'uns', 'uns', 'uns', 'uns', 'uns', ',', '</s>']
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Hypothesis: Die F<unk> @ ü<unk> @ t , die K<unk> @ u<unk> @ e in der P<unk> @ or<unk> @ -<unk> @ P<unk> @ or<unk> @ -<unk> @ P<unk> @ or<unk> @ s ist , in der wir uns uns uns uns , in der wir uns uns uns uns uns uns ,
2025-05-26 19:14:26,293 - INFO - joeynmt.training - Example #3
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'or@@', '<unk>', '@', 'e', 'in', 'der', 'K@@', '<unk>', '@', 'or@@', '<unk>', '@', 'e', ',', 'die', 'die', 'K@@', '<unk>', '@', 'or@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Hypothesis: Es ist in der K<unk> @ or<unk> @ e in der K<unk> @ or<unk> @ e , die die K<unk> @ or<unk> @ e .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - Example #4
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:14:26,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', ',', 'die', 'ich', ',', 'die', 'ich', ',', 'die', 'ich', 'in', 'der', 'F@@', '<unk>', '@', 'ei@@', '<unk>', '@', 't', ',', 'dass', 'ich', 'das', 'eine', 'M@@', '<unk>', '@', 'ü@@', '<unk>', '@', 't', ',', 'was', 'ist', ',', 'was', 'ich', ',', 'was', 'ist', ',', 'was', 'ich', ',', 'was', 'ist', ',', 'was', 'ist', ',', 'was', 'ist', ',', 'was', 'ist', '.', '</s>']
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:14:26,293 - INFO - joeynmt.training - 	Hypothesis: Die , die ich , die ich , die ich in der F<unk> @ ei<unk> @ t , dass ich das eine M<unk> @ ü<unk> @ t , was ist , was ich , was ist , was ich , was ist , was ist , was ist , was ist .
2025-05-26 19:15:03,387 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.704037, Batch Acc: 0.544419, Tokens per Sec:     5223, Lr: 0.000300
2025-05-26 19:15:41,658 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     1.634632, Batch Acc: 0.548959, Tokens per Sec:     5086, Lr: 0.000300
2025-05-26 19:16:16,591 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.641115, Batch Acc: 0.551057, Tokens per Sec:     5514, Lr: 0.000300
2025-05-26 19:16:50,970 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.612530, Batch Acc: 0.557132, Tokens per Sec:     5627, Lr: 0.000300
2025-05-26 19:17:23,064 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.640827, Batch Acc: 0.560442, Tokens per Sec:     6008, Lr: 0.000300
2025-05-26 19:17:23,066 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:17:23,066 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:20:57,827 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.56, generation: 214.7513[sec], evaluation: 0.0000[sec]
2025-05-26 19:20:57,830 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:20:57,915 - INFO - joeynmt.training - Example #0
2025-05-26 19:20:57,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:20:57,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:20:57,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'diese', 'Jahren', ',', 'dass', 'ich', 'diese', 'zwei', 'Jahren', ',', 'dass', 'ich', 'die', 'die', 'zwei', 'Jahren', ',', 'dass', 'die', 'die', 'die', 'die', 'die', 'F@@', '<unk>', '@', 'ra@@', '<unk>', '@', 'ten', ',', 'dass', 'die', 'die', 'M@@', '<unk>', '@', 'it@@', '<unk>', '@', 's', ',', 'die', 'die', 'die', 'die', 'M@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ten', ',', 'die', 'die', 'die', 'die', '1@@', '<unk>', '@', '0', 'Jahren', ',', 'die', 'die', 'die', 'die', 'letzten', 'Jahren', ',', 'die', 'die', 'die', 'die', 'F@@', '<unk>', '@', 'ra@@', '<unk>', '@', 'ten', 'von', 'der', 'der', 'M@@', '<unk>', '@', 'it@@', '<unk>', '@', 's', 'war', ',', 'die', 'die', 'die', 'die', 'F@@', '<unk>', '@', 'ra@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Hypothesis: Und ich habe diese Jahren , dass ich diese zwei Jahren , dass ich die die zwei Jahren , dass die die die die die F<unk> @ ra<unk> @ ten , dass die die M<unk> @ it<unk> @ s , die die die die M<unk> @ ar<unk> @ ten , die die die die 1<unk> @ 0 Jahren , die die die die letzten Jahren , die die die die F<unk> @ ra<unk> @ ten von der der M<unk> @ it<unk> @ s war , die die die die F<unk> @ ra<unk> @ ten .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - Example #1
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'die', 'erste', 'erste', 'erste', 'M@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'er@@', '<unk>', '@', 'halb', 'des', 'M@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'er@@', '<unk>', '@', 's@@', '<unk>', '@', 'eit', 'ist', 'nicht', 'die', 'Problem', '.', '</s>']
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Hypothesis: Aber die erste erste erste M<unk> @ u<unk> @ ch<unk> @ er<unk> @ halb des M<unk> @ u<unk> @ ch<unk> @ er<unk> @ s<unk> @ eit ist nicht die Problem .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - Example #2
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'te', ',', 'die', 'die', 'die', 'B@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'p@@', '<unk>', '@', '-@@', '<unk>', '@', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', '-@@', '<unk>', '@', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't', 'in', 'der', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'a', 'in', 'unser@@', '<unk>', '@', 'en', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', '-@@', '<unk>', '@', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Hypothesis: Die K<unk> @ ol<unk> @ te , die die die B<unk> @ ol<unk> @ p<unk> @ -<unk> @ K<unk> @ ol<unk> @ -<unk> @ K<unk> @ ol<unk> @ t in der K<unk> @ ol<unk> @ a in unser<unk> @ en K<unk> @ ol<unk> @ -<unk> @ K<unk> @ ol<unk> @ t .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - Example #3
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:20:57,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't', 'in', 'der', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't@@', '<unk>', '@', 'a@@', '<unk>', '@', 'h@@', '<unk>', '@', 't', 'und', 'die', 'K@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - 	Hypothesis: Es ist in der K<unk> @ ol<unk> @ t in der K<unk> @ ol<unk> @ t<unk> @ a<unk> @ h<unk> @ t und die K<unk> @ ol<unk> @ t .
2025-05-26 19:20:57,916 - INFO - joeynmt.training - Example #4
2025-05-26 19:20:57,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:20:57,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:20:57,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'erste', 'erste', 'erste', 'M@@', '<unk>', '@', 'ann', 'ist', ',', 'die', 'ich', 'ein', 'paar', 'Jahren', ',', 'was', 'ich', 'das', 'ist', ',', 'was', 'ich', 'das', 'ist', ',', 'was', 'das', 'ist', ',', 'was', 'das', 'ist', '.', '</s>']
2025-05-26 19:20:57,917 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:20:57,917 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:20:57,917 - INFO - joeynmt.training - 	Hypothesis: Die erste erste erste erste M<unk> @ ann ist , die ich ein paar Jahren , was ich das ist , was ich das ist , was das ist , was das ist .
2025-05-26 19:21:30,908 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.571739, Batch Acc: 0.566282, Tokens per Sec:     5777, Lr: 0.000300
2025-05-26 19:22:04,777 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     1.549625, Batch Acc: 0.573758, Tokens per Sec:     5595, Lr: 0.000300
2025-05-26 19:22:39,585 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     1.506431, Batch Acc: 0.579837, Tokens per Sec:     5512, Lr: 0.000300
2025-05-26 19:23:13,288 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     1.480976, Batch Acc: 0.582284, Tokens per Sec:     5708, Lr: 0.000300
2025-05-26 19:23:49,095 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     1.449345, Batch Acc: 0.586394, Tokens per Sec:     5433, Lr: 0.000300
2025-05-26 19:23:49,095 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:23:49,095 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:28:37,566 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.50, acc:   0.58, generation: 288.4591[sec], evaluation: 0.0000[sec]
2025-05-26 19:28:37,569 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:28:37,655 - INFO - joeynmt.helpers - delete models/bpe_2k_model/500.ckpt
2025-05-26 19:28:37,657 - INFO - joeynmt.training - Example #0
2025-05-26 19:28:37,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:28:37,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'Jahren', 'habe', 'ich', 'diese', 'M@@', '<unk>', '@', 'it@@', '<unk>', '@', 's', 'zwei', 'Jahre', ',', 'dass', 'die', 'F@@', '<unk>', '@', 'r@@', '<unk>', '@', 'auen', ',', 'um', 'die', 'F@@', '<unk>', '@', 'r@@', '<unk>', '@', 'auen', ',', 'dass', 'die', 'F@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'en@@', '<unk>', '@', 'z@@', '<unk>', '@', 'er@@', '<unk>', '@', 'rei@@', '<unk>', '@', 'ben', ',', 'die', 'die', 'die', 'letzten', 'Millionen', 'Jahre', 'der', 'letzten', '1@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@']
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or Jahren habe ich diese M<unk> @ it<unk> @ s zwei Jahre , dass die F<unk> @ r<unk> @ auen , um die F<unk> @ r<unk> @ auen , dass die F<unk> @ lu<unk> @ ss<unk> @ en<unk> @ z<unk> @ er<unk> @ rei<unk> @ ben , die die die letzten Millionen Jahre der letzten 1<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0<unk> @ 0
2025-05-26 19:28:37,658 - INFO - joeynmt.training - Example #1
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Problem', ',', 'dass', 'die', 'K@@', '<unk>', '@', 'un@@', '<unk>', '@', 'kt', 'der', 'Er@@', '<unk>', '@', 'de', 'des', 'M@@', '<unk>', '@', 'al', ',', 'weil', 'es', 'es', 'es', 'nicht', 'die', 'Z@@', '<unk>', '@', 'eit@@', '<unk>', '@', 'ung', 'des', 'Problem', '.', '</s>']
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Problem , dass die K<unk> @ un<unk> @ kt der Er<unk> @ de des M<unk> @ al , weil es es es nicht die Z<unk> @ eit<unk> @ ung des Problem .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - Example #2
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'B@@', '<unk>', '@', 'au@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'a@@', '<unk>', '@', 'h@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'B@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'h@@', '<unk>', '@', 'l@@', '<unk>', '@', 'ö@@', '<unk>', '@', 't@@', '<unk>', '@', 'z@@', '<unk>', '@', 'lich', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'l@@', '<unk>', '@', 'än@@', '<unk>', '@', 'de', '.', '</s>']
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - 	Hypothesis: Die B<unk> @ au<unk> @ ss<unk> @ a<unk> @ h<unk> @ ol<unk> @ l ist in der B<unk> @ ü<unk> @ h<unk> @ l<unk> @ ö<unk> @ t<unk> @ z<unk> @ lich in der K<unk> @ op<unk> @ p<unk> @ l<unk> @ än<unk> @ de .
2025-05-26 19:28:37,658 - INFO - joeynmt.training - Example #3
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:28:37,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'h@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'l@@', '<unk>', '@', 'en@@', '<unk>', '@', 'z@@', '<unk>', '@', 'er@@', '<unk>', '@', 'f@@', '<unk>', '@', 'and', '.', '</s>']
2025-05-26 19:28:37,659 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:28:37,659 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:28:37,659 - INFO - joeynmt.training - 	Hypothesis: Es ist in der K<unk> @ op<unk> @ h<unk> @ ol<unk> @ l<unk> @ en<unk> @ z<unk> @ er<unk> @ f<unk> @ and .
2025-05-26 19:28:37,659 - INFO - joeynmt.training - Example #4
2025-05-26 19:28:37,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:28:37,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:28:37,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'näch@@', '<unk>', '@', 'sten', 'näch@@', '<unk>', '@', 'sten', 'M@@', '<unk>', '@', 'al', 'ist', 'ein', 'M@@', '<unk>', '@', 'ut@@', '<unk>', '@', 'ter', ',', 'was', 'ich', 'war', ',', 'was', 'ich', 'war', ',', 'was', 'ich', 'war', 'war', ',', 'was', 'ich', 'war', 'war', '.', '</s>']
2025-05-26 19:28:37,659 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:28:37,659 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:28:37,659 - INFO - joeynmt.training - 	Hypothesis: Das näch<unk> @ sten näch<unk> @ sten M<unk> @ al ist ein M<unk> @ ut<unk> @ ter , was ich war , was ich war , was ich war war , was ich war war .
2025-05-26 19:29:14,352 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.427146, Batch Acc: 0.589048, Tokens per Sec:     5269, Lr: 0.000300
2025-05-26 19:29:22,987 - INFO - joeynmt.training - Epoch   1: total training loss 5611.61
2025-05-26 19:29:22,988 - INFO - joeynmt.training - EPOCH 2
2025-05-26 19:29:49,152 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     1.445012, Batch Acc: 0.595368, Tokens per Sec:     5571, Lr: 0.000300
2025-05-26 19:30:24,652 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     1.404344, Batch Acc: 0.598935, Tokens per Sec:     5400, Lr: 0.000300
2025-05-26 19:31:00,999 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     1.355447, Batch Acc: 0.603584, Tokens per Sec:     5305, Lr: 0.000300
2025-05-26 19:31:32,862 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     1.347157, Batch Acc: 0.606989, Tokens per Sec:     6000, Lr: 0.000300
2025-05-26 19:31:32,863 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:31:32,863 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:36:04,281 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.60, generation: 271.4071[sec], evaluation: 0.0000[sec]
2025-05-26 19:36:04,283 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:36:04,368 - INFO - joeynmt.helpers - delete models/bpe_2k_model/1000.ckpt
2025-05-26 19:36:04,371 - INFO - joeynmt.training - Example #0
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'Jahren', 'habe', 'ich', 'diese', 'zwei', 'Jahren', 'zwei', 'F@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'er', ',', 'um', 'die', 'ich', 'in', 'den', 'letzten', 'zwei', 'Jahren', ',', 'dass', 'die', 'letzten', 'letzten', 'letzten', 'Jahren', ',', 'dass', 'die', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'Jahren', ',', 'die', 'die', 'die', 'drei', 'Jahren', ',', 'die', 'die', 'die', 'drei', 'Jahren', ',', 'die', 'die', 'die', 'drei', 'Jahren', ',', 'die', 'die', 'die', 'letzten', 'Jahren', ',', 'die', 'die', 'die', 'letzten', 'Jahren', ',', 'die', 'die', 'die', 'die', 'letzten', 'letzten', 'letzten', 'Jahren', 'war', ',', 'mit', 'dem', 'dem', 'dem', 'dem', '1@@', '<unk>', '@', '0', 'Prozent', 'der', 'letzten', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'letzten', '6@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', '.', '</s>']
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or Jahren habe ich diese zwei Jahren zwei F<unk> @ ot<unk> @ er , um die ich in den letzten zwei Jahren , dass die letzten letzten letzten Jahren , dass die letzten letzten letzten letzten letzten Jahren , die die die drei Jahren , die die die drei Jahren , die die die drei Jahren , die die die letzten Jahren , die die die letzten Jahren , die die die die letzten letzten letzten Jahren war , mit dem dem dem dem 1<unk> @ 0 Prozent der letzten 4<unk> @ 0 Prozent der letzten 6<unk> @ 0 Prozent der U<unk> @ S<unk> @ A .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - Example #1
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Ge@@', '<unk>', '@', 'gen@@', '<unk>', '@', 'heit', ',', 'die', 'wir', 'der', 'Er@@', '<unk>', '@', 'de', 'des', 'Ver@@', '<unk>', '@', 'bin@@', '<unk>', '@', 'dung', 'der', 'Er@@', '<unk>', '@', 'de', ',', 'weil', 'es', 'nicht', 'die', 'Er@@', '<unk>', '@', 'de', 'des', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Ver@@', '<unk>', '@', 'änder@@', '<unk>', '@', 'ung', 'des', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Er@@', '<unk>', '@', 'de', '.', '</s>']
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Ge<unk> @ gen<unk> @ heit , die wir der Er<unk> @ de des Ver<unk> @ bin<unk> @ dung der Er<unk> @ de , weil es nicht die Er<unk> @ de des Problem , weil es nicht die Ver<unk> @ änder<unk> @ ung des Problem , weil es nicht die Er<unk> @ de .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - Example #2
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', '<unk>', '@', 'ran@@', '<unk>', '@', 'k@@', '<unk>', '@', 'k@@', '<unk>', '@', 'at@@', '<unk>', '@', 'te', 'in', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', '-@@', '<unk>', '@', 'S@@', '<unk>', '@', 'on@@', '<unk>', '@', 'e', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'h@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'l', ',', 'und', 'wir', 'haben', 'in', 'uns', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'os@@', '<unk>', '@', 'iti@@', '<unk>', '@', 'on', '.', '</s>']
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - 	Hypothesis: Die K<unk> @ ran<unk> @ k<unk> @ k<unk> @ at<unk> @ te in der N<unk> @ or<unk> @ d<unk> @ -<unk> @ S<unk> @ on<unk> @ e ist in der K<unk> @ op<unk> @ p<unk> @ h<unk> @ ol<unk> @ l , und wir haben in uns in der K<unk> @ op<unk> @ p<unk> @ os<unk> @ iti<unk> @ on .
2025-05-26 19:36:04,372 - INFO - joeynmt.training - Example #3
2025-05-26 19:36:04,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:36:04,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:36:04,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'B@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'h@@', '<unk>', '@', 'le', 'in', 'der', 'B@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ft', 'und', 'der', 'L@@', '<unk>', '@', 'ie@@', '<unk>', '@', 'b@@', '<unk>', '@', 's@@', '<unk>', '@', 'atz', '.', '</s>']
2025-05-26 19:36:04,373 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:36:04,373 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:36:04,373 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem B<unk> @ ü<unk> @ h<unk> @ le in der B<unk> @ ri<unk> @ f<unk> @ ft und der L<unk> @ ie<unk> @ b<unk> @ s<unk> @ atz .
2025-05-26 19:36:04,373 - INFO - joeynmt.training - Example #4
2025-05-26 19:36:04,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:36:04,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:36:04,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'sten', 'Jahr', ',', 'die', 'ich', 'Ihnen', 'ein', 'F@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'er', ',', 'was', 'ich', 'in', 'der', 'näch@@', '<unk>', '@', 'sten', 'Jahr', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-26 19:36:04,373 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:36:04,373 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:36:04,373 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ sten Jahr , die ich Ihnen ein F<unk> @ ot<unk> @ er , was ich in der näch<unk> @ sten Jahr 2<unk> @ 5 Jahren .
2025-05-26 19:36:42,035 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     1.402154, Batch Acc: 0.608802, Tokens per Sec:     5165, Lr: 0.000300
2025-05-26 19:37:17,219 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     1.331123, Batch Acc: 0.614646, Tokens per Sec:     5520, Lr: 0.000300
2025-05-26 19:37:52,391 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     1.398227, Batch Acc: 0.617638, Tokens per Sec:     5427, Lr: 0.000300
2025-05-26 19:38:27,370 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     1.373822, Batch Acc: 0.620607, Tokens per Sec:     5522, Lr: 0.000300
2025-05-26 19:39:04,513 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     1.232476, Batch Acc: 0.625677, Tokens per Sec:     5243, Lr: 0.000300
2025-05-26 19:39:04,514 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:39:04,514 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:43:59,129 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.35, ppl:   3.87, acc:   0.62, generation: 294.6039[sec], evaluation: 0.0000[sec]
2025-05-26 19:43:59,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:43:59,222 - INFO - joeynmt.helpers - delete models/bpe_2k_model/1500.ckpt
2025-05-26 19:43:59,224 - INFO - joeynmt.training - Example #0
2025-05-26 19:43:59,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:43:59,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:43:59,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'ich', 'diese', 'zwei', 'Jahre', ',', 'die', 'wir', 'sehen', ',', 'dass', 'zwei', 'zwei', 'Jahre', 'zwei', 'Jahren', 'auf', 'der', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'iert', ',', 'die', 'die', 'die', 'drei', 'Jahren', ',', 'die', 'f@@', '<unk>', '@', 'äl@@', '<unk>', '@', 't@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'drei', 'Jahren', ',', 'die', 'die', 'die', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', '1@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', '1@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'ersten', 'Millionen', 'Jahren', 'war', ',', 'die', 'die', 'die', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'b@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', ',', 'die', 'wir', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'S@@', '<unk>', '@', 'eite', '.', '</s>']
2025-05-26 19:43:59,224 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:43:59,224 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:43:59,224 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or ich diese zwei Jahre , die wir sehen , dass zwei zwei Jahre zwei Jahren auf der P<unk> @ o<unk> @ k<unk> @ oo<unk> @ k<unk> @ ap<unk> @ iert , die die die drei Jahren , die f<unk> @ äl<unk> @ t<unk> @ gef<unk> @ äh<unk> @ r drei Jahren , die die die F<unk> @ ü<unk> @ r drei Millionen Jahren , die die die S<unk> @ A , die die 1<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , die die die 1<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , die die die ersten Millionen Jahren war , die die die F<unk> @ ü<unk> @ b<unk> @ is<unk> @ se , die wir 4<unk> @ 0 Prozent der S<unk> @ eite .
2025-05-26 19:43:59,224 - INFO - joeynmt.training - Example #1
2025-05-26 19:43:59,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:43:59,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:43:59,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', '<unk>', '@', 'de', ',', 'dass', 'die', 'Re@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ierung', 'der', 'Er@@', '<unk>', '@', 'de', ',', 'weil', 'es', 'nicht', 'die', 'Re@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ierung', 'des', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'S@@', '<unk>', '@', 'eite', 'des', 'S@@', '<unk>', '@', 'eite', '.', '</s>']
2025-05-26 19:43:59,224 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Er<unk> @ de , dass die Re<unk> @ g<unk> @ ierung der Er<unk> @ de , weil es nicht die Re<unk> @ g<unk> @ ierung des Problem , weil es nicht die S<unk> @ eite des S<unk> @ eite .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - Example #2
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', '<unk>', '@', 'eite', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'd@@', '<unk>', '@', 'een', 'ist', 'auf', 'der', 'K@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'l@@', '<unk>', '@', 'e', 'in', 'der', 'S@@', '<unk>', '@', 'eite', ',', 'das', 'uns', 'in', 'der', 'G@@', '<unk>', '@', 'ru@@', '<unk>', '@', 'pp@@', '<unk>', '@', 'e', ',', 'das', 'uns', 'von', 'G@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'men', '.', '</s>']
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Hypothesis: Die S<unk> @ eite auf der N<unk> @ or<unk> @ d<unk> @ d<unk> @ een ist auf der K<unk> @ or<unk> @ d<unk> @ l<unk> @ e in der S<unk> @ eite , das uns in der G<unk> @ ru<unk> @ pp<unk> @ e , das uns von G<unk> @ l<unk> @ im<unk> @ men .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - Example #3
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'aus', 'der', 'S@@', '<unk>', '@', 'eite', ',', 'und', 'der', 'S@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ch', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Hypothesis: Es gibt aus der S<unk> @ eite , und der S<unk> @ u<unk> @ ch in der S<unk> @ om<unk> @ e .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - Example #4
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:43:59,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', '<unk>', '@', 'ste', ',', 'die', 'ich', 'Ihnen', 'sehen', ',', 'was', 'ich', 'ein', 'Bild', ',', 'was', 'ich', 'in', 'der', 'Zeit', ',', 'was', 'die', 'S@@', '<unk>', '@', 'eite', 'der', 'Zeit', 'ist', ',', 'was', 'die', 'T@@', '<unk>', '@', 'eil@@', '<unk>', '@', 'ung', '.', '</s>']
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:43:59,225 - INFO - joeynmt.training - 	Hypothesis: Und der näch<unk> @ ste , die ich Ihnen sehen , was ich ein Bild , was ich in der Zeit , was die S<unk> @ eite der Zeit ist , was die T<unk> @ eil<unk> @ ung .
2025-05-26 19:44:34,799 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.337895, Batch Acc: 0.628761, Tokens per Sec:     5404, Lr: 0.000300
2025-05-26 19:45:10,413 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.238137, Batch Acc: 0.632319, Tokens per Sec:     5420, Lr: 0.000300
2025-05-26 19:45:44,828 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.210793, Batch Acc: 0.638567, Tokens per Sec:     5566, Lr: 0.000300
2025-05-26 19:46:20,639 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.307690, Batch Acc: 0.640660, Tokens per Sec:     5397, Lr: 0.000300
2025-05-26 19:46:58,339 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.282894, Batch Acc: 0.644527, Tokens per Sec:     5163, Lr: 0.000300
2025-05-26 19:46:58,339 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:46:58,339 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:51:44,984 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.29, ppl:   3.64, acc:   0.63, generation: 286.6330[sec], evaluation: 0.0000[sec]
2025-05-26 19:51:44,992 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:51:45,073 - INFO - joeynmt.helpers - delete models/bpe_2k_model/2000.ckpt
2025-05-26 19:51:45,074 - INFO - joeynmt.training - Example #0
2025-05-26 19:51:45,074 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:51:45,074 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:51:45,074 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'g', 'ich', 'diese', 'zwei', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ap@@', '<unk>', '@', 't@@', '<unk>', '@', 'onen', ',', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ap@@', '<unk>', '@', 't@@', '<unk>', '@', 'onen', ',', 'die', 'die', 'die', 'letzten', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'die', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'M@@', '<unk>', '@', 'al', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'von', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'M@@', '<unk>', '@', 'al', '.', '</s>']
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ g<unk> @ ri<unk> @ g ich diese zwei , die die P<unk> @ o<unk> @ k<unk> @ ap<unk> @ t<unk> @ onen , die die die P<unk> @ o<unk> @ k<unk> @ ap<unk> @ t<unk> @ onen , die die die letzten Millionen Jahren , die die die die letzten drei Millionen Jahren , die die die die F<unk> @ ü<unk> @ r drei Millionen Jahren , die die die M<unk> @ al der U<unk> @ S<unk> @ A , die von 4<unk> @ 0 Prozent der M<unk> @ al .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - Example #1
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', '<unk>', '@', 'de', ',', 'die', 'die', 'Re@@', '<unk>', '@', 'cht@@', '<unk>', '@', 'ung', 'der', 'Er@@', '<unk>', '@', 'de', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'der', 'Er@@', '<unk>', '@', 'fa@@', '<unk>', '@', 'hr@@', '<unk>', '@', 'ung', ',', 'die', 'wir', 'nicht', 'die', 'D@@', '<unk>', '@', 'ingen', '.', '</s>']
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Er<unk> @ de , die die Re<unk> @ cht<unk> @ ung der Er<unk> @ de , weil es nicht die D<unk> @ is<unk> @ se der Er<unk> @ fa<unk> @ hr<unk> @ ung , die wir nicht die D<unk> @ ingen .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - Example #2
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'een', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'rie@@', '<unk>', '@', 'd@@', '<unk>', '@', 'st@@', '<unk>', '@', 's', 'in', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'nung', ',', 'die', 'uns', 'uns', 'von', 'uns', 'G@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'k@@', '<unk>', '@', 'es', ',', '</s>']
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:51:45,075 - INFO - joeynmt.training - 	Hypothesis: Die S<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ een ist in der K<unk> @ rie<unk> @ d<unk> @ st<unk> @ s in der N<unk> @ or<unk> @ d<unk> @ nung , die uns uns von uns G<unk> @ l<unk> @ im<unk> @ mer<unk> @ k<unk> @ es ,
2025-05-26 19:51:45,075 - INFO - joeynmt.training - Example #3
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:51:45,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'geht', 'in', 'der', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'us', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 19:51:45,076 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:51:45,076 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:51:45,076 - INFO - joeynmt.training - 	Hypothesis: Es geht in der S<unk> @ in<unk> @ n und K<unk> @ ri<unk> @ m<unk> @ us in der S<unk> @ om<unk> @ er .
2025-05-26 19:51:45,076 - INFO - joeynmt.training - Example #4
2025-05-26 19:51:45,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:51:45,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:51:45,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'M@@', '<unk>', '@', 'al', ',', 'die', 'ich', 'sehen', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'bin@@', '<unk>', '@', 'dung', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ist', '.', '</s>']
2025-05-26 19:51:45,076 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:51:45,076 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:51:45,076 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste M<unk> @ al , die ich sehen , ist ein Ver<unk> @ bin<unk> @ dung der letzten 2<unk> @ 5 Jahren , was die letzten 2<unk> @ 5 Jahren ist .
2025-05-26 19:52:18,436 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.157181, Batch Acc: 0.649765, Tokens per Sec:     5659, Lr: 0.000300
2025-05-26 19:52:54,165 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.268563, Batch Acc: 0.650692, Tokens per Sec:     5455, Lr: 0.000300
2025-05-26 19:53:29,963 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.227123, Batch Acc: 0.655744, Tokens per Sec:     5318, Lr: 0.000300
2025-05-26 19:54:04,516 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.173120, Batch Acc: 0.657274, Tokens per Sec:     5496, Lr: 0.000300
2025-05-26 19:54:38,116 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.102636, Batch Acc: 0.660787, Tokens per Sec:     5616, Lr: 0.000300
2025-05-26 19:54:38,117 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 19:54:38,117 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 19:59:32,146 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.24, ppl:   3.46, acc:   0.65, generation: 294.0136[sec], evaluation: 0.0000[sec]
2025-05-26 19:59:32,149 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 19:59:32,261 - INFO - joeynmt.helpers - delete models/bpe_2k_model/2500.ckpt
2025-05-26 19:59:32,266 - INFO - joeynmt.training - Example #0
2025-05-26 19:59:32,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 19:59:32,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 19:59:32,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'Jahren', ',', 'die', 'ich', 'zwei', 'D@@', '<unk>', '@', 'ingen', ',', 'um', 'zu', 't@@', '<unk>', '@', 'onen', 'zu', 'er@@', '<unk>', '@', 'kennen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 'lin@@', '<unk>', '@', 'ik@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahre', 'lang', ',', 'war', 'es', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'T@@', '<unk>', '@', 'ei@@', '<unk>', '@', 'le', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'S', ',', 'die', 'die', 'die', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'von', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'S', 'war', '.', '</s>']
2025-05-26 19:59:32,267 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 19:59:32,267 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 19:59:32,267 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or Jahren , die ich zwei D<unk> @ ingen , um zu t<unk> @ onen zu er<unk> @ kennen , dass die P<unk> @ oo<unk> @ l<unk> @ lin<unk> @ ik<unk> @ a<unk> @ p drei Millionen Jahren , die die die letzten drei Millionen Jahren der F<unk> @ ü<unk> @ r drei Millionen Jahre lang , war es in den letzten drei Millionen Jahren , die die T<unk> @ ei<unk> @ le der U<unk> @ S<unk> @ S , die die die U<unk> @ S<unk> @ A , die die die von 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ S war .
2025-05-26 19:59:32,267 - INFO - joeynmt.training - Example #1
2025-05-26 19:59:32,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 19:59:32,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 19:59:32,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', '<unk>', '@', 'schie@@', '<unk>', '@', 'd', 'der', 'Ge@@', '<unk>', '@', 'gen@@', '<unk>', '@', 's@@', '<unk>', '@', 'atz', 'der', 'Ge@@', '<unk>', '@', 'gen@@', '<unk>', '@', 'ommen', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'en@@', '<unk>', '@', 'ken', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'en@@', '<unk>', '@', 'b@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'der', 'Er@@', '<unk>', '@', 'de', '.', '</s>']
2025-05-26 19:59:32,267 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 19:59:32,267 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 19:59:32,267 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unter<unk> @ schie<unk> @ d der Ge<unk> @ gen<unk> @ s<unk> @ atz der Ge<unk> @ gen<unk> @ ommen , weil es nicht die D<unk> @ en<unk> @ ken , weil es nicht die D<unk> @ en<unk> @ b<unk> @ is<unk> @ se der Er<unk> @ de .
2025-05-26 19:59:32,267 - INFO - joeynmt.training - Example #2
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'c@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ool', ',', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'f', 'der', 'G@@', '<unk>', '@', 'el@@', '<unk>', '@', 'b@@', '<unk>', '@', 's@@', '<unk>', '@', 'einer', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'che', '.', '</s>']
2025-05-26 19:59:32,268 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 19:59:32,268 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 19:59:32,268 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ c<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der K<unk> @ op<unk> @ p<unk> @ ool , in der K<unk> @ op<unk> @ p<unk> @ f der G<unk> @ el<unk> @ b<unk> @ s<unk> @ einer K<unk> @ li<unk> @ ma<unk> @ che .
2025-05-26 19:59:32,268 - INFO - joeynmt.training - Example #3
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'der', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 19:59:32,268 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 19:59:32,268 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 19:59:32,268 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und der S<unk> @ in<unk> @ ter und in der S<unk> @ om<unk> @ mer<unk> @ n .
2025-05-26 19:59:32,268 - INFO - joeynmt.training - Example #4
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 19:59:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', ',', 'die', 'ich', 'Ihnen', 'er@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'auen', ',', 'ist', 'ein', 'S@@', '<unk>', '@', 'el@@', '<unk>', '@', 'b@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ens', '2@@', '<unk>', '@', '5', 'Jahre', 'alt', '.', '</s>']
2025-05-26 19:59:32,269 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 19:59:32,269 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 19:59:32,269 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste , die ich Ihnen er<unk> @ sch<unk> @ auen , ist ein S<unk> @ el<unk> @ b<unk> @ st<unk> @ ens 2<unk> @ 5 Jahre alt .
2025-05-26 20:00:17,822 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.294534, Batch Acc: 0.659811, Tokens per Sec:     4269, Lr: 0.000300
2025-05-26 20:01:03,124 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.154003, Batch Acc: 0.663259, Tokens per Sec:     4291, Lr: 0.000300
2025-05-26 20:01:47,676 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.170735, Batch Acc: 0.665510, Tokens per Sec:     4277, Lr: 0.000300
2025-05-26 20:02:34,599 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.175000, Batch Acc: 0.667168, Tokens per Sec:     4138, Lr: 0.000300
2025-05-26 20:03:18,413 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     1.159345, Batch Acc: 0.673826, Tokens per Sec:     4429, Lr: 0.000300
2025-05-26 20:03:18,415 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:03:18,415 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 20:07:59,423 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.21, ppl:   3.34, acc:   0.66, generation: 280.9925[sec], evaluation: 0.0000[sec]
2025-05-26 20:07:59,427 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 20:07:59,551 - INFO - joeynmt.helpers - delete models/bpe_2k_model/3000.ckpt
2025-05-26 20:07:59,554 - INFO - joeynmt.training - Example #0
2025-05-26 20:07:59,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 20:07:59,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 20:07:59,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'meine', ',', 'ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'a', ',', 'um', 'zu', 'sehen', ',', 'dass', 'die', 'zwei', 'Di@@', '<unk>', '@', 'a', ',', 'um', 'zu', 'er@@', '<unk>', '@', 'kennen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'F@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'igkeit', 'der', 'F@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'igkeit', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', 'der', 'der', 'der', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', 'dem', 'dem', 'dem', 'dem', 'V@@', '<unk>', '@', 'ater', ',', 'als', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', 'dem', 'ich', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'war', '.', '</s>']
2025-05-26 20:07:59,554 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 20:07:59,554 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 20:07:59,554 - INFO - joeynmt.training - 	Hypothesis: Ich meine , ich habe diese zwei Di<unk> @ a , um zu sehen , dass die zwei Di<unk> @ a , um zu er<unk> @ kennen , dass die P<unk> @ o<unk> @ ss<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahren der F<unk> @ äh<unk> @ igkeit der F<unk> @ äh<unk> @ igkeit der U<unk> @ S<unk> @ A , mit der der der der U<unk> @ S<unk> @ A , mit dem dem dem dem V<unk> @ ater , als 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit dem ich mit 4<unk> @ 0 Prozent war .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - Example #1
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', '<unk>', '@', 'neh@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ung', 'der', 'An@@', '<unk>', '@', 'fan@@', '<unk>', '@', 'g', ',', 'dass', 'es', 'nicht', 'die', 'Be@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ung', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'a@@', '<unk>', '@', 'kti@@', '<unk>', '@', 'on', 'der', 'E@@', '<unk>', '@', 'is', 'ist', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'ingen', '.', '</s>']
2025-05-26 20:07:59,555 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unter<unk> @ neh<unk> @ m<unk> @ ung der An<unk> @ fan<unk> @ g , dass es nicht die Be<unk> @ g<unk> @ ung , weil es nicht die Di<unk> @ a<unk> @ kti<unk> @ on der E<unk> @ is ist , weil es nicht die D<unk> @ ingen .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - Example #2
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'c@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ool', ',', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ft', '.', '</s>']
2025-05-26 20:07:59,555 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ c<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der K<unk> @ op<unk> @ p<unk> @ ool , ist in der K<unk> @ op<unk> @ p<unk> @ ft .
2025-05-26 20:07:59,555 - INFO - joeynmt.training - Example #3
2025-05-26 20:07:59,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 20:07:59,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 20:07:59,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', ',', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 20:07:59,556 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 20:07:59,556 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 20:07:59,556 - INFO - joeynmt.training - 	Hypothesis: Es ist eine W<unk> @ in<unk> @ ter und in der S<unk> @ om<unk> @ er , in der S<unk> @ om<unk> @ er .
2025-05-26 20:07:59,556 - INFO - joeynmt.training - Example #4
2025-05-26 20:07:59,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 20:07:59,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 20:07:59,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'näch@@', '<unk>', '@', 'ste', ',', 'die', 'ich', 'sehen', 'ist', 'eine', 'ver@@', '<unk>', '@', 'wen@@', '<unk>', '@', 'den', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ist', '.', '</s>']
2025-05-26 20:07:59,556 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 20:07:59,556 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 20:07:59,556 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste näch<unk> @ ste , die ich sehen ist eine ver<unk> @ wen<unk> @ den , was die letzten 2<unk> @ 5 Jahren ist .
2025-05-26 20:08:43,463 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.213608, Batch Acc: 0.671997, Tokens per Sec:     4287, Lr: 0.000300
2025-05-26 20:09:27,495 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.101355, Batch Acc: 0.672052, Tokens per Sec:     4373, Lr: 0.000300
2025-05-26 20:10:08,833 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.121852, Batch Acc: 0.675949, Tokens per Sec:     4569, Lr: 0.000300
2025-05-26 20:10:51,864 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.189848, Batch Acc: 0.677688, Tokens per Sec:     4362, Lr: 0.000300
2025-05-26 20:11:38,410 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.160305, Batch Acc: 0.675085, Tokens per Sec:     4172, Lr: 0.000300
2025-05-26 20:11:38,411 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:11:38,411 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 20:16:59,797 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.18, ppl:   3.26, acc:   0.66, generation: 321.3706[sec], evaluation: 0.0000[sec]
2025-05-26 20:16:59,800 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 20:16:59,922 - INFO - joeynmt.helpers - delete models/bpe_2k_model/3500.ckpt
2025-05-26 20:16:59,924 - INFO - joeynmt.training - Example #0
2025-05-26 20:16:59,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 20:16:59,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 20:16:59,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahre', 'alt', 'war', 'ich', 'diese', 'Di@@', '<unk>', '@', 'as', 'Jahre', 'von', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'letzten', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'F@@', '<unk>', '@', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'h@@', '<unk>', '@', 'l@@', '<unk>', '@', 'and', '.', '</s>']
2025-05-26 20:16:59,925 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 20:16:59,925 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 20:16:59,925 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ig Jahre alt war ich diese Di<unk> @ as Jahre von 4<unk> @ 0 Prozent der letzten zwei Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ ss<unk> @ a<unk> @ p , die die letzten drei Millionen Jahren der F<unk> @ un<unk> @ gef<unk> @ äh<unk> @ r drei Millionen Jahren , die die letzten drei Millionen Jahre Jahre ge<unk> @ k<unk> @ ü<unk> @ h<unk> @ l<unk> @ and .
2025-05-26 20:16:59,925 - INFO - joeynmt.training - Example #1
2025-05-26 20:16:59,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 20:16:59,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 20:16:59,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Ge@@', '<unk>', '@', 'dan@@', '<unk>', '@', 'ken', ',', 'das', 'ist', 'das', 'Re@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'e', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'kt@@', '<unk>', '@', 'or', 'ist', ',', 'das', 'nicht', 'die', 'Di@@', '<unk>', '@', 'kt@@', '<unk>', '@', 'or', 'sehen', '.', '</s>']
2025-05-26 20:16:59,925 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 20:16:59,925 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 20:16:59,925 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Ge<unk> @ dan<unk> @ ken , das ist das Re<unk> @ ss<unk> @ o<unk> @ ur<unk> @ e Problem , weil es nicht die Di<unk> @ kt<unk> @ or ist , das nicht die Di<unk> @ kt<unk> @ or sehen .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - Example #2
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'c@@', '<unk>', '@', 'a', 'auf', 'dem', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'Se@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'e', 'in', 'Se@@', '<unk>', '@', 'ch@@', '<unk>', '@', 's', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'in', 'den', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 20:16:59,926 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ c<unk> @ a auf dem N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in Se<unk> @ ch<unk> @ e in Se<unk> @ ch<unk> @ s S<unk> @ in<unk> @ n in den S<unk> @ in<unk> @ n .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - Example #3
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', 'und', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 20:16:59,926 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - 	Hypothesis: Es ist eine S<unk> @ in<unk> @ ne und in der S<unk> @ om<unk> @ er K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ er .
2025-05-26 20:16:59,926 - INFO - joeynmt.training - Example #4
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 20:16:59,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'sehen', ',', 'ist', 'eine', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', '2@@', '<unk>', '@', '5', 'Jahren', 'ist', ',', 'was', 'es', 'in', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ist', '.', '</s>']
2025-05-26 20:16:59,927 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 20:16:59,927 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 20:16:59,927 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich sehen , ist eine S<unk> @ in<unk> @ ne 2<unk> @ 5 Jahren ist , was es in der letzten 2<unk> @ 5 Jahren ist .
2025-05-26 20:17:45,622 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.032203, Batch Acc: 0.679770, Tokens per Sec:     4223, Lr: 0.000300
2025-05-26 20:18:28,055 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.046811, Batch Acc: 0.677661, Tokens per Sec:     4536, Lr: 0.000300
2025-05-26 20:18:50,240 - INFO - joeynmt.training - Epoch   2: total training loss 3900.70
2025-05-26 20:18:50,241 - INFO - joeynmt.training - EPOCH 3
2025-05-26 20:19:12,727 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     1.100320, Batch Acc: 0.686073, Tokens per Sec:     4222, Lr: 0.000300
2025-05-26 20:19:56,217 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     1.099827, Batch Acc: 0.690809, Tokens per Sec:     4389, Lr: 0.000300
2025-05-26 20:20:41,564 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     1.069069, Batch Acc: 0.688853, Tokens per Sec:     4288, Lr: 0.000300
2025-05-26 20:20:41,565 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:20:41,565 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 20:26:12,484 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.16, ppl:   3.18, acc:   0.67, generation: 330.9006[sec], evaluation: 0.0000[sec]
2025-05-26 20:26:12,489 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 20:26:12,620 - INFO - joeynmt.helpers - delete models/bpe_2k_model/4000.ckpt
2025-05-26 20:26:12,623 - INFO - joeynmt.training - Example #0
2025-05-26 20:26:12,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 20:26:12,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 20:26:12,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'ich', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'y@@', '<unk>', '@', 's', 'zu', 'zeigen', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'von', 'den', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'ß@@', '<unk>', '@', 'er@@', '<unk>', '@', 'halb', 'der', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'ß@@', '<unk>', '@', 'er@@', '<unk>', '@', 'halb', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', ',', 'die', 'die', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'hr@@', '<unk>', '@', 'ungs@@', '<unk>', '@', 'f@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'igkeit', 'war', '.', '</s>']
2025-05-26 20:26:12,623 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or ich diese zwei Di<unk> @ as sehen , die ich zwei Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ ss<unk> @ y<unk> @ s zu zeigen , die die die letzten drei Millionen Jahren von den F<unk> @ ü<unk> @ ß<unk> @ er<unk> @ halb der F<unk> @ ü<unk> @ ß<unk> @ er<unk> @ halb der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen , die die F<unk> @ ü<unk> @ hr<unk> @ ungs<unk> @ f<unk> @ äh<unk> @ igkeit war .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - Example #1
2025-05-26 20:26:12,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 20:26:12,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 20:26:12,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Ge@@', '<unk>', '@', 'dan@@', '<unk>', '@', 'ken', ',', 'dass', 'das', 'das', 'E@@', '<unk>', '@', 'ben@@', '<unk>', '@', 'e', 'des', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ie@@', '<unk>', '@', 'cher', 'ist', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'a@@', '<unk>', '@', 'kt', 'des', 'E@@', '<unk>', '@', 'ssen', 'ist', '.', '</s>']
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Ge<unk> @ dan<unk> @ ken , dass das das E<unk> @ ben<unk> @ e des Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ ie<unk> @ cher ist , weil es nicht die Di<unk> @ a<unk> @ kt des E<unk> @ ssen ist .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - Example #2
2025-05-26 20:26:12,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 20:26:12,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 20:26:12,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'den', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'in', 'den', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'h@@', '<unk>', '@', 'n@@', '<unk>', '@', 'ä@@', '<unk>', '@', 'mlich', '.', '</s>']
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in den N<unk> @ or<unk> @ d<unk> @ po<unk> @ l in den K<unk> @ l<unk> @ op<unk> @ p<unk> @ h<unk> @ n<unk> @ ä<unk> @ mlich .
2025-05-26 20:26:12,624 - INFO - joeynmt.training - Example #3
2025-05-26 20:26:12,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 20:26:12,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 20:26:12,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'eine', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', 'und', 'in', 'den', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 20:26:12,625 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 20:26:12,625 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 20:26:12,625 - INFO - joeynmt.training - 	Hypothesis: Es ist eine S<unk> @ in<unk> @ ter und in der S<unk> @ om<unk> @ er und in den S<unk> @ om<unk> @ er .
2025-05-26 20:26:12,625 - INFO - joeynmt.training - Example #4
2025-05-26 20:26:12,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 20:26:12,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 20:26:12,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', 'habe', ',', 'ist', 'eine', 'ver@@', '<unk>', '@', 'änder@@', '<unk>', '@', 'te', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'passiert', '.', '</s>']
2025-05-26 20:26:12,625 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 20:26:12,625 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 20:26:12,625 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen habe , ist eine ver<unk> @ änder<unk> @ te , was die letzten 2<unk> @ 5 Jahre passiert .
2025-05-26 20:26:57,963 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     1.029986, Batch Acc: 0.690775, Tokens per Sec:     4149, Lr: 0.000300
2025-05-26 20:27:40,431 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     1.092699, Batch Acc: 0.689526, Tokens per Sec:     4495, Lr: 0.000300
2025-05-26 20:28:24,949 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     0.995071, Batch Acc: 0.690848, Tokens per Sec:     4305, Lr: 0.000300
2025-05-26 20:29:11,706 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     0.965471, Batch Acc: 0.692052, Tokens per Sec:     4187, Lr: 0.000300
2025-05-26 20:29:53,356 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     1.100137, Batch Acc: 0.690964, Tokens per Sec:     4542, Lr: 0.000300
2025-05-26 20:29:53,356 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:29:53,356 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 20:34:26,405 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.14, acc:   0.67, generation: 273.0324[sec], evaluation: 0.0000[sec]
2025-05-26 20:34:26,411 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 20:34:26,532 - INFO - joeynmt.helpers - delete models/bpe_2k_model/4500.ckpt
2025-05-26 20:34:26,537 - INFO - joeynmt.training - Example #0
2025-05-26 20:34:26,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 20:34:26,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 20:34:26,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'zwei', 'Jahren', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lin@@', '<unk>', '@', 'ik@@', '<unk>', '@', 'er', ',', 'die', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lin@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'L@@', '<unk>', '@', 'ö@@', '<unk>', '@', 's@@', '<unk>', '@', 'ung', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'von', 'den', 'F@@', '<unk>', '@', 'e@@', '<unk>', '@', 'st@@', '<unk>', '@', 'el@@', '<unk>', '@', 'and', '.', '</s>']
2025-05-26 20:34:26,537 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 20:34:26,537 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 20:34:26,537 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or zwei Jahren habe ich diese zwei Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ lin<unk> @ ik<unk> @ er , die die die die P<unk> @ o<unk> @ lin<unk> @ sk<unk> @ a<unk> @ p , die die die L<unk> @ ö<unk> @ s<unk> @ ung der U<unk> @ S<unk> @ A , die die die die letzten drei Millionen Jahre von den F<unk> @ e<unk> @ st<unk> @ el<unk> @ and .
2025-05-26 20:34:26,538 - INFO - joeynmt.training - Example #1
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'der', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'el@@', '<unk>', '@', 'f@@', '<unk>', '@', 'i@@', '<unk>', '@', 'v', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'a@@', '<unk>', '@', 'gram@@', '<unk>', '@', 'm', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'a@@', '<unk>', '@', 'kt', ',', '</s>']
2025-05-26 20:34:26,538 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 20:34:26,538 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 20:34:26,538 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die S<unk> @ in<unk> @ n der Sp<unk> @ e<unk> @ zi<unk> @ el<unk> @ f<unk> @ i<unk> @ v , weil es nicht die Di<unk> @ a<unk> @ gram<unk> @ m , weil es nicht die Di<unk> @ a<unk> @ kt ,
2025-05-26 20:34:26,538 - INFO - joeynmt.training - Example #2
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'e', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ool', 'ist', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'ten', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'nen', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 20:34:26,538 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 20:34:26,538 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 20:34:26,538 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ e auf der N<unk> @ or<unk> @ d<unk> @ p<unk> @ ool ist in sie<unk> @ ch<unk> @ ten S<unk> @ in<unk> @ n in sie<unk> @ ch<unk> @ nen S<unk> @ in<unk> @ n .
2025-05-26 20:34:26,538 - INFO - joeynmt.training - Example #3
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 20:34:26,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 20:34:26,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 20:34:26,539 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 20:34:26,539 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 20:34:26,539 - INFO - joeynmt.training - 	Hypothesis: Es ist in der S<unk> @ om<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ er .
2025-05-26 20:34:26,539 - INFO - joeynmt.training - Example #4
2025-05-26 20:34:26,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 20:34:26,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 20:34:26,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', 'möchte', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', 'dem', 'dem', 'dem', 'dem', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'sagt', ',', 'was', 'es', 'in', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-26 20:34:26,539 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 20:34:26,539 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 20:34:26,539 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen möchte , ist ein Ver<unk> @ si<unk> @ on von dem dem dem dem dem letzten 2<unk> @ 5 Jahren ge<unk> @ sagt , was es in der letzten 2<unk> @ 5 Jahren .
2025-05-26 20:35:09,710 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     1.080910, Batch Acc: 0.693380, Tokens per Sec:     4309, Lr: 0.000300
2025-05-26 20:35:56,273 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     1.026923, Batch Acc: 0.694640, Tokens per Sec:     4132, Lr: 0.000300
2025-05-26 20:36:40,998 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     1.067011, Batch Acc: 0.693703, Tokens per Sec:     4314, Lr: 0.000300
2025-05-26 20:37:27,074 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     1.029433, Batch Acc: 0.696346, Tokens per Sec:     4191, Lr: 0.000300
2025-05-26 20:38:10,858 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     1.062788, Batch Acc: 0.695006, Tokens per Sec:     4489, Lr: 0.000300
2025-05-26 20:38:10,859 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:38:10,859 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 20:43:27,824 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.12, ppl:   3.08, acc:   0.68, generation: 316.9492[sec], evaluation: 0.0000[sec]
2025-05-26 20:43:27,830 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 20:43:27,948 - INFO - joeynmt.helpers - delete models/bpe_2k_model/5000.ckpt
2025-05-26 20:43:27,951 - INFO - joeynmt.training - Example #0
2025-05-26 20:43:27,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 20:43:27,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 20:43:27,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahre', 'lie@@', '<unk>', '@', 'gt', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'ik@@', '<unk>', '@', 'er', ',', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'schein@@', '<unk>', '@', 'lich@@', '<unk>', '@', 'es', 'vor', 'drei', 'Millionen', 'Jahre', 'der', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'ß@@', '<unk>', '@', 'er@@', '<unk>', '@', 'halb', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'als', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'F@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'igkeit', ',', 'die', 'die', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'st@@', '<unk>', '@', 'el@@', '<unk>', '@', 'be', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'mt', 'war', '.', '</s>']
2025-05-26 20:43:27,952 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 20:43:27,952 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 20:43:27,952 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ig Jahre lie<unk> @ gt ich diese zwei Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ ss<unk> @ ik<unk> @ er , die die die P<unk> @ o<unk> @ schein<unk> @ lich<unk> @ es vor drei Millionen Jahre der F<unk> @ ü<unk> @ ß<unk> @ er<unk> @ halb der letzten drei Millionen Jahre , als 4<unk> @ 0 Prozent der F<unk> @ äh<unk> @ igkeit , die die F<unk> @ ü<unk> @ st<unk> @ el<unk> @ be , die die letzten drei Millionen Jahre ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ mt war .
2025-05-26 20:43:27,952 - INFO - joeynmt.training - Example #1
2025-05-26 20:43:27,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 20:43:27,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 20:43:27,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'E@@', '<unk>', '@', 'ben@@', '<unk>', '@', 'e', 'des', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'i@@', '<unk>', '@', 'f@@', '<unk>', '@', 'i@@', '<unk>', '@', 'f@@', '<unk>', '@', 'i@@', '<unk>', '@', 've', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', 's@@', '<unk>', '@', 'eite', 'des', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die E<unk> @ ben<unk> @ e des Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ i<unk> @ f<unk> @ i<unk> @ f<unk> @ i<unk> @ ve Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ s<unk> @ eite des E<unk> @ is zeigt .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - Example #2
2025-05-26 20:43:27,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 20:43:27,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 20:43:27,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 's', ',', 'ist', 'es', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'st', ',', 'dass', 'es', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'i@@', '<unk>', '@', 'es', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in sie<unk> @ ch<unk> @ s , ist es in sie<unk> @ ch<unk> @ st , dass es in der K<unk> @ l<unk> @ im<unk> @ ma<unk> @ ss<unk> @ i<unk> @ es kl<unk> @ im<unk> @ ma<unk> @ sy<unk> @ stem .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - Example #3
2025-05-26 20:43:27,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 20:43:27,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 20:43:27,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 20:43:27,953 - INFO - joeynmt.training - Example #4
2025-05-26 20:43:27,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 20:43:27,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 20:43:27,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', ',', 'ist', 'ein', 's@@', '<unk>', '@', 'einer', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'sagt', '.', '</s>']
2025-05-26 20:43:27,954 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 20:43:27,954 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 20:43:27,954 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen , ist ein s<unk> @ einer Ver<unk> @ si<unk> @ on , was die letzten 2<unk> @ 5 Jahre ge<unk> @ sagt .
2025-05-26 20:44:12,044 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     1.027960, Batch Acc: 0.694417, Tokens per Sec:     4330, Lr: 0.000300
2025-05-26 20:44:54,258 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     1.074775, Batch Acc: 0.700524, Tokens per Sec:     4481, Lr: 0.000300
2025-05-26 20:45:38,658 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     1.091899, Batch Acc: 0.697496, Tokens per Sec:     4410, Lr: 0.000300
2025-05-26 20:46:21,081 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     1.030847, Batch Acc: 0.700122, Tokens per Sec:     4484, Lr: 0.000300
2025-05-26 20:47:03,281 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.042274, Batch Acc: 0.697268, Tokens per Sec:     4573, Lr: 0.000300
2025-05-26 20:47:03,283 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:47:03,283 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 20:51:23,724 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.11, ppl:   3.04, acc:   0.68, generation: 260.4254[sec], evaluation: 0.0000[sec]
2025-05-26 20:51:23,730 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 20:51:23,852 - INFO - joeynmt.helpers - delete models/bpe_2k_model/5500.ckpt
2025-05-26 20:51:23,854 - INFO - joeynmt.training - Example #0
2025-05-26 20:51:23,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 20:51:23,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 20:51:23,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'a', 'gesehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'al', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'al', 'sehen', ',', 'die', 'die', 'P@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'al', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'in', 'den', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'h@@', '<unk>', '@', 'l@@', '<unk>', '@', 'ung', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'elt', '.', '</s>']
2025-05-26 20:51:23,854 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 20:51:23,854 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 20:51:23,854 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ a gesehen , dass die P<unk> @ ot<unk> @ i<unk> @ zi<unk> @ al sehen , dass die P<unk> @ ot<unk> @ i<unk> @ zi<unk> @ al sehen , die die P<unk> @ ot<unk> @ i<unk> @ zi<unk> @ al der U<unk> @ S<unk> @ A , die die in den U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der F<unk> @ ü<unk> @ h<unk> @ l<unk> @ ung der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ elt .
2025-05-26 20:51:23,854 - INFO - joeynmt.training - Example #1
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'ung', 'dieses', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'el@@', '<unk>', '@', 'b@@', '<unk>', '@', 'ung', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'it', 'sehen', '.', '</s>']
2025-05-26 20:51:23,855 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 20:51:23,855 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 20:51:23,855 - INFO - joeynmt.training - 	Hypothesis: Aber das Unter<unk> @ sch<unk> @ ät<unk> @ z<unk> @ ung dieses Sp<unk> @ e<unk> @ zi<unk> @ el<unk> @ b<unk> @ ung , weil es nicht die D<unk> @ am<unk> @ it sehen .
2025-05-26 20:51:23,855 - INFO - joeynmt.training - Example #2
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'nen', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del', 'von', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al@@', '<unk>', '@', 'er@@', '<unk>', '@', 'weise', '.', '</s>']
2025-05-26 20:51:23,855 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 20:51:23,855 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 20:51:23,855 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in sie<unk> @ ch<unk> @ nen S<unk> @ in<unk> @ n , die K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del von uns gl<unk> @ ob<unk> @ al<unk> @ er<unk> @ weise .
2025-05-26 20:51:23,855 - INFO - joeynmt.training - Example #3
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 20:51:23,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 20:51:23,856 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 20:51:23,856 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 20:51:23,856 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der S<unk> @ om<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ er .
2025-05-26 20:51:23,856 - INFO - joeynmt.training - Example #4
2025-05-26 20:51:23,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 20:51:23,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 20:51:23,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'der', 'ich', 'zeigen', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'der', 'L@@', '<unk>', '@', 'ei@@', '<unk>', '@', 'der', 'ge@@', '<unk>', '@', 'sagt', ',', 'was', 'es', 'in', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'sagt', '.', '</s>']
2025-05-26 20:51:23,856 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 20:51:23,856 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 20:51:23,856 - INFO - joeynmt.training - 	Hypothesis: Und der näch<unk> @ ste Di<unk> @ a , der ich zeigen , ist ein Ver<unk> @ si<unk> @ on der L<unk> @ ei<unk> @ der ge<unk> @ sagt , was es in der letzten 2<unk> @ 5 Jahren ge<unk> @ sagt .
2025-05-26 20:52:05,971 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     0.969935, Batch Acc: 0.700711, Tokens per Sec:     4516, Lr: 0.000300
2025-05-26 20:52:51,867 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     0.991936, Batch Acc: 0.697327, Tokens per Sec:     4306, Lr: 0.000300
2025-05-26 20:53:32,017 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     1.062114, Batch Acc: 0.703674, Tokens per Sec:     4683, Lr: 0.000300
2025-05-26 20:54:16,939 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.111147, Batch Acc: 0.700215, Tokens per Sec:     4276, Lr: 0.000300
2025-05-26 20:54:58,172 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.013862, Batch Acc: 0.702340, Tokens per Sec:     4676, Lr: 0.000300
2025-05-26 20:54:58,173 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 20:54:58,173 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:00:21,281 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   3.00, acc:   0.68, generation: 323.0933[sec], evaluation: 0.0000[sec]
2025-05-26 21:00:21,288 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:00:21,399 - INFO - joeynmt.helpers - delete models/bpe_2k_model/6000.ckpt
2025-05-26 21:00:21,402 - INFO - joeynmt.training - Example #0
2025-05-26 21:00:21,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:00:21,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:00:21,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahre', 'lie@@', '<unk>', '@', 'gt', ',', 'die', 'die', 'P@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'i@@', '<unk>', '@', 'onen', ',', 'die', 'die', 'P@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'en@@', '<unk>', '@', 'ken', ',', 'die', 'die', 'P@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'en@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'g', 'B@@', '<unk>', '@', 'et@@', '<unk>', '@', 'rie@@', '<unk>', '@', 'b', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'F@@', '<unk>', '@', 'e@@', '<unk>', '@', 'st@@', '<unk>', '@', 'el@@', '<unk>', '@', 'ten', 'von', 'den', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'F@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'r', '.', '</s>']
2025-05-26 21:00:21,403 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:00:21,403 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:00:21,403 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ig Jahre lie<unk> @ gt , die die P<unk> @ ot<unk> @ i<unk> @ onen , die die P<unk> @ ot<unk> @ en<unk> @ ken , die die P<unk> @ ot<unk> @ en<unk> @ zi<unk> @ g B<unk> @ et<unk> @ rie<unk> @ b , die die letzten drei Millionen Jahre der F<unk> @ e<unk> @ st<unk> @ el<unk> @ ten von den U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der F<unk> @ ü<unk> @ r .
2025-05-26 21:00:21,403 - INFO - joeynmt.training - Example #1
2025-05-26 21:00:21,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:00:21,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:00:21,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'üt@@', '<unk>', '@', 'zt', 'das', 'das', 'ist', ',', 'was', 'nicht', 'die', 'Be@@', '<unk>', '@', 'g@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 's@@', '<unk>', '@', 'on@@', '<unk>', '@', 'st', 'des', 'E@@', '<unk>', '@', 'is', 'ist', '.', '</s>']
2025-05-26 21:00:21,403 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:00:21,403 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:00:21,403 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das unter<unk> @ sch<unk> @ üt<unk> @ zt das das ist , was nicht die Be<unk> @ g<unk> @ in<unk> @ n des E<unk> @ is , weil es nicht die Di<unk> @ ck<unk> @ s<unk> @ on<unk> @ st des E<unk> @ is ist .
2025-05-26 21:00:21,403 - INFO - joeynmt.training - Example #2
2025-05-26 21:00:21,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:00:21,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:00:21,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'ist', 'in', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'nen', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'in', 'der', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'h@@', '<unk>', '@', 'l@@', '<unk>', '@', 'ung', 'von', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ma@@', '<unk>', '@', 's', '.', '</s>']
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ sk<unk> @ a<unk> @ p ist in der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in sie<unk> @ ch<unk> @ nen S<unk> @ in<unk> @ n , die wir in der K<unk> @ li<unk> @ ma<unk> @ h<unk> @ l<unk> @ ung von uns gl<unk> @ ob<unk> @ al kl<unk> @ im<unk> @ ma<unk> @ s .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - Example #3
2025-05-26 21:00:21,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:00:21,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:00:21,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ er .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - Example #4
2025-05-26 21:00:21,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:00:21,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:00:21,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'sehen', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'der', 'L@@', '<unk>', '@', 'ei@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ung', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:00:21,404 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich Ihnen sehen , ist ein Ver<unk> @ si<unk> @ on der L<unk> @ ei<unk> @ st<unk> @ ung , was die letzten 2<unk> @ 5 Jahre pass<unk> @ ierte .
2025-05-26 21:01:03,684 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     1.014706, Batch Acc: 0.702460, Tokens per Sec:     4458, Lr: 0.000300
2025-05-26 21:01:49,738 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     0.976586, Batch Acc: 0.702423, Tokens per Sec:     4251, Lr: 0.000300
2025-05-26 21:02:37,299 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.100669, Batch Acc: 0.701998, Tokens per Sec:     4151, Lr: 0.000300
2025-05-26 21:03:20,779 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.005437, Batch Acc: 0.702811, Tokens per Sec:     4383, Lr: 0.000300
2025-05-26 21:04:05,237 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.066198, Batch Acc: 0.703934, Tokens per Sec:     4371, Lr: 0.000300
2025-05-26 21:04:05,238 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:04:05,238 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:09:20,871 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.96, acc:   0.69, generation: 315.6170[sec], evaluation: 0.0000[sec]
2025-05-26 21:09:20,875 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:09:20,995 - INFO - joeynmt.helpers - delete models/bpe_2k_model/6500.ckpt
2025-05-26 21:09:21,000 - INFO - joeynmt.training - Example #0
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'x@@', '<unk>', '@', 'ien', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'x@@', '<unk>', '@', 'ien', ',', 'die', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'in@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'p', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'F@@', '<unk>', '@', 'e@@', '<unk>', '@', 'st@@', '<unk>', '@', 'el@@', '<unk>', '@', 'and', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', '</s>']
2025-05-26 21:09:21,001 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:09:21,001 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:09:21,001 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or Jahr habe ich diese zwei Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ x<unk> @ ien zeigen , dass die P<unk> @ o<unk> @ x<unk> @ ien , die die die die P<unk> @ o<unk> @ in<unk> @ zi<unk> @ p der U<unk> @ S<unk> @ A , die die die letzten drei Millionen Jahren der U<unk> @ S<unk> @ A , die die die letzten drei Millionen Jahren , die die F<unk> @ e<unk> @ st<unk> @ el<unk> @ and des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A ,
2025-05-26 21:09:21,001 - INFO - joeynmt.training - Example #1
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'ze', 'das', 'ist', ',', 'dass', 'das', 'Ge@@', '<unk>', '@', 'dan@@', '<unk>', '@', 'ken', 'des', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'der', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'men@@', '<unk>', '@', 'te', 'des', 'E@@', '<unk>', '@', 'is', 'ist', '.', '</s>']
2025-05-26 21:09:21,001 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:09:21,001 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:09:21,001 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ ze das ist , dass das Ge<unk> @ dan<unk> @ ken des E<unk> @ is , weil es nicht der D<unk> @ am<unk> @ men<unk> @ te des E<unk> @ is ist .
2025-05-26 21:09:21,001 - INFO - joeynmt.training - Example #2
2025-05-26 21:09:21,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'ist', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'e', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', 'ist', 'in', 'sie@@', '<unk>', '@', 'ch@@', '<unk>', '@', 's', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 21:09:21,002 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:09:21,002 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:09:21,002 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ sk<unk> @ a<unk> @ p ist auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in sie<unk> @ ch<unk> @ e S<unk> @ in<unk> @ ne ist in sie<unk> @ ch<unk> @ s K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del<unk> @ n .
2025-05-26 21:09:21,002 - INFO - joeynmt.training - Example #3
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 21:09:21,002 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:09:21,002 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:09:21,002 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 21:09:21,002 - INFO - joeynmt.training - Example #4
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:09:21,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'möchte', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 21:09:21,003 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:09:21,003 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:09:21,003 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen möchte , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-26 21:10:03,651 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.006551, Batch Acc: 0.704350, Tokens per Sec:     4513, Lr: 0.000300
2025-05-26 21:10:45,604 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.001386, Batch Acc: 0.708368, Tokens per Sec:     4555, Lr: 0.000300
2025-05-26 21:11:30,117 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.061077, Batch Acc: 0.703999, Tokens per Sec:     4436, Lr: 0.000300
2025-05-26 21:11:59,342 - INFO - joeynmt.training - Epoch   3: total training loss 3299.91
2025-05-26 21:11:59,342 - INFO - joeynmt.training - EPOCH 4
2025-05-26 21:12:10,090 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     0.939053, Batch Acc: 0.713387, Tokens per Sec:     4452, Lr: 0.000300
2025-05-26 21:12:50,949 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     0.972304, Batch Acc: 0.714551, Tokens per Sec:     4711, Lr: 0.000300
2025-05-26 21:12:50,951 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:12:50,951 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:17:57,853 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.94, acc:   0.69, generation: 306.8869[sec], evaluation: 0.0000[sec]
2025-05-26 21:17:57,859 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:17:57,965 - INFO - joeynmt.helpers - delete models/bpe_2k_model/7000.ckpt
2025-05-26 21:17:57,970 - INFO - joeynmt.training - Example #0
2025-05-26 21:17:57,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:17:57,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:17:57,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'ich', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lei@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lei@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'sten', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'größ@@', '<unk>', '@', 'eren', 'An@@', '<unk>', '@', 'za@@', '<unk>', '@', 'hl', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 21:17:57,971 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:17:57,971 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:17:57,971 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or zwei Di<unk> @ as sehen , die ich zeigen , dass die P<unk> @ o<unk> @ lei<unk> @ sk<unk> @ a<unk> @ p , die die die P<unk> @ o<unk> @ lei<unk> @ sk<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ sten der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % der größ<unk> @ eren An<unk> @ za<unk> @ hl der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 21:17:57,971 - INFO - joeynmt.training - Example #1
2025-05-26 21:17:57,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:17:57,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:17:57,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'eigen@@', '<unk>', '@', 'e', 'Sch@@', '<unk>', '@', 'at@@', '<unk>', '@', 't', ',', 'dass', 'das', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'it', 'der', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'a@@', '<unk>', '@', 'gram@@', '<unk>', '@', 'm', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 21:17:57,971 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:17:57,971 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:17:57,971 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die eigen<unk> @ e Sch<unk> @ at<unk> @ t , dass das nicht die D<unk> @ am<unk> @ it der E<unk> @ is , weil es nicht die Di<unk> @ a<unk> @ gram<unk> @ m des E<unk> @ is .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - Example #2
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'p@@', '<unk>', '@', 'f', ',', 'die', 'die', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 21:17:57,972 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der K<unk> @ l<unk> @ ö<unk> @ p<unk> @ f , die die wir uns gl<unk> @ ob<unk> @ al kl<unk> @ im<unk> @ a .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - Example #3
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 21:17:57,972 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - 	Hypothesis: Es ist in der S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 21:17:57,972 - INFO - joeynmt.training - Example #4
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:17:57,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', 'werde', ',', 'ist', 'ein', 'ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on@@', '<unk>', '@', 's@@', '<unk>', '@', 'eit', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ist', '.', '</s>']
2025-05-26 21:17:57,973 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:17:57,973 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:17:57,973 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen werde , ist ein ver<unk> @ si<unk> @ on<unk> @ s<unk> @ eit der letzten 2<unk> @ 5 Jahren ist .
2025-05-26 21:18:41,066 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     0.918505, Batch Acc: 0.715365, Tokens per Sec:     4502, Lr: 0.000300
2025-05-26 21:19:23,406 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     0.988123, Batch Acc: 0.717501, Tokens per Sec:     4569, Lr: 0.000300
2025-05-26 21:20:08,181 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     0.960822, Batch Acc: 0.713008, Tokens per Sec:     4315, Lr: 0.000300
2025-05-26 21:20:51,147 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     1.113963, Batch Acc: 0.714805, Tokens per Sec:     4479, Lr: 0.000300
2025-05-26 21:21:36,158 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     0.969245, Batch Acc: 0.713248, Tokens per Sec:     4348, Lr: 0.000300
2025-05-26 21:21:36,159 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:21:36,160 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:26:27,865 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.92, acc:   0.69, generation: 291.6901[sec], evaluation: 0.0000[sec]
2025-05-26 21:26:27,873 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:26:27,983 - INFO - joeynmt.helpers - delete models/bpe_2k_model/7500.ckpt
2025-05-26 21:26:27,989 - INFO - joeynmt.training - Example #0
2025-05-26 21:26:27,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:26:27,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:26:27,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lei@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'zu', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lei@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'gel@@', '<unk>', '@', 'aufen', 'hatte', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 21:26:27,989 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:26:27,989 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:26:27,989 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or zwei Di<unk> @ as sehen , um zu zeigen , dass die P<unk> @ o<unk> @ lei<unk> @ sk<unk> @ a<unk> @ p zu zeigen , dass die P<unk> @ o<unk> @ lei<unk> @ sk<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahren der V<unk> @ o<unk> @ gel<unk> @ aufen hatte , die die die letzten drei Millionen Jahren der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der V<unk> @ o<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 21:26:27,989 - INFO - joeynmt.training - Example #1
2025-05-26 21:26:27,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:26:27,990 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:26:27,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Aus@@', '<unk>', '@', 'wir@@', '<unk>', '@', 'kun@@', '<unk>', '@', 'gen', 'der', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'el@@', '<unk>', '@', 'f@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ges', 'ist', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 21:26:27,990 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:26:27,990 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:26:27,990 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieser spe<unk> @ zi<unk> @ elle Aus<unk> @ wir<unk> @ kun<unk> @ gen der Sp<unk> @ e<unk> @ zi<unk> @ el<unk> @ f<unk> @ i<unk> @ ges ist , weil es nicht die E<unk> @ is des E<unk> @ is .
2025-05-26 21:26:27,990 - INFO - joeynmt.training - Example #2
2025-05-26 21:26:27,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:26:27,990 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:26:27,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'sie@@', '<unk>', '@', 'ben', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', 'von', 'uns', 'G@@', '<unk>', '@', 'l@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 21:26:27,990 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:26:27,990 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:26:27,990 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in sie<unk> @ ben S<unk> @ in<unk> @ ne , die S<unk> @ in<unk> @ ne von uns G<unk> @ l<unk> @ ob<unk> @ al kl<unk> @ im<unk> @ a .
2025-05-26 21:26:27,990 - INFO - joeynmt.training - Example #3
2025-05-26 21:26:27,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:26:27,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:26:27,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 21:26:27,991 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:26:27,991 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:26:27,991 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ mer<unk> @ n .
2025-05-26 21:26:27,991 - INFO - joeynmt.training - Example #4
2025-05-26 21:26:27,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:26:27,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:26:27,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 21:26:27,991 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:26:27,991 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:26:27,991 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen , ist ein Ver<unk> @ si<unk> @ on , was die letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-26 21:27:11,302 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:     1.036581, Batch Acc: 0.712100, Tokens per Sec:     4463, Lr: 0.000300
2025-05-26 21:27:54,495 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:     0.967183, Batch Acc: 0.714241, Tokens per Sec:     4446, Lr: 0.000300
2025-05-26 21:28:38,050 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:     1.013457, Batch Acc: 0.711647, Tokens per Sec:     4355, Lr: 0.000300
2025-05-26 21:29:20,609 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:     0.985738, Batch Acc: 0.715061, Tokens per Sec:     4434, Lr: 0.000300
2025-05-26 21:30:01,543 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:     1.004409, Batch Acc: 0.716636, Tokens per Sec:     4687, Lr: 0.000300
2025-05-26 21:30:01,544 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:30:01,544 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:34:18,117 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.91, acc:   0.69, generation: 256.5591[sec], evaluation: 0.0000[sec]
2025-05-26 21:34:18,123 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:34:18,232 - INFO - joeynmt.helpers - delete models/bpe_2k_model/8000.ckpt
2025-05-26 21:34:18,237 - INFO - joeynmt.training - Example #0
2025-05-26 21:34:18,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:34:18,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:34:18,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'ich', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'x@@', '<unk>', '@', 'i@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'x@@', '<unk>', '@', 'i@@', '<unk>', '@', '-@@', '<unk>', '@', 'K@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'von', 'Jahren', ',', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ur@@', '<unk>', '@', 's', 'war', '.', '</s>']
2025-05-26 21:34:18,238 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:34:18,238 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:34:18,238 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or zwei Di<unk> @ as sehen , die ich zwei Di<unk> @ as sehen , um zu zeigen , dass die P<unk> @ o<unk> @ x<unk> @ i<unk> @ sk<unk> @ a<unk> @ p , die die P<unk> @ o<unk> @ x<unk> @ i<unk> @ -<unk> @ K<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre von Jahren , 4<unk> @ 0 Prozent der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ ur<unk> @ s war .
2025-05-26 21:34:18,238 - INFO - joeynmt.training - Example #1
2025-05-26 21:34:18,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:34:18,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:34:18,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', 'kennen', '.', '</s>']
2025-05-26 21:34:18,238 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:34:18,238 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:34:18,238 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieser spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ kennen .
2025-05-26 21:34:18,238 - INFO - joeynmt.training - Example #2
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'sie@@', '<unk>', '@', 'ben', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'ist', 'in', 'sie@@', '<unk>', '@', 'ker@@', '<unk>', '@', 'e', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', '.', '</s>']
2025-05-26 21:34:18,239 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:34:18,239 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:34:18,239 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in sie<unk> @ ben S<unk> @ in<unk> @ n , ist in sie<unk> @ ker<unk> @ e S<unk> @ in<unk> @ ne .
2025-05-26 21:34:18,239 - INFO - joeynmt.training - Example #3
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 21:34:18,239 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:34:18,239 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:34:18,239 - INFO - joeynmt.training - 	Hypothesis: Es ist in der S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 21:34:18,239 - INFO - joeynmt.training - Example #4
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:34:18,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'Ihnen', 'zeigen', 'ist', 'ein', 'ver@@', '<unk>', '@', 'br@@', '<unk>', '@', 'eit@@', '<unk>', '@', 'et', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'sagt', '.', '</s>']
2025-05-26 21:34:18,240 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:34:18,240 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:34:18,240 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen Ihnen zeigen ist ein ver<unk> @ br<unk> @ eit<unk> @ et , was die letzten 2<unk> @ 5 Jahre ge<unk> @ sagt .
2025-05-26 21:35:03,871 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:     0.999358, Batch Acc: 0.714071, Tokens per Sec:     4326, Lr: 0.000300
2025-05-26 21:35:46,351 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     0.909402, Batch Acc: 0.715782, Tokens per Sec:     4436, Lr: 0.000300
2025-05-26 21:36:26,198 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     1.002830, Batch Acc: 0.714669, Tokens per Sec:     4706, Lr: 0.000300
2025-05-26 21:37:10,152 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     0.934030, Batch Acc: 0.715205, Tokens per Sec:     4502, Lr: 0.000300
2025-05-26 21:37:54,759 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:     0.913096, Batch Acc: 0.718175, Tokens per Sec:     4276, Lr: 0.000300
2025-05-26 21:37:54,760 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:37:54,761 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:43:08,240 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.06, ppl:   2.88, acc:   0.70, generation: 313.4633[sec], evaluation: 0.0000[sec]
2025-05-26 21:43:08,243 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:43:08,359 - INFO - joeynmt.helpers - delete models/bpe_2k_model/8500.ckpt
2025-05-26 21:43:08,362 - INFO - joeynmt.training - Example #0
2025-05-26 21:43:08,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:43:08,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:43:08,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'zwei', 'Di@@', '<unk>', '@', 'as', 'gesehen', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'gesehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'von', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', '</s>']
2025-05-26 21:43:08,363 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:43:08,363 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:43:08,363 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or zwei Di<unk> @ as gesehen habe ich diese zwei Di<unk> @ as gesehen , um zu zeigen , dass die P<unk> @ o<unk> @ ss<unk> @ a<unk> @ p , die die P<unk> @ o<unk> @ ss<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre von der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A ,
2025-05-26 21:43:08,363 - INFO - joeynmt.training - Example #1
2025-05-26 21:43:08,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:43:08,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:43:08,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'ung', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'ell', ',', 'das', 'ist', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'st@@', '<unk>', '@', 're@@', '<unk>', '@', 'kt', 'ist', '.', '</s>']
2025-05-26 21:43:08,363 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:43:08,363 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:43:08,363 - INFO - joeynmt.training - 	Hypothesis: Aber das Unter<unk> @ sch<unk> @ ät<unk> @ z<unk> @ ung dieses spe<unk> @ zi<unk> @ ell , das ist nicht die E<unk> @ is , weil es nicht die Di<unk> @ en<unk> @ st<unk> @ re<unk> @ kt ist .
2025-05-26 21:43:08,363 - INFO - joeynmt.training - Example #2
2025-05-26 21:43:08,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:43:08,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:43:08,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', '-@@', '<unk>', '@', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'M@@', '<unk>', '@', 'eer@@', '<unk>', '@', 'e@@', '<unk>', '@', 's@@', '<unk>', '@', '-@@', '<unk>', '@', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ -<unk> @ N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in M<unk> @ eer<unk> @ e<unk> @ s<unk> @ -<unk> @ K<unk> @ li<unk> @ ma<unk> @ -<unk> @ Sy<unk> @ stem .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - Example #3
2025-05-26 21:43:08,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:43:08,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:43:08,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - Example #4
2025-05-26 21:43:08,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:43:08,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:43:08,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigt', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:43:08,364 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigt , ist ein Ver<unk> @ si<unk> @ on von der letzten 2<unk> @ 5 Jahre pass<unk> @ ierte .
2025-05-26 21:43:51,189 - INFO - joeynmt.training - Epoch   4, Step:    11100, Batch Loss:     1.010682, Batch Acc: 0.716214, Tokens per Sec:     4519, Lr: 0.000300
2025-05-26 21:44:33,778 - INFO - joeynmt.training - Epoch   4, Step:    11200, Batch Loss:     0.981407, Batch Acc: 0.715287, Tokens per Sec:     4534, Lr: 0.000300
2025-05-26 21:45:16,953 - INFO - joeynmt.training - Epoch   4, Step:    11300, Batch Loss:     0.919357, Batch Acc: 0.719379, Tokens per Sec:     4433, Lr: 0.000300
2025-05-26 21:45:59,545 - INFO - joeynmt.training - Epoch   4, Step:    11400, Batch Loss:     0.940396, Batch Acc: 0.718658, Tokens per Sec:     4483, Lr: 0.000300
2025-05-26 21:46:43,732 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     0.928482, Batch Acc: 0.718539, Tokens per Sec:     4309, Lr: 0.000300
2025-05-26 21:46:43,732 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:46:43,732 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 21:52:11,681 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.86, acc:   0.70, generation: 327.9333[sec], evaluation: 0.0000[sec]
2025-05-26 21:52:11,684 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 21:52:11,799 - INFO - joeynmt.helpers - delete models/bpe_2k_model/9000.ckpt
2025-05-26 21:52:11,801 - INFO - joeynmt.training - Example #0
2025-05-26 21:52:11,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 21:52:11,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 21:52:11,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahre', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'die', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'iz@@', '<unk>', '@', 'iert', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'von', 'den', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 21:52:11,802 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 21:52:11,802 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 21:52:11,802 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ig Jahre zei<unk> @ ge ich diese zwei Di<unk> @ as sehen , die die die zwei Di<unk> @ as sehen , die die P<unk> @ o<unk> @ ss<unk> @ i<unk> @ zi<unk> @ f<unk> @ iz<unk> @ iert , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e drei Millionen Jahren , die die Gr<unk> @ öß<unk> @ e von den U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 21:52:11,802 - INFO - joeynmt.training - Example #1
2025-05-26 21:52:11,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 21:52:11,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 21:52:11,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'fte', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a@@', '<unk>', '@', 'gram@@', '<unk>', '@', 'm', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a@@', '<unk>', '@', 'gram@@', '<unk>', '@', 'm', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a@@', '<unk>', '@', 'gram@@', '<unk>', '@', 'm', 'sehen', '.', '</s>']
2025-05-26 21:52:11,802 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 21:52:11,802 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 21:52:11,802 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st<unk> @ ha<unk> @ fte dieser spe<unk> @ zi<unk> @ elle Problem , weil es nicht die Di<unk> @ en<unk> @ a<unk> @ gram<unk> @ m , weil es nicht die Di<unk> @ en<unk> @ a<unk> @ gram<unk> @ m , weil es nicht die Di<unk> @ en<unk> @ a<unk> @ gram<unk> @ m sehen .
2025-05-26 21:52:11,802 - INFO - joeynmt.training - Example #2
2025-05-26 21:52:11,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 21:52:11,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 21:52:11,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'op@@', '<unk>', '@', 'f', 'der', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'ß@@', '<unk>', '@', 'e', 'ist', ',', 'dass', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'it@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der K<unk> @ op<unk> @ f der K<unk> @ li<unk> @ ma<unk> @ ß<unk> @ e ist , dass wir uns gl<unk> @ ob<unk> @ al kl<unk> @ im<unk> @ it<unk> @ t .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - Example #3
2025-05-26 21:52:11,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 21:52:11,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 21:52:11,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ mer<unk> @ n .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - Example #4
2025-05-26 21:52:11,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 21:52:11,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 21:52:11,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'passiert', '.', '</s>']
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 21:52:11,803 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen , ist ein Ver<unk> @ si<unk> @ on , die ich Ihnen zeigen , was die letzten 2<unk> @ 5 Jahre passiert .
2025-05-26 21:52:55,036 - INFO - joeynmt.training - Epoch   4, Step:    11600, Batch Loss:     0.966175, Batch Acc: 0.717784, Tokens per Sec:     4429, Lr: 0.000300
2025-05-26 21:53:38,725 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     0.956584, Batch Acc: 0.719236, Tokens per Sec:     4386, Lr: 0.000300
2025-05-26 21:54:22,689 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     0.974705, Batch Acc: 0.721554, Tokens per Sec:     4352, Lr: 0.000300
2025-05-26 21:55:09,889 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     0.956189, Batch Acc: 0.719401, Tokens per Sec:     4104, Lr: 0.000300
2025-05-26 21:55:53,750 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     0.894184, Batch Acc: 0.720422, Tokens per Sec:     4427, Lr: 0.000300
2025-05-26 21:55:53,751 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 21:55:53,751 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:00:47,131 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 293.3644[sec], evaluation: 0.0000[sec]
2025-05-26 22:00:47,135 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:00:47,252 - INFO - joeynmt.helpers - delete models/bpe_2k_model/9500.ckpt
2025-05-26 22:00:47,256 - INFO - joeynmt.training - Example #0
2025-05-26 22:00:47,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:00:47,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:00:47,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'die', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'en@@', '<unk>', '@', '-@@', '<unk>', '@', 'A@@', '<unk>', '@', 'pp@@', '<unk>', '@', 'e', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ch@@', '<unk>', '@', 's', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', '</s>']
2025-05-26 22:00:47,257 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:00:47,257 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:00:47,257 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or ich diese zwei Di<unk> @ as zeigen , die die zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ ss<unk> @ en<unk> @ -<unk> @ A<unk> @ pp<unk> @ e , die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ ch<unk> @ s , die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A ,
2025-05-26 22:00:47,257 - INFO - joeynmt.training - Example #1
2025-05-26 22:00:47,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:00:47,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:00:47,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'ung', 'dieses', 'The@@', '<unk>', '@', 'ma', ',', 'das', 'ist', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'st@@', '<unk>', '@', 'an@@', '<unk>', '@', 'z', 'der', 'E@@', '<unk>', '@', 'is', 'zeigt', ',', 'ist', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', '.', '</s>']
2025-05-26 22:00:47,257 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Hypothesis: Aber das Unter<unk> @ sch<unk> @ ät<unk> @ z<unk> @ ung dieses The<unk> @ ma , das ist nicht die Di<unk> @ en<unk> @ st<unk> @ an<unk> @ z der E<unk> @ is zeigt , ist es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - Example #2
2025-05-26 22:00:47,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:00:47,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:00:47,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'M@@', '<unk>', '@', 'eer@@', '<unk>', '@', 'e', ',', 'die', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'y@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der M<unk> @ eer<unk> @ e , die K<unk> @ li<unk> @ ma<unk> @ ss<unk> @ y<unk> @ stem .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - Example #3
2025-05-26 22:00:47,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:00:47,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:00:47,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - 	Hypothesis: Es ist in der S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 22:00:47,258 - INFO - joeynmt.training - Example #4
2025-05-26 22:00:47,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:00:47,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:00:47,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', '2@@', '<unk>', '@', '5', 'Jahre', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-26 22:00:47,259 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:00:47,259 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:00:47,259 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen , ist eine Ver<unk> @ si<unk> @ on von 2<unk> @ 5 Jahre pass<unk> @ ierte .
2025-05-26 22:01:28,238 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     0.932202, Batch Acc: 0.722780, Tokens per Sec:     4696, Lr: 0.000300
2025-05-26 22:02:11,411 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     0.960358, Batch Acc: 0.719171, Tokens per Sec:     4420, Lr: 0.000300
2025-05-26 22:02:51,538 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     0.995471, Batch Acc: 0.720086, Tokens per Sec:     4742, Lr: 0.000300
2025-05-26 22:03:36,068 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     0.910492, Batch Acc: 0.719426, Tokens per Sec:     4301, Lr: 0.000300
2025-05-26 22:04:18,888 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     1.022021, Batch Acc: 0.720381, Tokens per Sec:     4445, Lr: 0.000300
2025-05-26 22:04:18,889 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:04:18,889 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:09:08,226 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.82, acc:   0.70, generation: 289.3226[sec], evaluation: 0.0000[sec]
2025-05-26 22:09:08,233 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:09:08,350 - INFO - joeynmt.helpers - delete models/bpe_2k_model/10000.ckpt
2025-05-26 22:09:08,353 - INFO - joeynmt.training - Example #0
2025-05-26 22:09:08,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:09:08,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:09:08,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'gesehen', ',', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'i@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'i@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'st@@', '<unk>', '@', 'i@@', '<unk>', '@', 'hr@@', '<unk>', '@', 'es', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:09:08,353 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:09:08,353 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ as gesehen , die zwei Di<unk> @ as sehen , die die P<unk> @ o<unk> @ L<unk> @ i<unk> @ sk<unk> @ a<unk> @ p , die die P<unk> @ o<unk> @ L<unk> @ i<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ st<unk> @ i<unk> @ hr<unk> @ es , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - Example #1
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'te', 'des', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'te', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die Di<unk> @ en<unk> @ te des E<unk> @ is , weil es nicht die Di<unk> @ en<unk> @ te des E<unk> @ is .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - Example #2
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'at@@', '<unk>', '@', 'z@@', '<unk>', '@', '-@@', '<unk>', '@', 'P@@', '<unk>', '@', 'ool', 'ist', 'in', 'der', 'M@@', '<unk>', '@', 'eer@@', '<unk>', '@', 'e', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'rop@@', '<unk>', '@', 'hen', '.', '</s>']
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ at<unk> @ z<unk> @ -<unk> @ P<unk> @ ool ist in der M<unk> @ eer<unk> @ e ist in der K<unk> @ l<unk> @ op<unk> @ p<unk> @ e ist in der K<unk> @ l<unk> @ im<unk> @ at<unk> @ ast<unk> @ rop<unk> @ hen .
2025-05-26 22:09:08,354 - INFO - joeynmt.training - Example #3
2025-05-26 22:09:08,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:09:08,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:09:08,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'st', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 22:09:08,355 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:09:08,355 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:09:08,355 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ st in der S<unk> @ om<unk> @ mer<unk> @ n .
2025-05-26 22:09:08,355 - INFO - joeynmt.training - Example #4
2025-05-26 22:09:08,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:09:08,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:09:08,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'habe', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 22:09:08,355 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:09:08,355 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:09:08,355 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen habe , ist eine Ver<unk> @ si<unk> @ on von 2<unk> @ 5 Jahre ge<unk> @ scha<unk> @ h .
2025-05-26 22:09:08,361 - INFO - joeynmt.training - Epoch   4: total training loss 3071.67
2025-05-26 22:09:08,361 - INFO - joeynmt.training - EPOCH 5
2025-05-26 22:09:51,034 - INFO - joeynmt.training - Epoch   5, Step:    12600, Batch Loss:     0.983806, Batch Acc: 0.728360, Tokens per Sec:     4442, Lr: 0.000300
2025-05-26 22:10:38,319 - INFO - joeynmt.training - Epoch   5, Step:    12700, Batch Loss:     0.861098, Batch Acc: 0.727786, Tokens per Sec:     4141, Lr: 0.000300
2025-05-26 22:11:19,970 - INFO - joeynmt.training - Epoch   5, Step:    12800, Batch Loss:     0.938386, Batch Acc: 0.726889, Tokens per Sec:     4569, Lr: 0.000300
2025-05-26 22:12:01,316 - INFO - joeynmt.training - Epoch   5, Step:    12900, Batch Loss:     1.019997, Batch Acc: 0.730307, Tokens per Sec:     4619, Lr: 0.000300
2025-05-26 22:12:46,561 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:     0.890946, Batch Acc: 0.730521, Tokens per Sec:     4353, Lr: 0.000300
2025-05-26 22:12:46,563 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:12:46,563 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:18:16,341 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.81, acc:   0.70, generation: 329.7623[sec], evaluation: 0.0000[sec]
2025-05-26 22:18:16,345 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:18:16,464 - INFO - joeynmt.helpers - delete models/bpe_2k_model/10500.ckpt
2025-05-26 22:18:16,467 - INFO - joeynmt.training - Example #0
2025-05-26 22:18:16,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:18:16,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:18:16,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:18:16,467 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:18:16,467 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:18:16,467 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ as zeigen , dass die zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ L<unk> @ k<unk> @ a<unk> @ p sehen , dass die P<unk> @ o<unk> @ L<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ k<unk> @ a<unk> @ p der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:18:16,467 - INFO - joeynmt.training - Example #1
2025-05-26 22:18:16,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:18:16,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:18:16,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'The@@', '<unk>', '@', 'ma', 'ist', 'das', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'denn', 'das', 'nicht', 'die', 'Di@@', '<unk>', '@', 're@@', '<unk>', '@', 'kt', 'des', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'en@@', '<unk>', '@', 'g@@', '<unk>', '@', 's', 'zeigt', '.', '</s>']
2025-05-26 22:18:16,468 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:18:16,468 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:18:16,468 - INFO - joeynmt.training - 	Hypothesis: Aber das The<unk> @ ma ist das ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , denn das nicht die Di<unk> @ re<unk> @ kt des E<unk> @ is<unk> @ en<unk> @ g<unk> @ s zeigt .
2025-05-26 22:18:16,468 - INFO - joeynmt.training - Example #2
2025-05-26 22:18:16,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:18:16,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:18:16,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'it@@', '<unk>', '@', 'ä@@', '<unk>', '@', 'ten', 'von', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'alen', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 22:18:16,468 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:18:16,468 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:18:16,468 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ n , die wir in gew<unk> @ is<unk> @ se K<unk> @ l<unk> @ im<unk> @ it<unk> @ ä<unk> @ ten von uns gl<unk> @ ob<unk> @ alen K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del<unk> @ n .
2025-05-26 22:18:16,468 - INFO - joeynmt.training - Example #3
2025-05-26 22:18:16,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:18:16,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:18:16,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'La@@', '<unk>', '@', 'ge', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:18:16,469 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:18:16,469 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:18:16,469 - INFO - joeynmt.training - 	Hypothesis: Es ist in der La<unk> @ ge und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 22:18:16,469 - INFO - joeynmt.training - Example #4
2025-05-26 22:18:16,469 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:18:16,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:18:16,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', ',', 'ist', 'eine', 'S@@', '<unk>', '@', 'el@@', '<unk>', '@', 'b@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-26 22:18:16,469 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:18:16,469 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:18:16,469 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich zeigen , ist eine S<unk> @ el<unk> @ b<unk> @ st<unk> @ ver<unk> @ si<unk> @ on , was die letzten 2<unk> @ 5 Jahre pass<unk> @ ierte .
2025-05-26 22:18:57,928 - INFO - joeynmt.training - Epoch   5, Step:    13100, Batch Loss:     0.918034, Batch Acc: 0.729786, Tokens per Sec:     4627, Lr: 0.000300
2025-05-26 22:19:41,147 - INFO - joeynmt.training - Epoch   5, Step:    13200, Batch Loss:     0.946794, Batch Acc: 0.727822, Tokens per Sec:     4386, Lr: 0.000300
2025-05-26 22:20:22,796 - INFO - joeynmt.training - Epoch   5, Step:    13300, Batch Loss:     0.904636, Batch Acc: 0.729585, Tokens per Sec:     4572, Lr: 0.000300
2025-05-26 22:21:07,611 - INFO - joeynmt.training - Epoch   5, Step:    13400, Batch Loss:     0.923641, Batch Acc: 0.727764, Tokens per Sec:     4339, Lr: 0.000300
2025-05-26 22:21:50,584 - INFO - joeynmt.training - Epoch   5, Step:    13500, Batch Loss:     0.868232, Batch Acc: 0.727956, Tokens per Sec:     4490, Lr: 0.000300
2025-05-26 22:21:50,585 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:21:50,585 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:26:39,942 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.81, acc:   0.70, generation: 289.3413[sec], evaluation: 0.0000[sec]
2025-05-26 22:26:39,947 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:26:40,070 - INFO - joeynmt.helpers - delete models/bpe_2k_model/11000.ckpt
2025-05-26 22:26:40,073 - INFO - joeynmt.training - Example #0
2025-05-26 22:26:40,074 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:26:40,074 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:26:40,074 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahre', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'en@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'al', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'y@@', '<unk>', '@', 's', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'l@@', '<unk>', '@', 's', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:26:40,074 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:26:40,074 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:26:40,074 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ig Jahre habe ich diese zwei Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ ss<unk> @ en<unk> @ zi<unk> @ al sehen , dass die P<unk> @ o<unk> @ ss<unk> @ y<unk> @ s , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ ol<unk> @ l<unk> @ s , die die Gr<unk> @ öß<unk> @ e der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:26:40,074 - INFO - joeynmt.training - Example #1
2025-05-26 22:26:40,074 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:26:40,074 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:26:40,074 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ff@@', '<unk>', '@', 'en@@', '<unk>', '@', 'schaft', 'des', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ff@@', '<unk>', '@', 'e', 'des', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-26 22:26:40,074 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:26:40,074 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:26:40,074 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ elle Problem , weil es nicht die Di<unk> @ ff<unk> @ en<unk> @ schaft des E<unk> @ is , weil es nicht die Di<unk> @ ff<unk> @ e des E<unk> @ is zeigt .
2025-05-26 22:26:40,074 - INFO - joeynmt.training - Example #2
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'einer', 'M@@', '<unk>', '@', 'eer@@', '<unk>', '@', 'e', ',', 'die', 'wir', 'uns', 'l@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'sen', ',', 'uns', 'die', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'at@@', '<unk>', '@', 'isch', '.', '</s>']
2025-05-26 22:26:40,075 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:26:40,075 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:26:40,075 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in einer M<unk> @ eer<unk> @ e , die wir uns l<unk> @ ö<unk> @ sen , uns die G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ at<unk> @ isch .
2025-05-26 22:26:40,075 - INFO - joeynmt.training - Example #3
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:26:40,075 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:26:40,075 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:26:40,075 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 22:26:40,075 - INFO - joeynmt.training - Example #4
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:26:40,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'den', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 22:26:40,076 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:26:40,076 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:26:40,076 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigen , ist eine Ver<unk> @ si<unk> @ on von den letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-26 22:27:21,532 - INFO - joeynmt.training - Epoch   5, Step:    13600, Batch Loss:     0.989912, Batch Acc: 0.727755, Tokens per Sec:     4625, Lr: 0.000300
2025-05-26 22:28:05,974 - INFO - joeynmt.training - Epoch   5, Step:    13700, Batch Loss:     0.929041, Batch Acc: 0.726261, Tokens per Sec:     4346, Lr: 0.000300
2025-05-26 22:28:49,510 - INFO - joeynmt.training - Epoch   5, Step:    13800, Batch Loss:     0.936533, Batch Acc: 0.725397, Tokens per Sec:     4385, Lr: 0.000300
2025-05-26 22:29:29,628 - INFO - joeynmt.training - Epoch   5, Step:    13900, Batch Loss:     0.950722, Batch Acc: 0.731143, Tokens per Sec:     4617, Lr: 0.000300
2025-05-26 22:30:11,387 - INFO - joeynmt.training - Epoch   5, Step:    14000, Batch Loss:     0.947831, Batch Acc: 0.730557, Tokens per Sec:     4542, Lr: 0.000300
2025-05-26 22:30:11,389 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:30:11,389 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:34:09,702 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.79, acc:   0.71, generation: 238.2983[sec], evaluation: 0.0000[sec]
2025-05-26 22:34:09,708 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:34:09,827 - INFO - joeynmt.helpers - delete models/bpe_2k_model/11500.ckpt
2025-05-26 22:34:09,832 - INFO - joeynmt.training - Example #0
2025-05-26 22:34:09,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:34:09,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:34:09,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahre', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'k@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'des', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:34:09,832 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:34:09,832 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:34:09,832 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or V<unk> @ or<unk> @ ig Jahre habe ich diese zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ L<unk> @ k<unk> @ at<unk> @ ast<unk> @ sk<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ des , die die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:34:09,832 - INFO - joeynmt.training - Example #1
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ä@@', '<unk>', '@', 'gt', 'das', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', '.', '</s>']
2025-05-26 22:34:09,833 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:34:09,833 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:34:09,833 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ä<unk> @ gt das ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem .
2025-05-26 22:34:09,833 - INFO - joeynmt.training - Example #2
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'uns', 'l@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'h@@', '<unk>', '@', 'n@@', '<unk>', '@', 'lich', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 22:34:09,833 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:34:09,833 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:34:09,833 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ n , die wir uns l<unk> @ ö<unk> @ h<unk> @ n<unk> @ lich kl<unk> @ im<unk> @ a .
2025-05-26 22:34:09,833 - INFO - joeynmt.training - Example #3
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:34:09,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:34:09,834 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:34:09,834 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:34:09,834 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 22:34:09,834 - INFO - joeynmt.training - Example #4
2025-05-26 22:34:09,834 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:34:09,834 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:34:09,834 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigt', ',', 'ist', 'ein', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'es', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-26 22:34:09,834 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:34:09,834 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:34:09,834 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zeigt , ist ein Ver<unk> @ si<unk> @ on von dem , was es die letzten 2<unk> @ 5 Jahren pass<unk> @ ierte .
2025-05-26 22:34:53,850 - INFO - joeynmt.training - Epoch   5, Step:    14100, Batch Loss:     1.000873, Batch Acc: 0.726746, Tokens per Sec:     4442, Lr: 0.000300
2025-05-26 22:35:38,649 - INFO - joeynmt.training - Epoch   5, Step:    14200, Batch Loss:     0.918809, Batch Acc: 0.729738, Tokens per Sec:     4336, Lr: 0.000300
2025-05-26 22:36:21,963 - INFO - joeynmt.training - Epoch   5, Step:    14300, Batch Loss:     0.887422, Batch Acc: 0.730793, Tokens per Sec:     4348, Lr: 0.000300
2025-05-26 22:37:04,341 - INFO - joeynmt.training - Epoch   5, Step:    14400, Batch Loss:     0.932313, Batch Acc: 0.729557, Tokens per Sec:     4582, Lr: 0.000300
2025-05-26 22:37:49,110 - INFO - joeynmt.training - Epoch   5, Step:    14500, Batch Loss:     0.892886, Batch Acc: 0.728451, Tokens per Sec:     4366, Lr: 0.000300
2025-05-26 22:37:49,111 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:37:49,111 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:42:44,439 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 295.3118[sec], evaluation: 0.0000[sec]
2025-05-26 22:42:44,443 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:42:44,566 - INFO - joeynmt.helpers - delete models/bpe_2k_model/12000.ckpt
2025-05-26 22:42:44,569 - INFO - joeynmt.training - Example #0
2025-05-26 22:42:44,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:42:44,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:42:44,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'ich', 'diese', 'bei@@', '<unk>', '@', 'den', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'L@@', '<unk>', '@', 'u@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:42:44,570 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:42:44,570 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:42:44,570 - INFO - joeynmt.training - 	Hypothesis: Und ich habe diese zwei Di<unk> @ as sehen , die ich diese bei<unk> @ den Di<unk> @ as sehen , dass die P<unk> @ o<unk> @ L<unk> @ k<unk> @ a<unk> @ p , die die L<unk> @ u<unk> @ sk<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ k<unk> @ a<unk> @ p des V<unk> @ o<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:42:44,570 - INFO - joeynmt.training - Example #1
2025-05-26 22:42:44,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:42:44,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:42:44,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'en@@', '<unk>', '@', 'st@@', '<unk>', '@', 'lei@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ung', 'des', 'E@@', '<unk>', '@', 'is', 'ist', '.', '</s>']
2025-05-26 22:42:44,570 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:42:44,570 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:42:44,570 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ en<unk> @ st<unk> @ lei<unk> @ st<unk> @ ung des E<unk> @ is ist .
2025-05-26 22:42:44,570 - INFO - joeynmt.training - Example #2
2025-05-26 22:42:44,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:42:44,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:42:44,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ige', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'k@@', '<unk>', '@', 'let@@', '<unk>', '@', 't', '.', '</s>']
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ al<unk> @ t<unk> @ ige S<unk> @ in<unk> @ ne , die wir uns gl<unk> @ ob<unk> @ al k<unk> @ let<unk> @ t .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - Example #3
2025-05-26 22:42:44,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:42:44,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:42:44,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Sie', 's@@', '<unk>', '@', 'it@@', '<unk>', '@', 'zen', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Hypothesis: Sie s<unk> @ it<unk> @ zen in den S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ ft in den S<unk> @ omm<unk> @ er .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - Example #4
2025-05-26 22:42:44,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:42:44,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:42:44,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'es', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:42:44,571 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen , ist eine Ver<unk> @ si<unk> @ on von dem , was es die letzten 2<unk> @ 5 Jahre pass<unk> @ ierte .
2025-05-26 22:43:29,603 - INFO - joeynmt.training - Epoch   5, Step:    14600, Batch Loss:     1.001760, Batch Acc: 0.727534, Tokens per Sec:     4358, Lr: 0.000300
2025-05-26 22:44:13,952 - INFO - joeynmt.training - Epoch   5, Step:    14700, Batch Loss:     0.899153, Batch Acc: 0.730498, Tokens per Sec:     4398, Lr: 0.000300
2025-05-26 22:44:57,769 - INFO - joeynmt.training - Epoch   5, Step:    14800, Batch Loss:     0.970375, Batch Acc: 0.728562, Tokens per Sec:     4351, Lr: 0.000300
2025-05-26 22:45:38,299 - INFO - joeynmt.training - Epoch   5, Step:    14900, Batch Loss:     0.924359, Batch Acc: 0.728606, Tokens per Sec:     4687, Lr: 0.000300
2025-05-26 22:46:24,784 - INFO - joeynmt.training - Epoch   5, Step:    15000, Batch Loss:     0.942785, Batch Acc: 0.728675, Tokens per Sec:     4272, Lr: 0.000300
2025-05-26 22:46:24,785 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:46:24,785 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:50:15,797 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.76, acc:   0.71, generation: 230.9967[sec], evaluation: 0.0000[sec]
2025-05-26 22:50:15,803 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:50:15,938 - INFO - joeynmt.helpers - delete models/bpe_2k_model/12500.ckpt
2025-05-26 22:50:15,941 - INFO - joeynmt.training - Example #0
2025-05-26 22:50:15,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:50:15,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:50:15,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'ich', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'L@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:50:15,941 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:50:15,941 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:50:15,941 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ as sehen , die ich zwei Di<unk> @ as sehen , um zu zeigen , dass die P<unk> @ o<unk> @ L<unk> @ sk<unk> @ a<unk> @ p , die die die P<unk> @ o<unk> @ L<unk> @ sk<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:50:15,941 - INFO - joeynmt.training - Example #1
2025-05-26 22:50:15,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:50:15,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:50:15,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Ge@@', '<unk>', '@', 'mein@@', '<unk>', '@', 'de', 'des', 'dieses', 'The@@', '<unk>', '@', 'ma', ',', 'das', 'ist', 'das', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'it', 'des', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's', 'nicht', 'der', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 22:50:15,942 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:50:15,942 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:50:15,942 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Ge<unk> @ mein<unk> @ de des dieses The<unk> @ ma , das ist das Problem , weil es nicht die D<unk> @ am<unk> @ it des E<unk> @ is<unk> @ s nicht der E<unk> @ is .
2025-05-26 22:50:15,942 - INFO - joeynmt.training - Example #2
2025-05-26 22:50:15,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:50:15,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:50:15,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ige', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'ale', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del', '.', '</s>']
2025-05-26 22:50:15,942 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:50:15,942 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:50:15,942 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ al<unk> @ t<unk> @ ige S<unk> @ in<unk> @ n , die wir uns gl<unk> @ ob<unk> @ ale K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del .
2025-05-26 22:50:15,942 - INFO - joeynmt.training - Example #3
2025-05-26 22:50:15,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:50:15,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:50:15,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:50:15,943 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:50:15,943 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:50:15,943 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ om<unk> @ er .
2025-05-26 22:50:15,943 - INFO - joeynmt.training - Example #4
2025-05-26 22:50:15,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:50:15,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:50:15,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'passiert', '.', '</s>']
2025-05-26 22:50:15,943 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:50:15,943 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:50:15,943 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen Ihnen zeigen werde , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre passiert .
2025-05-26 22:50:57,701 - INFO - joeynmt.training - Epoch   5, Step:    15100, Batch Loss:     0.944623, Batch Acc: 0.728694, Tokens per Sec:     4548, Lr: 0.000300
2025-05-26 22:51:39,390 - INFO - joeynmt.training - Epoch   5, Step:    15200, Batch Loss:     0.994716, Batch Acc: 0.728766, Tokens per Sec:     4562, Lr: 0.000300
2025-05-26 22:52:25,676 - INFO - joeynmt.training - Epoch   5, Step:    15300, Batch Loss:     0.977075, Batch Acc: 0.728682, Tokens per Sec:     4148, Lr: 0.000300
2025-05-26 22:53:09,688 - INFO - joeynmt.training - Epoch   5, Step:    15400, Batch Loss:     0.954610, Batch Acc: 0.730917, Tokens per Sec:     4273, Lr: 0.000300
2025-05-26 22:53:54,912 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     0.919723, Batch Acc: 0.728975, Tokens per Sec:     4242, Lr: 0.000300
2025-05-26 22:53:54,914 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 22:53:54,914 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 22:58:35,044 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 280.1192[sec], evaluation: 0.0000[sec]
2025-05-26 22:58:35,049 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 22:58:35,135 - INFO - joeynmt.helpers - delete models/bpe_2k_model/13000.ckpt
2025-05-26 22:58:35,138 - INFO - joeynmt.training - Example #0
2025-05-26 22:58:35,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 22:58:35,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 22:58:35,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'diesem', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'lei@@', '<unk>', '@', 'ch@@', '<unk>', '@', 'en@@', '<unk>', '@', '-@@', '<unk>', '@', 'L@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'etwa', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 22:58:35,138 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 22:58:35,138 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 22:58:35,138 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or diesem Jahr habe ich diese zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ lei<unk> @ ch<unk> @ en<unk> @ -<unk> @ L<unk> @ sk<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e der U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahren , etwa die Gr<unk> @ öß<unk> @ e der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 22:58:35,138 - INFO - joeynmt.training - Example #1
2025-05-26 22:58:35,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 22:58:35,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'zt', 'das', 'sch@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'n', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'nicht', 'der', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ zt das sch<unk> @ ö<unk> @ n dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ ck<unk> @ er nicht der Di<unk> @ ck<unk> @ er des E<unk> @ is .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - Example #2
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'h@@', '<unk>', '@', 'är@@', '<unk>', '@', 'e', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ n , die wir uns gl<unk> @ ob<unk> @ al kl<unk> @ op<unk> @ p<unk> @ h<unk> @ är<unk> @ e K<unk> @ li<unk> @ ma<unk> @ sy<unk> @ stem .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - Example #3
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 22:58:35,139 - INFO - joeynmt.training - Example #4
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 22:58:35,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 22:58:35,139 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 22:58:35,140 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 22:58:35,140 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen werde , ist eine Ver<unk> @ si<unk> @ on von 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-26 22:59:10,780 - INFO - joeynmt.training - Epoch   5, Step:    15600, Batch Loss:     0.915696, Batch Acc: 0.729343, Tokens per Sec:     5333, Lr: 0.000300
2025-05-26 22:59:19,833 - INFO - joeynmt.training - Epoch   5: total training loss 2931.57
2025-05-26 22:59:19,834 - INFO - joeynmt.training - EPOCH 6
2025-05-26 22:59:45,249 - INFO - joeynmt.training - Epoch   6, Step:    15700, Batch Loss:     0.840703, Batch Acc: 0.737174, Tokens per Sec:     5629, Lr: 0.000300
2025-05-26 23:00:21,231 - INFO - joeynmt.training - Epoch   6, Step:    15800, Batch Loss:     0.892483, Batch Acc: 0.738218, Tokens per Sec:     5297, Lr: 0.000300
2025-05-26 23:00:56,435 - INFO - joeynmt.training - Epoch   6, Step:    15900, Batch Loss:     0.947082, Batch Acc: 0.736999, Tokens per Sec:     5433, Lr: 0.000300
2025-05-26 23:01:30,848 - INFO - joeynmt.training - Epoch   6, Step:    16000, Batch Loss:     0.975543, Batch Acc: 0.736034, Tokens per Sec:     5532, Lr: 0.000300
2025-05-26 23:01:30,849 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:01:30,849 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:04:59,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.76, acc:   0.71, generation: 208.8562[sec], evaluation: 0.0000[sec]
2025-05-26 23:04:59,795 - INFO - joeynmt.helpers - delete models/bpe_2k_model/13500.ckpt
2025-05-26 23:04:59,802 - INFO - joeynmt.training - Example #0
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahren', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'i@@', '<unk>', '@', 'x@@', '<unk>', '@', 'i@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahren', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-26 23:04:59,802 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:04:59,802 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:04:59,802 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahren habe ich diese zwei Di<unk> @ as zeigen , die die P<unk> @ o<unk> @ i<unk> @ x<unk> @ i<unk> @ sk<unk> @ a<unk> @ p , die die letzten drei Millionen Jahren un<unk> @ gef<unk> @ äh<unk> @ r drei Millionen Jahren un<unk> @ gef<unk> @ äh<unk> @ r die Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-26 23:04:59,802 - INFO - joeynmt.training - Example #1
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'zt', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', 'der', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 23:04:59,802 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:04:59,802 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:04:59,802 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ zt wirklich die ern<unk> @ st dieser spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem der E<unk> @ is .
2025-05-26 23:04:59,802 - INFO - joeynmt.training - Example #2
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:04:59,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'te', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'uns', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al@@', '<unk>', '@', 'er', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del', '.', '</s>']
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ al<unk> @ t<unk> @ ig<unk> @ te S<unk> @ in<unk> @ n , die uns uns gl<unk> @ ob<unk> @ al<unk> @ er K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - Example #3
2025-05-26 23:04:59,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:04:59,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:04:59,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ om<unk> @ mer<unk> @ n .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - Example #4
2025-05-26 23:04:59,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:04:59,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:04:59,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'der', 'ich', 'zei@@', '<unk>', '@', 'ge', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:04:59,803 - INFO - joeynmt.training - 	Hypothesis: Und der näch<unk> @ ste Di<unk> @ a , der ich zei<unk> @ ge ist eine Ver<unk> @ si<unk> @ on von der letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-26 23:05:33,981 - INFO - joeynmt.training - Epoch   6, Step:    16100, Batch Loss:     0.941766, Batch Acc: 0.739983, Tokens per Sec:     5564, Lr: 0.000300
2025-05-26 23:06:10,975 - INFO - joeynmt.training - Epoch   6, Step:    16200, Batch Loss:     0.924140, Batch Acc: 0.737612, Tokens per Sec:     5193, Lr: 0.000300
2025-05-26 23:06:46,284 - INFO - joeynmt.training - Epoch   6, Step:    16300, Batch Loss:     0.939442, Batch Acc: 0.736988, Tokens per Sec:     5411, Lr: 0.000300
2025-05-26 23:07:21,977 - INFO - joeynmt.training - Epoch   6, Step:    16400, Batch Loss:     0.854984, Batch Acc: 0.737577, Tokens per Sec:     5381, Lr: 0.000300
2025-05-26 23:07:56,242 - INFO - joeynmt.training - Epoch   6, Step:    16500, Batch Loss:     0.956353, Batch Acc: 0.738197, Tokens per Sec:     5628, Lr: 0.000300
2025-05-26 23:07:56,243 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:07:56,243 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:11:37,499 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.73, acc:   0.71, generation: 221.2455[sec], evaluation: 0.0000[sec]
2025-05-26 23:11:37,504 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 23:11:37,586 - INFO - joeynmt.helpers - delete models/bpe_2k_model/14000.ckpt
2025-05-26 23:11:37,588 - INFO - joeynmt.training - Example #0
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'Jahr', 'lie@@', '<unk>', '@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'i@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ber@@', '<unk>', '@', 's', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 23:11:37,588 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:11:37,588 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:11:37,588 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or Jahr lie<unk> @ ß ich diese zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ i<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ ber<unk> @ s , die die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 23:11:37,588 - INFO - joeynmt.training - Example #1
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'e', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 23:11:37,588 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:11:37,588 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:11:37,588 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieser spe<unk> @ zi<unk> @ elle Problem , weil es nicht die D<unk> @ am<unk> @ e des E<unk> @ is .
2025-05-26 23:11:37,588 - INFO - joeynmt.training - Example #2
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:11:37,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ige', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'es', '.', '</s>']
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ is auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ al<unk> @ t<unk> @ ige S<unk> @ in<unk> @ n des K<unk> @ li<unk> @ ma<unk> @ sch<unk> @ es .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - Example #3
2025-05-26 23:11:37,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:11:37,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:11:37,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - Example #4
2025-05-26 23:11:37,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:11:37,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:11:37,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'habe', ',', 'ist', 'eine', 'S@@', '<unk>', '@', 'el@@', '<unk>', '@', 'b@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'gesch@@', '<unk>', '@', 'ie@@', '<unk>', '@', 'ht', '.', '</s>']
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:11:37,589 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen habe , ist eine S<unk> @ el<unk> @ b<unk> @ st<unk> @ ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre gesch<unk> @ ie<unk> @ ht .
2025-05-26 23:12:12,540 - INFO - joeynmt.training - Epoch   6, Step:    16600, Batch Loss:     0.939106, Batch Acc: 0.739415, Tokens per Sec:     5451, Lr: 0.000300
2025-05-26 23:12:44,407 - INFO - joeynmt.training - Epoch   6, Step:    16700, Batch Loss:     0.864677, Batch Acc: 0.737389, Tokens per Sec:     5937, Lr: 0.000300
2025-05-26 23:13:20,489 - INFO - joeynmt.training - Epoch   6, Step:    16800, Batch Loss:     0.838479, Batch Acc: 0.736015, Tokens per Sec:     5271, Lr: 0.000300
2025-05-26 23:13:53,922 - INFO - joeynmt.training - Epoch   6, Step:    16900, Batch Loss:     0.880632, Batch Acc: 0.738822, Tokens per Sec:     5719, Lr: 0.000300
2025-05-26 23:14:31,803 - INFO - joeynmt.training - Epoch   6, Step:    17000, Batch Loss:     0.932558, Batch Acc: 0.735970, Tokens per Sec:     5171, Lr: 0.000300
2025-05-26 23:14:31,804 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:14:31,804 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:17:59,623 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 207.8087[sec], evaluation: 0.0000[sec]
2025-05-26 23:17:59,625 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 23:17:59,701 - INFO - joeynmt.helpers - delete models/bpe_2k_model/14500.ckpt
2025-05-26 23:17:59,706 - INFO - joeynmt.training - Example #0
2025-05-26 23:17:59,706 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:17:59,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:17:59,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'i@@', '<unk>', '@', 'en@@', '<unk>', '@', '-@@', '<unk>', '@', 'Ja@@', '<unk>', '@', 'hr@@', '<unk>', '@', 'es', 'zei@@', '<unk>', '@', 'gte', ',', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'i@@', '<unk>', '@', 'en@@', '<unk>', '@', '-@@', '<unk>', '@', 'T@@', '<unk>', '@', 'eil@@', '<unk>', '@', 'ung', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-26 23:17:59,706 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:17:59,706 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:17:59,706 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ i<unk> @ en<unk> @ -<unk> @ Ja<unk> @ hr<unk> @ es zei<unk> @ gte , die die die P<unk> @ o<unk> @ i<unk> @ en<unk> @ -<unk> @ T<unk> @ eil<unk> @ ung der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-26 23:17:59,706 - INFO - joeynmt.training - Example #1
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ä@@', '<unk>', '@', 'ß', 'dieses', 'The@@', '<unk>', '@', 'ma', ',', 'das', 'ist', 'das', 'ern@@', '<unk>', '@', 'st', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Hypothesis: Aber das Unter<unk> @ sch<unk> @ ä<unk> @ ß dieses The<unk> @ ma , das ist das ern<unk> @ st dieser spe<unk> @ zi<unk> @ elle Problem , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che des E<unk> @ is .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - Example #2
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ige', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', 'von', 'uns', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ al<unk> @ t<unk> @ ige S<unk> @ in<unk> @ ne von uns G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ ma<unk> @ sy<unk> @ stem .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - Example #3
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'La@@', '<unk>', '@', 'se', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - 	Hypothesis: Es ist in der La<unk> @ se und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 23:17:59,707 - INFO - joeynmt.training - Example #4
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:17:59,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'gesch@@', '<unk>', '@', 'ie@@', '<unk>', '@', 'ht', '.', '</s>']
2025-05-26 23:17:59,708 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:17:59,708 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:17:59,708 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre gesch<unk> @ ie<unk> @ ht .
2025-05-26 23:18:33,899 - INFO - joeynmt.training - Epoch   6, Step:    17100, Batch Loss:     0.891754, Batch Acc: 0.737006, Tokens per Sec:     5575, Lr: 0.000300
2025-05-26 23:19:10,289 - INFO - joeynmt.training - Epoch   6, Step:    17200, Batch Loss:     0.878153, Batch Acc: 0.739647, Tokens per Sec:     5309, Lr: 0.000300
2025-05-26 23:19:44,072 - INFO - joeynmt.training - Epoch   6, Step:    17300, Batch Loss:     0.883495, Batch Acc: 0.737141, Tokens per Sec:     5612, Lr: 0.000300
2025-05-26 23:20:20,192 - INFO - joeynmt.training - Epoch   6, Step:    17400, Batch Loss:     0.902120, Batch Acc: 0.736915, Tokens per Sec:     5356, Lr: 0.000300
2025-05-26 23:20:55,387 - INFO - joeynmt.training - Epoch   6, Step:    17500, Batch Loss:     0.910770, Batch Acc: 0.735618, Tokens per Sec:     5511, Lr: 0.000300
2025-05-26 23:20:55,388 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:20:55,388 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:24:33,688 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 218.2890[sec], evaluation: 0.0000[sec]
2025-05-26 23:24:33,691 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 23:24:33,773 - INFO - joeynmt.helpers - delete models/bpe_2k_model/15000.ckpt
2025-05-26 23:24:33,778 - INFO - joeynmt.training - Example #0
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'den', 'letzten', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'die', 'bei@@', '<unk>', '@', 'den', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'die', 'die', 'L@@', '<unk>', '@', 'i@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'von', 'dem', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'k@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-26 23:24:33,779 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:24:33,779 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:24:33,779 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or den letzten Jahr habe ich diese zwei Di<unk> @ as sehen , die die bei<unk> @ den Di<unk> @ as sehen , die die die L<unk> @ i<unk> @ sk<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre , die die die letzten drei Millionen Jahre , die die die letzten drei Millionen Jahre , die die Gr<unk> @ öß<unk> @ e von dem V<unk> @ o<unk> @ k<unk> @ r<unk> @ ö<unk> @ m<unk> @ pen .
2025-05-26 23:24:33,779 - INFO - joeynmt.training - Example #1
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', ',', '</s>']
2025-05-26 23:24:33,779 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:24:33,779 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:24:33,779 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che ,
2025-05-26 23:24:33,779 - INFO - joeynmt.training - Example #2
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:24:33,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'e', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'uns', 'von', 'unser@@', '<unk>', '@', 'em', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'it@@', '<unk>', '@', 'ä@@', '<unk>', '@', 'ten', 'von', 'uns', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'it@@', '<unk>', '@', 'ä@@', '<unk>', '@', 'ten', '.', '</s>']
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ e auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ n , die wir uns von unser<unk> @ em G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ it<unk> @ ä<unk> @ ten von uns G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ it<unk> @ ä<unk> @ ten .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - Example #3
2025-05-26 23:24:33,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:24:33,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:24:33,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - Example #4
2025-05-26 23:24:33,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:24:33,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:24:33,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigt', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'gesch@@', '<unk>', '@', 'n@@', '<unk>', '@', 'itten', 'ist', '.', '</s>']
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:24:33,780 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigt , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren gesch<unk> @ n<unk> @ itten ist .
2025-05-26 23:25:06,152 - INFO - joeynmt.training - Epoch   6, Step:    17600, Batch Loss:     0.900385, Batch Acc: 0.737232, Tokens per Sec:     5934, Lr: 0.000300
2025-05-26 23:25:40,374 - INFO - joeynmt.training - Epoch   6, Step:    17700, Batch Loss:     0.930326, Batch Acc: 0.737412, Tokens per Sec:     5618, Lr: 0.000300
2025-05-26 23:26:13,984 - INFO - joeynmt.training - Epoch   6, Step:    17800, Batch Loss:     1.041900, Batch Acc: 0.737046, Tokens per Sec:     5831, Lr: 0.000300
2025-05-26 23:26:48,619 - INFO - joeynmt.training - Epoch   6, Step:    17900, Batch Loss:     0.807912, Batch Acc: 0.736894, Tokens per Sec:     5512, Lr: 0.000300
2025-05-26 23:27:21,598 - INFO - joeynmt.training - Epoch   6, Step:    18000, Batch Loss:     0.931184, Batch Acc: 0.736764, Tokens per Sec:     5811, Lr: 0.000300
2025-05-26 23:27:21,599 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:27:21,599 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:30:38,255 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 196.6457[sec], evaluation: 0.0000[sec]
2025-05-26 23:30:38,345 - INFO - joeynmt.helpers - delete models/bpe_2k_model/16000.ckpt
2025-05-26 23:30:38,351 - INFO - joeynmt.training - Example #0
2025-05-26 23:30:38,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:30:38,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:30:38,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', ',', 'die', 'die', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'i@@', '<unk>', '@', 'k@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'rop@@', '<unk>', '@', 'he', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'etwa', 'drei', 'Millionen', 'Jahren', ',', 'als', 'c@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 23:30:38,351 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:30:38,351 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:30:38,351 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ as sehen , die die zwei Di<unk> @ as , die die die P<unk> @ o<unk> @ i<unk> @ k<unk> @ at<unk> @ ast<unk> @ rop<unk> @ he , die die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahren etwa drei Millionen Jahren , als c<unk> @ a .
2025-05-26 23:30:38,351 - INFO - joeynmt.training - Example #1
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'The@@', '<unk>', '@', 'ma', ',', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-26 23:30:38,352 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:30:38,352 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:30:38,352 - INFO - joeynmt.training - 	Hypothesis: Aber das The<unk> @ ma , das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem des E<unk> @ is .
2025-05-26 23:30:38,352 - INFO - joeynmt.training - Example #2
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ser', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 23:30:38,352 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:30:38,352 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:30:38,352 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ ser K<unk> @ l<unk> @ im<unk> @ a .
2025-05-26 23:30:38,352 - INFO - joeynmt.training - Example #3
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:30:38,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:30:38,353 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:30:38,353 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:30:38,353 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-26 23:30:38,353 - INFO - joeynmt.training - Example #4
2025-05-26 23:30:38,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:30:38,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:30:38,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-26 23:30:38,353 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:30:38,353 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:30:38,353 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge ist eine Ver<unk> @ si<unk> @ on von Ver<unk> @ si<unk> @ on von 2<unk> @ 5 Jahren .
2025-05-26 23:31:15,267 - INFO - joeynmt.training - Epoch   6, Step:    18100, Batch Loss:     0.955691, Batch Acc: 0.738804, Tokens per Sec:     5214, Lr: 0.000300
2025-05-26 23:31:51,717 - INFO - joeynmt.training - Epoch   6, Step:    18200, Batch Loss:     0.864197, Batch Acc: 0.740377, Tokens per Sec:     5353, Lr: 0.000300
2025-05-26 23:32:28,441 - INFO - joeynmt.training - Epoch   6, Step:    18300, Batch Loss:     0.861865, Batch Acc: 0.736531, Tokens per Sec:     5268, Lr: 0.000300
2025-05-26 23:33:03,798 - INFO - joeynmt.training - Epoch   6, Step:    18400, Batch Loss:     0.846448, Batch Acc: 0.736693, Tokens per Sec:     5551, Lr: 0.000300
2025-05-26 23:33:40,548 - INFO - joeynmt.training - Epoch   6, Step:    18500, Batch Loss:     0.894659, Batch Acc: 0.735263, Tokens per Sec:     5236, Lr: 0.000300
2025-05-26 23:33:40,548 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:33:40,548 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:38:20,056 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.70, acc:   0.71, generation: 279.4968[sec], evaluation: 0.0000[sec]
2025-05-26 23:38:20,058 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 23:38:20,141 - INFO - joeynmt.helpers - delete models/bpe_2k_model/15500.ckpt
2025-05-26 23:38:20,144 - INFO - joeynmt.training - Example #0
2025-05-26 23:38:20,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahren', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'os@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'ide@@', '<unk>', '@', 'o@@', '<unk>', '@', '-@@', '<unk>', '@', 'C@@', '<unk>', '@', 'o@@', '<unk>', '@', '-@@', '<unk>', '@', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'Ver@@', '<unk>', '@', 'ein@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ten', 'St@@', '<unk>', '@', 'aa@@', '<unk>', '@', 'ten', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahren zei<unk> @ ge ich diese zwei Di<unk> @ as sehen , dass die M<unk> @ os<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ ide<unk> @ o<unk> @ -<unk> @ C<unk> @ o<unk> @ -<unk> @ S<unk> @ in<unk> @ n , mit 4<unk> @ 0 % der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % der Ver<unk> @ ein<unk> @ ig<unk> @ ten St<unk> @ aa<unk> @ ten , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - Example #1
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'lich', 'der', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'lichen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das sch<unk> @ ät<unk> @ z<unk> @ lich der sch<unk> @ ät<unk> @ z<unk> @ lichen Problem , weil es nicht die E<unk> @ is des E<unk> @ is des E<unk> @ is , weil es nicht die E<unk> @ is zeigt .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - Example #2
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'em', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del@@', '<unk>', '@', 's', '.', '</s>']
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ em S<unk> @ in<unk> @ n des K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del<unk> @ s .
2025-05-26 23:38:20,145 - INFO - joeynmt.training - Example #3
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:38:20,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:38:20,146 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:38:20,146 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:38:20,146 - INFO - joeynmt.training - 	Hypothesis: Es ist in der S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-26 23:38:20,146 - INFO - joeynmt.training - Example #4
2025-05-26 23:38:20,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:38:20,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:38:20,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zeigen', 'werde', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'passiert', 'ist', '.', '</s>']
2025-05-26 23:38:20,146 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:38:20,146 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:38:20,146 - INFO - joeynmt.training - 	Hypothesis: Der näch<unk> @ ste Di<unk> @ a , die ich zeigen werde , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre passiert ist .
2025-05-26 23:38:55,642 - INFO - joeynmt.training - Epoch   6, Step:    18600, Batch Loss:     0.965249, Batch Acc: 0.738795, Tokens per Sec:     5400, Lr: 0.000300
2025-05-26 23:39:31,476 - INFO - joeynmt.training - Epoch   6, Step:    18700, Batch Loss:     0.902710, Batch Acc: 0.738791, Tokens per Sec:     5405, Lr: 0.000300
2025-05-26 23:39:48,648 - INFO - joeynmt.training - Epoch   6: total training loss 2830.55
2025-05-26 23:39:48,650 - INFO - joeynmt.training - EPOCH 7
2025-05-26 23:40:08,775 - INFO - joeynmt.training - Epoch   7, Step:    18800, Batch Loss:     0.875122, Batch Acc: 0.752883, Tokens per Sec:     4813, Lr: 0.000300
2025-05-26 23:40:42,543 - INFO - joeynmt.training - Epoch   7, Step:    18900, Batch Loss:     0.926145, Batch Acc: 0.748267, Tokens per Sec:     5705, Lr: 0.000300
2025-05-26 23:41:18,509 - INFO - joeynmt.training - Epoch   7, Step:    19000, Batch Loss:     0.858875, Batch Acc: 0.747368, Tokens per Sec:     5348, Lr: 0.000300
2025-05-26 23:41:18,511 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:41:18,511 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:44:40,296 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 201.7745[sec], evaluation: 0.0000[sec]
2025-05-26 23:44:40,380 - INFO - joeynmt.helpers - delete models/bpe_2k_model/16500.ckpt
2025-05-26 23:44:40,386 - INFO - joeynmt.training - Example #0
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 's', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 's@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'etwa', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'st@@', '<unk>', '@', 's', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 23:44:40,386 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:44:40,386 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:44:40,386 - INFO - joeynmt.training - 	Hypothesis: Und ich habe diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ oo<unk> @ l<unk> @ s zeigen , dass die M<unk> @ oo<unk> @ l<unk> @ s<unk> @ k<unk> @ a<unk> @ p , die die letzten drei Millionen Jahren etwa drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ st<unk> @ s der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 23:44:40,386 - INFO - joeynmt.training - Example #1
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'zt', 'die', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'te', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'als', 'sehen', '.', '</s>']
2025-05-26 23:44:40,386 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:44:40,386 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:44:40,386 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ zt die sch<unk> @ ät<unk> @ z<unk> @ te dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die D<unk> @ am<unk> @ als sehen .
2025-05-26 23:44:40,386 - INFO - joeynmt.training - Example #2
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:44:40,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'einer', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ige', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', 'von', 'unser@@', '<unk>', '@', 'em', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in einer gew<unk> @ al<unk> @ t<unk> @ ige S<unk> @ in<unk> @ ne von unser<unk> @ em G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ a .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - Example #3
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Hypothesis: Es hat in der S<unk> @ omm<unk> @ er und K<unk> @ ri<unk> @ m<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - Example #4
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:44:40,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:44:40,387 - INFO - joeynmt.training - 	Hypothesis: Und der näch<unk> @ ste Di<unk> @ a , die ich zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von der letzten 2<unk> @ 5 Jahren passiert ist .
2025-05-26 23:45:15,130 - INFO - joeynmt.training - Epoch   7, Step:    19100, Batch Loss:     0.914236, Batch Acc: 0.747290, Tokens per Sec:     5420, Lr: 0.000300
2025-05-26 23:45:47,750 - INFO - joeynmt.training - Epoch   7, Step:    19200, Batch Loss:     0.829815, Batch Acc: 0.744861, Tokens per Sec:     5756, Lr: 0.000300
2025-05-26 23:46:22,538 - INFO - joeynmt.training - Epoch   7, Step:    19300, Batch Loss:     0.847925, Batch Acc: 0.745978, Tokens per Sec:     5573, Lr: 0.000300
2025-05-26 23:46:58,980 - INFO - joeynmt.training - Epoch   7, Step:    19400, Batch Loss:     0.932900, Batch Acc: 0.742318, Tokens per Sec:     5316, Lr: 0.000300
2025-05-26 23:47:33,830 - INFO - joeynmt.training - Epoch   7, Step:    19500, Batch Loss:     0.956445, Batch Acc: 0.744349, Tokens per Sec:     5431, Lr: 0.000300
2025-05-26 23:47:33,831 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:47:33,831 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:51:17,294 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.70, acc:   0.71, generation: 223.4525[sec], evaluation: 0.0000[sec]
2025-05-26 23:51:17,383 - INFO - joeynmt.helpers - delete models/bpe_2k_model/17000.ckpt
2025-05-26 23:51:17,384 - INFO - joeynmt.training - Example #0
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ier@@', '<unk>', '@', 'ter', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ho@@', '<unk>', '@', 'de', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ff@@', '<unk>', '@', 's', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'etwa', 'etwa', 'etwa', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'sten', '.', '</s>']
2025-05-26 23:51:17,384 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:51:17,384 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:51:17,384 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ i<unk> @ ent<unk> @ ier<unk> @ ter ich diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ et<unk> @ ho<unk> @ de , die die letzten drei Millionen Jahre , die Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ ff<unk> @ s , die die letzten drei Millionen Jahren etwa etwa etwa 4<unk> @ 0 Prozent der Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ sten .
2025-05-26 23:51:17,384 - INFO - joeynmt.training - Example #1
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'isch@@', '<unk>', '@', 'es', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'es', 'nicht', 'sehen', '.', '</s>']
2025-05-26 23:51:17,384 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:51:17,384 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:51:17,384 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ isch<unk> @ es Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ sch<unk> @ i<unk> @ ck<unk> @ es nicht sehen .
2025-05-26 23:51:17,384 - INFO - joeynmt.training - Example #2
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:51:17,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', 'des', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ ne , die K<unk> @ l<unk> @ im<unk> @ a des K<unk> @ l<unk> @ im<unk> @ a .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - Example #3
2025-05-26 23:51:17,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:51:17,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:51:17,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - Example #4
2025-05-26 23:51:17,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:51:17,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:51:17,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zei@@', '<unk>', '@', 'ge', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'gesch@@', '<unk>', '@', 'n@@', '<unk>', '@', 'itten', '.', '</s>']
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:51:17,385 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zei<unk> @ ge ist eine Ver<unk> @ si<unk> @ on , was die letzten 2<unk> @ 5 Jahren gesch<unk> @ n<unk> @ itten .
2025-05-26 23:51:49,844 - INFO - joeynmt.training - Epoch   7, Step:    19600, Batch Loss:     0.824835, Batch Acc: 0.745977, Tokens per Sec:     5828, Lr: 0.000300
2025-05-26 23:52:23,528 - INFO - joeynmt.training - Epoch   7, Step:    19700, Batch Loss:     0.988167, Batch Acc: 0.745233, Tokens per Sec:     5747, Lr: 0.000300
2025-05-26 23:52:59,025 - INFO - joeynmt.training - Epoch   7, Step:    19800, Batch Loss:     0.863563, Batch Acc: 0.743548, Tokens per Sec:     5438, Lr: 0.000300
2025-05-26 23:53:32,273 - INFO - joeynmt.training - Epoch   7, Step:    19900, Batch Loss:     0.817912, Batch Acc: 0.743214, Tokens per Sec:     5771, Lr: 0.000300
2025-05-26 23:54:08,267 - INFO - joeynmt.training - Epoch   7, Step:    20000, Batch Loss:     0.820624, Batch Acc: 0.742966, Tokens per Sec:     5382, Lr: 0.000300
2025-05-26 23:54:08,268 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-26 23:54:08,268 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-26 23:58:33,378 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.69, acc:   0.72, generation: 265.0990[sec], evaluation: 0.0000[sec]
2025-05-26 23:58:33,383 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-26 23:58:33,460 - INFO - joeynmt.helpers - delete models/bpe_2k_model/18000.ckpt
2025-05-26 23:58:33,465 - INFO - joeynmt.training - Example #0
2025-05-26 23:58:33,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-26 23:58:33,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-26 23:58:33,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahre', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'os@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'etwa', 'etwa', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-26 23:58:33,465 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-26 23:58:33,465 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-26 23:58:33,465 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahre habe ich diese zwei Di<unk> @ as sehen , dass die M<unk> @ os<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre , die die die die letzten drei Millionen Jahre , die die die die letzten drei Millionen Jahre , etwa etwa die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-26 23:58:33,465 - INFO - joeynmt.training - Example #1
2025-05-26 23:58:33,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-26 23:58:33,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-26 23:58:33,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'der', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'lich', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'zu', 'zeigen', '.', '</s>']
2025-05-26 23:58:33,465 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-26 23:58:33,465 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich der sch<unk> @ ät<unk> @ z<unk> @ lich dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die E<unk> @ is des E<unk> @ is zu zeigen .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - Example #2
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'em', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'wir', 'uns', 'von', 'unser@@', '<unk>', '@', 'em', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ is<unk> @ se auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ em S<unk> @ in<unk> @ ne , die wir uns von unser<unk> @ em G<unk> @ lo<unk> @ b<unk> @ al<unk> @ -<unk> @ Sy<unk> @ stem .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - Example #3
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - Example #4
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-26 23:58:33,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-26 23:58:33,466 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-26 23:58:33,467 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre ge<unk> @ scha<unk> @ h .
2025-05-26 23:59:08,102 - INFO - joeynmt.training - Epoch   7, Step:    20100, Batch Loss:     0.902108, Batch Acc: 0.742857, Tokens per Sec:     5512, Lr: 0.000300
2025-05-26 23:59:45,056 - INFO - joeynmt.training - Epoch   7, Step:    20200, Batch Loss:     0.892061, Batch Acc: 0.742239, Tokens per Sec:     5324, Lr: 0.000300
2025-05-27 00:00:18,029 - INFO - joeynmt.training - Epoch   7, Step:    20300, Batch Loss:     0.880746, Batch Acc: 0.743323, Tokens per Sec:     5632, Lr: 0.000300
2025-05-27 00:00:51,247 - INFO - joeynmt.training - Epoch   7, Step:    20400, Batch Loss:     0.923869, Batch Acc: 0.742368, Tokens per Sec:     5867, Lr: 0.000300
2025-05-27 00:01:26,656 - INFO - joeynmt.training - Epoch   7, Step:    20500, Batch Loss:     0.969257, Batch Acc: 0.743191, Tokens per Sec:     5426, Lr: 0.000300
2025-05-27 00:01:26,657 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:01:26,657 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:05:01,610 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 214.9426[sec], evaluation: 0.0000[sec]
2025-05-27 00:05:01,617 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 00:05:01,704 - INFO - joeynmt.helpers - delete models/bpe_2k_model/17500.ckpt
2025-05-27 00:05:01,706 - INFO - joeynmt.training - Example #0
2025-05-27 00:05:01,706 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:05:01,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:05:01,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'war', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'os@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'von', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 00:05:01,706 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:05:01,706 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:05:01,706 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em war ich diese zwei Di<unk> @ as , um zu zeigen , dass die M<unk> @ os<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre , die die die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , die die die letzten drei Millionen von der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 00:05:01,706 - INFO - joeynmt.training - Example #1
2025-05-27 00:05:01,706 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:05:01,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:05:01,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che des E<unk> @ is .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - Example #2
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'einem', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'das', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf einem S<unk> @ in<unk> @ n , das ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ n des K<unk> @ li<unk> @ ma<unk> @ -<unk> @ Sy<unk> @ stem .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - Example #3
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - Example #4
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:05:01,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:05:01,707 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre ge<unk> @ scha<unk> @ h .
2025-05-27 00:05:36,244 - INFO - joeynmt.training - Epoch   7, Step:    20600, Batch Loss:     0.898548, Batch Acc: 0.743509, Tokens per Sec:     5512, Lr: 0.000300
2025-05-27 00:06:10,419 - INFO - joeynmt.training - Epoch   7, Step:    20700, Batch Loss:     0.848181, Batch Acc: 0.741345, Tokens per Sec:     5667, Lr: 0.000300
2025-05-27 00:06:44,746 - INFO - joeynmt.training - Epoch   7, Step:    20800, Batch Loss:     0.925477, Batch Acc: 0.742014, Tokens per Sec:     5569, Lr: 0.000300
2025-05-27 00:07:19,199 - INFO - joeynmt.training - Epoch   7, Step:    20900, Batch Loss:     0.939373, Batch Acc: 0.743534, Tokens per Sec:     5614, Lr: 0.000300
2025-05-27 00:07:53,251 - INFO - joeynmt.training - Epoch   7, Step:    21000, Batch Loss:     0.911593, Batch Acc: 0.744437, Tokens per Sec:     5675, Lr: 0.000300
2025-05-27 00:07:53,253 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:07:53,253 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:11:47,387 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.67, acc:   0.72, generation: 234.1229[sec], evaluation: 0.0000[sec]
2025-05-27 00:11:47,392 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 00:11:47,472 - INFO - joeynmt.helpers - delete models/bpe_2k_model/19000.ckpt
2025-05-27 00:11:47,475 - INFO - joeynmt.training - Example #0
2025-05-27 00:11:47,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:11:47,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:11:47,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'l@@', '<unk>', '@', 'l@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 00:11:47,475 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:11:47,475 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:11:47,475 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahr habe ich diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ ü<unk> @ l<unk> @ l<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 00:11:47,475 - INFO - joeynmt.training - Example #1
2025-05-27 00:11:47,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:11:47,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:11:47,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'sehen', ',', 'dass', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'sehen', '.', '</s>']
2025-05-27 00:11:47,475 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:11:47,475 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:11:47,475 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ ck<unk> @ er sehen , dass es nicht die Di<unk> @ ck<unk> @ er sehen .
2025-05-27 00:11:47,475 - INFO - joeynmt.training - Example #2
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'einem', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'em', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', ',', 'die', 'wir', 'uns', 'von', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'alen', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'wan@@', '<unk>', '@', 'del', '.', '</s>']
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ s<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf einem gew<unk> @ is<unk> @ s<unk> @ em S<unk> @ in<unk> @ n , die wir uns von uns gl<unk> @ ob<unk> @ alen K<unk> @ li<unk> @ ma<unk> @ wan<unk> @ del .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - Example #3
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ft', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ ft in der S<unk> @ omm<unk> @ er .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - Example #4
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:11:47,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'habe', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ft', '.', '</s>']
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:11:47,476 - INFO - joeynmt.training - 	Hypothesis: Der näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen habe , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre ge<unk> @ scha<unk> @ f<unk> @ ft .
2025-05-27 00:12:25,732 - INFO - joeynmt.training - Epoch   7, Step:    21100, Batch Loss:     0.838497, Batch Acc: 0.744163, Tokens per Sec:     4998, Lr: 0.000300
2025-05-27 00:13:03,666 - INFO - joeynmt.training - Epoch   7, Step:    21200, Batch Loss:     0.888284, Batch Acc: 0.745125, Tokens per Sec:     5072, Lr: 0.000300
2025-05-27 00:13:37,222 - INFO - joeynmt.training - Epoch   7, Step:    21300, Batch Loss:     0.858527, Batch Acc: 0.745231, Tokens per Sec:     5602, Lr: 0.000300
2025-05-27 00:14:11,799 - INFO - joeynmt.training - Epoch   7, Step:    21400, Batch Loss:     0.923995, Batch Acc: 0.742991, Tokens per Sec:     5606, Lr: 0.000300
2025-05-27 00:14:49,020 - INFO - joeynmt.training - Epoch   7, Step:    21500, Batch Loss:     0.836680, Batch Acc: 0.745800, Tokens per Sec:     5248, Lr: 0.000300
2025-05-27 00:14:49,021 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:14:49,021 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:18:33,238 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 224.2060[sec], evaluation: 0.0000[sec]
2025-05-27 00:18:33,241 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 00:18:33,316 - INFO - joeynmt.helpers - delete models/bpe_2k_model/19500.ckpt
2025-05-27 00:18:33,322 - INFO - joeynmt.training - Example #0
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahren', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ster', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'von', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahre', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahren zei<unk> @ ge ich diese zwei Di<unk> @ as sehen , dass die M<unk> @ u<unk> @ ster , die die die letzten drei Millionen Jahre , die die die letzten drei Millionen Jahre , die die Gr<unk> @ öß<unk> @ e von der U<unk> @ S<unk> @ A , die die die letzten drei Millionen Jahren un<unk> @ gef<unk> @ äh<unk> @ r drei Millionen Jahre , die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - Example #1
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'zt', 'das', 'hier', 'die', 'sch@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'nen', 'dieser', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'sehen', '.', '</s>']
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ zt das hier die sch<unk> @ ö<unk> @ nen dieser spe<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ ck<unk> @ er sehen .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - Example #2
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der K<unk> @ l<unk> @ im<unk> @ ma<unk> @ sy<unk> @ stem .
2025-05-27 00:18:33,323 - INFO - joeynmt.training - Example #3
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:18:33,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:18:33,324 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:18:33,324 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:18:33,324 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 00:18:33,324 - INFO - joeynmt.training - Example #4
2025-05-27 00:18:33,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:18:33,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:18:33,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-27 00:18:33,324 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:18:33,324 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:18:33,324 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge ist eine Ver<unk> @ si<unk> @ on von der letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-27 00:19:11,227 - INFO - joeynmt.training - Epoch   7, Step:    21600, Batch Loss:     0.923817, Batch Acc: 0.745514, Tokens per Sec:     5240, Lr: 0.000300
2025-05-27 00:19:48,679 - INFO - joeynmt.training - Epoch   7, Step:    21700, Batch Loss:     0.883887, Batch Acc: 0.744647, Tokens per Sec:     5141, Lr: 0.000300
2025-05-27 00:20:24,860 - INFO - joeynmt.training - Epoch   7, Step:    21800, Batch Loss:     0.875338, Batch Acc: 0.744317, Tokens per Sec:     5243, Lr: 0.000300
2025-05-27 00:20:49,187 - INFO - joeynmt.training - Epoch   7: total training loss 2751.57
2025-05-27 00:20:49,188 - INFO - joeynmt.training - EPOCH 8
2025-05-27 00:20:57,442 - INFO - joeynmt.training - Epoch   8, Step:    21900, Batch Loss:     0.852767, Batch Acc: 0.750304, Tokens per Sec:     5776, Lr: 0.000300
2025-05-27 00:21:32,890 - INFO - joeynmt.training - Epoch   8, Step:    22000, Batch Loss:     0.859882, Batch Acc: 0.753655, Tokens per Sec:     5482, Lr: 0.000300
2025-05-27 00:21:32,891 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:21:32,891 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:25:12,518 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.67, acc:   0.72, generation: 219.6167[sec], evaluation: 0.0000[sec]
2025-05-27 00:25:12,618 - INFO - joeynmt.helpers - delete models/bpe_2k_model/18500.ckpt
2025-05-27 00:25:12,621 - INFO - joeynmt.training - Example #0
2025-05-27 00:25:12,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:25:12,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:25:12,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'bei@@', '<unk>', '@', 'den', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ster', 'die', 'L@@', '<unk>', '@', 'ö@@', '<unk>', '@', 's@@', '<unk>', '@', 'ung', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'st@@', '<unk>', '@', 'il@@', '<unk>', '@', 'and', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 00:25:12,621 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:25:12,621 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:25:12,621 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em zei<unk> @ ge ich diese bei<unk> @ den Di<unk> @ as sehen , dass die M<unk> @ u<unk> @ ster die L<unk> @ ö<unk> @ s<unk> @ ung , die die die letzten drei Millionen Jahre , die die Gr<unk> @ öß<unk> @ e des V<unk> @ o<unk> @ st<unk> @ il<unk> @ and des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 00:25:12,621 - INFO - joeynmt.training - Example #1
2025-05-27 00:25:12,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:25:12,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:25:12,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'isch@@', '<unk>', '@', 'es', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-27 00:25:12,621 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:25:12,621 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:25:12,621 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ isch<unk> @ es Problem , weil es nicht die Di<unk> @ ck<unk> @ er des E<unk> @ is .
2025-05-27 00:25:12,621 - INFO - joeynmt.training - Example #2
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ser@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'ßen', ',', 'von', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'en@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ ser<unk> @ ma<unk> @ ßen , von uns gl<unk> @ ob<unk> @ al kl<unk> @ op<unk> @ p<unk> @ en<unk> @ sy<unk> @ stem .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - Example #3
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - Example #4
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:25:12,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'es', 'passiert', '.', '</s>']
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:25:12,622 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von dem , was es passiert .
2025-05-27 00:25:48,329 - INFO - joeynmt.training - Epoch   8, Step:    22100, Batch Loss:     0.848040, Batch Acc: 0.752749, Tokens per Sec:     5342, Lr: 0.000300
2025-05-27 00:26:23,649 - INFO - joeynmt.training - Epoch   8, Step:    22200, Batch Loss:     0.887019, Batch Acc: 0.751272, Tokens per Sec:     5471, Lr: 0.000300
2025-05-27 00:26:59,774 - INFO - joeynmt.training - Epoch   8, Step:    22300, Batch Loss:     0.832441, Batch Acc: 0.752288, Tokens per Sec:     5299, Lr: 0.000300
2025-05-27 00:27:35,306 - INFO - joeynmt.training - Epoch   8, Step:    22400, Batch Loss:     0.801868, Batch Acc: 0.750920, Tokens per Sec:     5295, Lr: 0.000300
2025-05-27 00:28:10,536 - INFO - joeynmt.training - Epoch   8, Step:    22500, Batch Loss:     0.844527, Batch Acc: 0.751588, Tokens per Sec:     5416, Lr: 0.000300
2025-05-27 00:28:10,537 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:28:10,537 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:32:11,944 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 241.3957[sec], evaluation: 0.0000[sec]
2025-05-27 00:32:12,028 - INFO - joeynmt.helpers - delete models/bpe_2k_model/20000.ckpt
2025-05-27 00:32:12,032 - INFO - joeynmt.training - Example #0
2025-05-27 00:32:12,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:32:12,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:32:12,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahren', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'l@@', '<unk>', '@', 'le', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 00:32:12,032 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:32:12,032 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:32:12,032 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahren zei<unk> @ ge ich diese zwei Di<unk> @ as zeigen , dass die M<unk> @ ü<unk> @ l<unk> @ le , die die letzten drei Millionen Jahre , die die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahren , die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 00:32:12,032 - INFO - joeynmt.training - Example #1
2025-05-27 00:32:12,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:32:12,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:32:12,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'e', 'des', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ elle Problem , weil es nicht die D<unk> @ am<unk> @ e des E<unk> @ is des E<unk> @ is zeigt .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - Example #2
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'das', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', 'von', 'uns', ',', 'das', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'it@@', '<unk>', '@', 't', '.', '</s>']
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ ne , das K<unk> @ l<unk> @ im<unk> @ a von uns , das G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ it<unk> @ t .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - Example #3
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - Example #4
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:32:12,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'den', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ft', 'ist', '.', '</s>']
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:32:12,033 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:32:12,034 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on , die ich Ihnen zeigen , ist eine Ver<unk> @ si<unk> @ on von den letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ f<unk> @ ft ist .
2025-05-27 00:32:46,292 - INFO - joeynmt.training - Epoch   8, Step:    22600, Batch Loss:     0.871714, Batch Acc: 0.749939, Tokens per Sec:     5507, Lr: 0.000300
2025-05-27 00:33:22,568 - INFO - joeynmt.training - Epoch   8, Step:    22700, Batch Loss:     0.805734, Batch Acc: 0.749676, Tokens per Sec:     5321, Lr: 0.000300
2025-05-27 00:33:56,468 - INFO - joeynmt.training - Epoch   8, Step:    22800, Batch Loss:     0.949487, Batch Acc: 0.752510, Tokens per Sec:     5654, Lr: 0.000300
2025-05-27 00:34:31,940 - INFO - joeynmt.training - Epoch   8, Step:    22900, Batch Loss:     0.915061, Batch Acc: 0.749863, Tokens per Sec:     5396, Lr: 0.000300
2025-05-27 00:35:06,869 - INFO - joeynmt.training - Epoch   8, Step:    23000, Batch Loss:     0.758991, Batch Acc: 0.752465, Tokens per Sec:     5525, Lr: 0.000300
2025-05-27 00:35:06,870 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:35:06,870 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:39:24,472 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.65, acc:   0.72, generation: 257.5906[sec], evaluation: 0.0000[sec]
2025-05-27 00:39:24,478 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 00:39:24,550 - INFO - joeynmt.helpers - delete models/bpe_2k_model/20500.ckpt
2025-05-27 00:39:24,555 - INFO - joeynmt.training - Example #0
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'es', 'Jahr', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', ',', 'die', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Hypothesis: Und ich habe es Jahr zei<unk> @ ge ich diese zwei Di<unk> @ as , die die zwei Di<unk> @ as , die die letzten drei Millionen Jahren , die die Gr<unk> @ öß<unk> @ e , die die die letzten drei Millionen Jahren , die die die Gr<unk> @ öß<unk> @ e der U<unk> @ S<unk> @ A , die die die letzten drei Millionen Jahren , die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - Example #1
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'isch@@', '<unk>', '@', 'es', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'te', 'des', 'E@@', '<unk>', '@', 'is', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'te', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ isch<unk> @ es Problem , weil es nicht die Di<unk> @ ck<unk> @ te des E<unk> @ is nicht die Di<unk> @ ck<unk> @ te des E<unk> @ is .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - Example #2
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'em', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'wir', 'uns', 'die', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'är@@', '<unk>', '@', 't', 'von', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'in@@', '<unk>', '@', 'gt', '.', '</s>']
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ em S<unk> @ in<unk> @ ne , die wir uns die G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ är<unk> @ t von uns gl<unk> @ ob<unk> @ al kl<unk> @ in<unk> @ gt .
2025-05-27 00:39:24,556 - INFO - joeynmt.training - Example #3
2025-05-27 00:39:24,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:39:24,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:39:24,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:39:24,557 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:39:24,557 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:39:24,557 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 00:39:24,557 - INFO - joeynmt.training - Example #4
2025-05-27 00:39:24,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:39:24,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:39:24,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'gesch@@', '<unk>', '@', 'n@@', '<unk>', '@', 'itten', 'ist', '.', '</s>']
2025-05-27 00:39:24,557 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:39:24,557 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:39:24,557 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren gesch<unk> @ n<unk> @ itten ist .
2025-05-27 00:40:00,178 - INFO - joeynmt.training - Epoch   8, Step:    23100, Batch Loss:     0.824785, Batch Acc: 0.752043, Tokens per Sec:     5482, Lr: 0.000300
2025-05-27 00:40:32,121 - INFO - joeynmt.training - Epoch   8, Step:    23200, Batch Loss:     0.801192, Batch Acc: 0.751754, Tokens per Sec:     5869, Lr: 0.000300
2025-05-27 00:41:06,808 - INFO - joeynmt.training - Epoch   8, Step:    23300, Batch Loss:     0.871958, Batch Acc: 0.748415, Tokens per Sec:     5556, Lr: 0.000300
2025-05-27 00:41:42,262 - INFO - joeynmt.training - Epoch   8, Step:    23400, Batch Loss:     0.935139, Batch Acc: 0.749083, Tokens per Sec:     5442, Lr: 0.000300
2025-05-27 00:42:17,149 - INFO - joeynmt.training - Epoch   8, Step:    23500, Batch Loss:     0.897898, Batch Acc: 0.747279, Tokens per Sec:     5546, Lr: 0.000300
2025-05-27 00:42:17,150 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:42:17,151 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:46:33,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 256.7695[sec], evaluation: 0.0000[sec]
2025-05-27 00:46:34,011 - INFO - joeynmt.helpers - delete models/bpe_2k_model/21000.ckpt
2025-05-27 00:46:34,016 - INFO - joeynmt.training - Example #0
2025-05-27 00:46:34,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:46:34,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:46:34,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahren', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'etwa', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 00:46:34,016 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:46:34,016 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:46:34,016 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahren habe ich diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ oo<unk> @ l<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahre in etwa etwa die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 00:46:34,016 - INFO - joeynmt.training - Example #1
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'Auf@@', '<unk>', '@', 'ga@@', '<unk>', '@', 'be', 'des', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ischen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er', 'sehen', '.', '</s>']
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die Auf<unk> @ ga<unk> @ be des Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ ischen Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ -<unk> @ Problem ist , weil es nicht die Di<unk> @ ck<unk> @ er sehen .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - Example #2
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'en', 'auf', 'dem', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ser', 'Wei@@', '<unk>', '@', 'se', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ser', 'Wei@@', '<unk>', '@', 'se', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', 'von', 'uns', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ en auf dem N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ ser Wei<unk> @ se in gew<unk> @ is<unk> @ ser Wei<unk> @ se in der K<unk> @ l<unk> @ im<unk> @ a von uns G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ a .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - Example #3
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'et@@', '<unk>', '@', 'zen', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ et<unk> @ zen in der W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 00:46:34,017 - INFO - joeynmt.training - Example #4
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:46:34,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', '.', '</s>']
2025-05-27 00:46:34,018 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:46:34,018 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:46:34,018 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen werde , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre .
2025-05-27 00:47:11,519 - INFO - joeynmt.training - Epoch   8, Step:    23600, Batch Loss:     0.874171, Batch Acc: 0.749165, Tokens per Sec:     5141, Lr: 0.000300
2025-05-27 00:47:45,627 - INFO - joeynmt.training - Epoch   8, Step:    23700, Batch Loss:     0.851524, Batch Acc: 0.749380, Tokens per Sec:     5583, Lr: 0.000300
2025-05-27 00:48:20,360 - INFO - joeynmt.training - Epoch   8, Step:    23800, Batch Loss:     0.866439, Batch Acc: 0.750346, Tokens per Sec:     5432, Lr: 0.000300
2025-05-27 00:48:54,914 - INFO - joeynmt.training - Epoch   8, Step:    23900, Batch Loss:     0.872466, Batch Acc: 0.748901, Tokens per Sec:     5679, Lr: 0.000300
2025-05-27 00:49:30,397 - INFO - joeynmt.training - Epoch   8, Step:    24000, Batch Loss:     0.883770, Batch Acc: 0.748281, Tokens per Sec:     5358, Lr: 0.000300
2025-05-27 00:49:30,398 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:49:30,398 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 00:53:28,970 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 238.5610[sec], evaluation: 0.0000[sec]
2025-05-27 00:53:28,974 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 00:53:29,057 - INFO - joeynmt.helpers - delete models/bpe_2k_model/22000.ckpt
2025-05-27 00:53:29,063 - INFO - joeynmt.training - Example #0
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ierte', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'l@@', '<unk>', '@', 'l@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'etwa', 'drei', 'Millionen', 'Jahren', 'etwa', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 00:53:29,063 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 00:53:29,063 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 00:53:29,063 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ i<unk> @ ent<unk> @ ierte ich diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ ü<unk> @ l<unk> @ l<unk> @ k<unk> @ a<unk> @ p , die die die letzten drei Millionen Jahren etwa drei Millionen Jahren etwa die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 00:53:29,063 - INFO - joeynmt.training - Example #1
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'zt', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'isch@@', '<unk>', '@', 'er', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', 'ist', '.', '</s>']
2025-05-27 00:53:29,063 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 00:53:29,063 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 00:53:29,063 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ zt die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ isch<unk> @ er Problem , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che ist .
2025-05-27 00:53:29,063 - INFO - joeynmt.training - Example #2
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 00:53:29,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'la@@', '<unk>', '@', 'f', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', ',', 'ist', 'in', 'der', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', ',', 'die', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'it@@', '<unk>', '@', 'iert', '.', '</s>']
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sch<unk> @ la<unk> @ f auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in der K<unk> @ l<unk> @ op<unk> @ p<unk> @ e , ist in der K<unk> @ l<unk> @ im<unk> @ a , die wir uns gl<unk> @ ob<unk> @ al kl<unk> @ im<unk> @ it<unk> @ iert .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - Example #3
2025-05-27 00:53:29,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 00:53:29,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 00:53:29,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Hypothesis: Es ist in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - Example #4
2025-05-27 00:53:29,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 00:53:29,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 00:53:29,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 00:53:29,064 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von dem , was der letzten 2<unk> @ 5 Jahren passiert .
2025-05-27 00:54:05,047 - INFO - joeynmt.training - Epoch   8, Step:    24100, Batch Loss:     0.906670, Batch Acc: 0.750536, Tokens per Sec:     5379, Lr: 0.000300
2025-05-27 00:54:41,738 - INFO - joeynmt.training - Epoch   8, Step:    24200, Batch Loss:     0.891991, Batch Acc: 0.748797, Tokens per Sec:     5261, Lr: 0.000300
2025-05-27 00:55:16,098 - INFO - joeynmt.training - Epoch   8, Step:    24300, Batch Loss:     0.823086, Batch Acc: 0.748431, Tokens per Sec:     5675, Lr: 0.000300
2025-05-27 00:55:49,964 - INFO - joeynmt.training - Epoch   8, Step:    24400, Batch Loss:     0.821044, Batch Acc: 0.751431, Tokens per Sec:     5644, Lr: 0.000300
2025-05-27 00:56:24,257 - INFO - joeynmt.training - Epoch   8, Step:    24500, Batch Loss:     0.840608, Batch Acc: 0.748923, Tokens per Sec:     5521, Lr: 0.000300
2025-05-27 00:56:24,258 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 00:56:24,258 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:00:55,499 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 271.2308[sec], evaluation: 0.0000[sec]
2025-05-27 01:00:55,506 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 01:00:55,586 - INFO - joeynmt.helpers - delete models/bpe_2k_model/22500.ckpt
2025-05-27 01:00:55,589 - INFO - joeynmt.training - Example #0
2025-05-27 01:00:55,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:00:55,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:00:55,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'Or@@', '<unk>', '@', 'ganis@@', '<unk>', '@', 'men', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'os@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'drei', 'Millionen', 'Jahren', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 01:00:55,589 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:00:55,589 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:00:55,589 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or Or<unk> @ ganis<unk> @ men zei<unk> @ ge ich diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ os<unk> @ k<unk> @ a<unk> @ p , die die letzten drei Millionen Jahren un<unk> @ gef<unk> @ äh<unk> @ r drei Millionen Jahren , die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 01:00:55,589 - INFO - joeynmt.training - Example #1
2025-05-27 01:00:55,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:00:55,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:00:55,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'The@@', '<unk>', '@', 'ma', ',', 'das', 'ist', 'wirklich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'ellen', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', 'in', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das The<unk> @ ma , das ist wirklich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ ellen Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ in des E<unk> @ is .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - Example #2
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ser@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'ßen', ',', 'die', 'wir', 'uns', 'gl@@', '<unk>', '@', 'ob@@', '<unk>', '@', 'ale', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ ser<unk> @ ma<unk> @ ßen , die wir uns gl<unk> @ ob<unk> @ ale K<unk> @ li<unk> @ ma<unk> @ sy<unk> @ stem .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - Example #3
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'den', 'S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'mer@@', '<unk>', '@', 'n', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Hypothesis: Es hat in den S<unk> @ om<unk> @ mer<unk> @ n und k<unk> @ ri<unk> @ m<unk> @ pt in den S<unk> @ omm<unk> @ er .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - Example #4
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:00:55,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'habe', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:00:55,590 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen habe , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren passiert ist .
2025-05-27 01:01:32,850 - INFO - joeynmt.training - Epoch   8, Step:    24600, Batch Loss:     0.940356, Batch Acc: 0.745898, Tokens per Sec:     5238, Lr: 0.000300
2025-05-27 01:02:05,964 - INFO - joeynmt.training - Epoch   8, Step:    24700, Batch Loss:     0.830208, Batch Acc: 0.748967, Tokens per Sec:     5685, Lr: 0.000300
2025-05-27 01:02:43,761 - INFO - joeynmt.training - Epoch   8, Step:    24800, Batch Loss:     0.855031, Batch Acc: 0.748326, Tokens per Sec:     5183, Lr: 0.000300
2025-05-27 01:03:18,900 - INFO - joeynmt.training - Epoch   8, Step:    24900, Batch Loss:     0.880766, Batch Acc: 0.746454, Tokens per Sec:     5496, Lr: 0.000300
2025-05-27 01:03:54,478 - INFO - joeynmt.training - Epoch   8, Step:    25000, Batch Loss:     0.769979, Batch Acc: 0.751248, Tokens per Sec:     5497, Lr: 0.000300
2025-05-27 01:03:54,478 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:03:54,478 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:08:09,756 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 255.2674[sec], evaluation: 0.0000[sec]
2025-05-27 01:08:09,762 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 01:08:09,849 - INFO - joeynmt.helpers - delete models/bpe_2k_model/21500.ckpt
2025-05-27 01:08:09,852 - INFO - joeynmt.training - Example #0
2025-05-27 01:08:09,852 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:08:09,852 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:08:09,852 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'zei@@', '<unk>', '@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'die', 'in', 'den', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 01:08:09,852 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:08:09,852 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:08:09,852 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em zei<unk> @ ge ich diese zwei Di<unk> @ as sehen , die in den M<unk> @ oo<unk> @ l<unk> @ k<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre un<unk> @ gef<unk> @ äh<unk> @ r die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 01:08:09,852 - INFO - joeynmt.training - Example #1
2025-05-27 01:08:09,852 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:08:09,852 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:08:09,852 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'der', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich der ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die E<unk> @ is des E<unk> @ is zeigt .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - Example #2
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'einem', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'em', 'H@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't', 'von', 'uns', ',', 'das', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'n@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in einem gew<unk> @ is<unk> @ s<unk> @ em H<unk> @ ar<unk> @ t von uns , das G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ n<unk> @ sy<unk> @ stem .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - Example #3
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'et@@', '<unk>', '@', 'zen', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ et<unk> @ zen in den W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - Example #4
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:08:09,853 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'zei@@', '<unk>', '@', 'ge', 'ist', ',', 'ist', 'eine', 'sch@@', '<unk>', '@', 'n@@', '<unk>', '@', 'üt@@', '<unk>', '@', 'z@@', '<unk>', '@', 'te', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:08:09,853 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich zei<unk> @ ge ist , ist eine sch<unk> @ n<unk> @ üt<unk> @ z<unk> @ te , was die letzten 2<unk> @ 5 Jahren ge<unk> @ scha<unk> @ h .
2025-05-27 01:08:09,856 - INFO - joeynmt.training - Epoch   8: total training loss 2688.26
2025-05-27 01:08:09,856 - INFO - joeynmt.training - EPOCH 9
2025-05-27 01:08:44,029 - INFO - joeynmt.training - Epoch   9, Step:    25100, Batch Loss:     0.824486, Batch Acc: 0.757595, Tokens per Sec:     5573, Lr: 0.000300
2025-05-27 01:09:19,580 - INFO - joeynmt.training - Epoch   9, Step:    25200, Batch Loss:     0.811259, Batch Acc: 0.757992, Tokens per Sec:     5480, Lr: 0.000300
2025-05-27 01:09:53,885 - INFO - joeynmt.training - Epoch   9, Step:    25300, Batch Loss:     0.810840, Batch Acc: 0.758084, Tokens per Sec:     5547, Lr: 0.000300
2025-05-27 01:10:30,585 - INFO - joeynmt.training - Epoch   9, Step:    25400, Batch Loss:     0.791370, Batch Acc: 0.759440, Tokens per Sec:     5321, Lr: 0.000300
2025-05-27 01:11:08,003 - INFO - joeynmt.training - Epoch   9, Step:    25500, Batch Loss:     0.838743, Batch Acc: 0.758015, Tokens per Sec:     5106, Lr: 0.000300
2025-05-27 01:11:08,003 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:11:08,003 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:15:22,819 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 254.8040[sec], evaluation: 0.0000[sec]
2025-05-27 01:15:22,899 - INFO - joeynmt.helpers - delete models/bpe_2k_model/23500.ckpt
2025-05-27 01:15:22,902 - INFO - joeynmt.training - Example #0
2025-05-27 01:15:22,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:15:22,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:15:22,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'letzten', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'os@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'M@@', '<unk>', '@', 'i@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', '-@@', '<unk>', '@', 'F@@', '<unk>', '@', 'un@@', '<unk>', '@', 'ktion@@', '<unk>', '@', 's@@', '<unk>', '@', 'f@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'igkeit', 'des', 'F@@', '<unk>', '@', 'un@@', '<unk>', '@', 'des', 'des', 'V@@', '<unk>', '@', 'o@@', '<unk>', '@', 'st@@', '<unk>', '@', 'an@@', '<unk>', '@', 'des', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 01:15:22,902 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:15:22,902 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:15:22,902 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or letzten Jahr habe ich diese zwei Di<unk> @ as sehen , um zu zeigen , dass die M<unk> @ os<unk> @ k<unk> @ a<unk> @ p , die die M<unk> @ i<unk> @ oo<unk> @ l<unk> @ -<unk> @ F<unk> @ un<unk> @ ktion<unk> @ s<unk> @ f<unk> @ äh<unk> @ igkeit des F<unk> @ un<unk> @ des des V<unk> @ o<unk> @ st<unk> @ an<unk> @ des des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 01:15:22,902 - INFO - joeynmt.training - Example #1
2025-05-27 01:15:22,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:15:22,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:15:22,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'lich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'Di@@', '<unk>', '@', 'ck@@', '<unk>', '@', 'er@@', '<unk>', '@', 'es', 'zeigt', '.', '</s>']
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Hypothesis: Aber das unter<unk> @ sch<unk> @ ät<unk> @ z<unk> @ lich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die Di<unk> @ ck<unk> @ er<unk> @ es zeigt .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - Example #2
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'dem', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'es', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ul@@', '<unk>', '@', 'iert', ',', 'von', 'unser@@', '<unk>', '@', 'em', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'en@@', '<unk>', '@', 'z@@', '<unk>', '@', 'ier@@', '<unk>', '@', 'ten', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf dem N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ es kl<unk> @ op<unk> @ p<unk> @ ul<unk> @ iert , von unser<unk> @ em G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ op<unk> @ p<unk> @ en<unk> @ z<unk> @ ier<unk> @ ten K<unk> @ li<unk> @ ma<unk> @ sy<unk> @ stem .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - Example #3
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Hypothesis: Es ist in den W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in den S<unk> @ omm<unk> @ er .
2025-05-27 01:15:22,903 - INFO - joeynmt.training - Example #4
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:15:22,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'habe', ',', 'ist', 'eine', 'besch@@', '<unk>', '@', 'le@@', '<unk>', '@', 'un@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'te', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 01:15:22,903 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:15:22,904 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:15:22,904 - INFO - joeynmt.training - 	Hypothesis: Und die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen habe , ist eine besch<unk> @ le<unk> @ un<unk> @ ig<unk> @ te Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren passiert .
2025-05-27 01:15:58,587 - INFO - joeynmt.training - Epoch   9, Step:    25600, Batch Loss:     0.898134, Batch Acc: 0.754875, Tokens per Sec:     5333, Lr: 0.000300
2025-05-27 01:16:35,244 - INFO - joeynmt.training - Epoch   9, Step:    25700, Batch Loss:     0.813204, Batch Acc: 0.755315, Tokens per Sec:     5197, Lr: 0.000300
2025-05-27 01:17:12,128 - INFO - joeynmt.training - Epoch   9, Step:    25800, Batch Loss:     0.930986, Batch Acc: 0.754143, Tokens per Sec:     5261, Lr: 0.000300
2025-05-27 01:17:47,975 - INFO - joeynmt.training - Epoch   9, Step:    25900, Batch Loss:     0.884458, Batch Acc: 0.756660, Tokens per Sec:     5418, Lr: 0.000300
2025-05-27 01:18:24,502 - INFO - joeynmt.training - Epoch   9, Step:    26000, Batch Loss:     0.788183, Batch Acc: 0.756521, Tokens per Sec:     5348, Lr: 0.000300
2025-05-27 01:18:24,503 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:18:24,503 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:22:15,128 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 230.6150[sec], evaluation: 0.0000[sec]
2025-05-27 01:22:15,203 - INFO - joeynmt.helpers - delete models/bpe_2k_model/23000.ckpt
2025-05-27 01:22:15,208 - INFO - joeynmt.training - Example #0
2025-05-27 01:22:15,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:22:15,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:22:15,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahren', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'gesehen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 01:22:15,208 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:22:15,208 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:22:15,208 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahren habe ich diese zwei Di<unk> @ as gesehen , um zu zeigen , dass die M<unk> @ oo<unk> @ l<unk> @ sk<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 01:22:15,208 - INFO - joeynmt.training - Example #1
2025-05-27 01:22:15,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'der', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich der ern<unk> @ st dieses spe<unk> @ zi<unk> @ elle Problem , weil es nicht die E<unk> @ is des E<unk> @ is zeigt .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - Example #2
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'es', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', ',', 'die', 'wir', 'uns', 'in', 'gew@@', '<unk>', '@', 'al@@', '<unk>', '@', 't@@', '<unk>', '@', 'ige', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ es K<unk> @ l<unk> @ im<unk> @ a , die wir uns in gew<unk> @ al<unk> @ t<unk> @ ige S<unk> @ in<unk> @ n .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - Example #3
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 01:22:15,209 - INFO - joeynmt.training - Example #4
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:22:15,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'besch@@', '<unk>', '@', 'le@@', '<unk>', '@', 'un@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ere', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'den', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-27 01:22:15,210 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:22:15,210 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:22:15,210 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine besch<unk> @ le<unk> @ un<unk> @ ig<unk> @ ere Ver<unk> @ si<unk> @ on von den letzten 2<unk> @ 5 Jahren .
2025-05-27 01:22:50,440 - INFO - joeynmt.training - Epoch   9, Step:    26100, Batch Loss:     0.997594, Batch Acc: 0.756546, Tokens per Sec:     5368, Lr: 0.000300
2025-05-27 01:23:25,284 - INFO - joeynmt.training - Epoch   9, Step:    26200, Batch Loss:     0.842291, Batch Acc: 0.754888, Tokens per Sec:     5464, Lr: 0.000300
2025-05-27 01:24:00,332 - INFO - joeynmt.training - Epoch   9, Step:    26300, Batch Loss:     0.783652, Batch Acc: 0.754724, Tokens per Sec:     5439, Lr: 0.000300
2025-05-27 01:24:35,374 - INFO - joeynmt.training - Epoch   9, Step:    26400, Batch Loss:     0.842275, Batch Acc: 0.753968, Tokens per Sec:     5412, Lr: 0.000300
2025-05-27 01:25:09,823 - INFO - joeynmt.training - Epoch   9, Step:    26500, Batch Loss:     0.858532, Batch Acc: 0.754508, Tokens per Sec:     5564, Lr: 0.000300
2025-05-27 01:25:09,824 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:25:09,824 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:28:37,336 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 207.5018[sec], evaluation: 0.0000[sec]
2025-05-27 01:28:37,411 - INFO - joeynmt.helpers - delete models/bpe_2k_model/25500.ckpt
2025-05-27 01:28:37,417 - INFO - joeynmt.training - Example #0
2025-05-27 01:28:37,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:28:37,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:28:37,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'os@@', '<unk>', '@', 'iti@@', '<unk>', '@', 'on', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'le', 'drei', 'Millionen', 'Jahre', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'von', 'den', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ver@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ück@@', '<unk>', '@', 'te', '.', '</s>']
2025-05-27 01:28:37,417 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:28:37,417 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:28:37,417 - INFO - joeynmt.training - 	Hypothesis: Und ich habe diese zwei Di<unk> @ as zeigen , um zu zeigen , dass die P<unk> @ os<unk> @ iti<unk> @ on zeigen , dass die M<unk> @ oo<unk> @ le drei Millionen Jahre in den letzten drei Millionen Jahre , die die Gr<unk> @ öß<unk> @ e von den U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahren un<unk> @ gef<unk> @ äh<unk> @ r die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ver<unk> @ r<unk> @ ück<unk> @ te .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - Example #1
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Gr@@', '<unk>', '@', 'unde', 'gen@@', '<unk>', '@', 'ommen', ',', 'dass', 'das', 'hier', 'die', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ik@@', '<unk>', '@', 'de@@', '<unk>', '@', 'proble@@', '<unk>', '@', 'm', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ke', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Gr<unk> @ unde gen<unk> @ ommen , dass das hier die Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ ik<unk> @ de<unk> @ proble<unk> @ m , weil es nicht die D<unk> @ ic<unk> @ ke des E<unk> @ is .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - Example #2
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', '-@@', '<unk>', '@', 'P@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'e', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'wir', 'in', 'einem', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ul@@', '<unk>', '@', 'ier@@', '<unk>', '@', 'en@@', '<unk>', '@', 'des', 'Her@@', '<unk>', '@', 'zen', ',', '</s>']
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ is<unk> @ s<unk> @ -<unk> @ P<unk> @ ol<unk> @ e ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ ne , die wir in einem kl<unk> @ op<unk> @ p<unk> @ ul<unk> @ ier<unk> @ en<unk> @ des Her<unk> @ zen ,
2025-05-27 01:28:37,418 - INFO - joeynmt.training - Example #3
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - 	Hypothesis: Es ist in den W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in den S<unk> @ omm<unk> @ er .
2025-05-27 01:28:37,418 - INFO - joeynmt.training - Example #4
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:28:37,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'möchte', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'den', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-27 01:28:37,419 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:28:37,419 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:28:37,419 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen möchte , ist eine Ver<unk> @ si<unk> @ on von den letzten 2<unk> @ 5 Jahren .
2025-05-27 01:29:11,489 - INFO - joeynmt.training - Epoch   9, Step:    26600, Batch Loss:     0.861422, Batch Acc: 0.751502, Tokens per Sec:     5732, Lr: 0.000300
2025-05-27 01:29:46,918 - INFO - joeynmt.training - Epoch   9, Step:    26700, Batch Loss:     0.831593, Batch Acc: 0.752903, Tokens per Sec:     5416, Lr: 0.000300
2025-05-27 01:30:19,124 - INFO - joeynmt.training - Epoch   9, Step:    26800, Batch Loss:     0.809836, Batch Acc: 0.752368, Tokens per Sec:     5820, Lr: 0.000300
2025-05-27 01:30:54,561 - INFO - joeynmt.training - Epoch   9, Step:    26900, Batch Loss:     0.808877, Batch Acc: 0.752883, Tokens per Sec:     5422, Lr: 0.000300
2025-05-27 01:31:30,404 - INFO - joeynmt.training - Epoch   9, Step:    27000, Batch Loss:     0.838909, Batch Acc: 0.752949, Tokens per Sec:     5378, Lr: 0.000300
2025-05-27 01:31:30,405 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:31:30,405 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:35:07,129 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 216.7137[sec], evaluation: 0.0000[sec]
2025-05-27 01:35:07,209 - INFO - joeynmt.helpers - delete models/bpe_2k_model/24000.ckpt
2025-05-27 01:35:07,215 - INFO - joeynmt.training - Example #0
2025-05-27 01:35:07,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:35:07,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:35:07,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'von', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 01:35:07,215 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:35:07,215 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:35:07,215 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em Jahr habe ich diese zwei Di<unk> @ as sehen , dass die zwei Di<unk> @ as zeigen , die die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , die die letzten drei Millionen von der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 01:35:07,215 - INFO - joeynmt.training - Example #1
2025-05-27 01:35:07,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:35:07,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:35:07,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'die', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'des', 'E@@', '<unk>', '@', 'is', 'zeigt', '.', '</s>']
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich die ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die E<unk> @ is des E<unk> @ is des E<unk> @ is zeigt .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - Example #2
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'en@@', '<unk>', '@', 'heit', '.', '</s>']
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ s<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se S<unk> @ in<unk> @ n des K<unk> @ li<unk> @ ma<unk> @ ss<unk> @ en<unk> @ heit .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - Example #3
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'et@@', '<unk>', '@', 'zen', 'im', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ et<unk> @ zen im W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - Example #4
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:35:07,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', 'ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:35:07,216 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen werde , ist eine ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren passiert ist .
2025-05-27 01:35:40,962 - INFO - joeynmt.training - Epoch   9, Step:    27100, Batch Loss:     0.897794, Batch Acc: 0.753882, Tokens per Sec:     5683, Lr: 0.000300
2025-05-27 01:36:15,069 - INFO - joeynmt.training - Epoch   9, Step:    27200, Batch Loss:     0.837264, Batch Acc: 0.753466, Tokens per Sec:     5786, Lr: 0.000300
2025-05-27 01:36:51,736 - INFO - joeynmt.training - Epoch   9, Step:    27300, Batch Loss:     0.807858, Batch Acc: 0.751799, Tokens per Sec:     5286, Lr: 0.000300
2025-05-27 01:37:26,326 - INFO - joeynmt.training - Epoch   9, Step:    27400, Batch Loss:     0.851910, Batch Acc: 0.753628, Tokens per Sec:     5510, Lr: 0.000300
2025-05-27 01:38:02,279 - INFO - joeynmt.training - Epoch   9, Step:    27500, Batch Loss:     0.908606, Batch Acc: 0.753026, Tokens per Sec:     5331, Lr: 0.000300
2025-05-27 01:38:02,280 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:38:02,280 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:42:04,999 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 242.7090[sec], evaluation: 0.0000[sec]
2025-05-27 01:42:05,004 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 01:42:05,080 - INFO - joeynmt.helpers - delete models/bpe_2k_model/24500.ckpt
2025-05-27 01:42:05,082 - INFO - joeynmt.training - Example #0
2025-05-27 01:42:05,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:42:05,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:42:05,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ier@@', '<unk>', '@', 'ten', 'Jahr', 'lie@@', '<unk>', '@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'dass', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 01:42:05,082 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:42:05,082 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:42:05,082 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ i<unk> @ ent<unk> @ ier<unk> @ ten Jahr lie<unk> @ ß ich diese zwei Di<unk> @ as sehen , dass die zwei Di<unk> @ as zeigen , die die die letzten drei Millionen Jahre , die die die Gr<unk> @ öß<unk> @ e der U<unk> @ S<unk> @ A , die die die letzten drei Millionen Jahre der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 01:42:05,082 - INFO - joeynmt.training - Example #1
2025-05-27 01:42:05,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Gr@@', '<unk>', '@', 'und', ',', 'dass', 'dieses', 'Unter@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'z@@', '<unk>', '@', 'ung', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'isch@@', '<unk>', '@', 'es', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', ',', '</s>']
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Gr<unk> @ und , dass dieses Unter<unk> @ sch<unk> @ ät<unk> @ z<unk> @ ung dieses spe<unk> @ zi<unk> @ f<unk> @ isch<unk> @ es Problem , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che ,
2025-05-27 01:42:05,083 - INFO - joeynmt.training - Example #2
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sch@@', '<unk>', '@', 'es', 'auf', 'dem', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'es', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ s<unk> @ is<unk> @ sch<unk> @ es auf dem K<unk> @ l<unk> @ im<unk> @ a ist in gew<unk> @ is<unk> @ s<unk> @ es K<unk> @ l<unk> @ im<unk> @ a .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - Example #3
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - 	Hypothesis: Es ist in den W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in den S<unk> @ omm<unk> @ er .
2025-05-27 01:42:05,083 - INFO - joeynmt.training - Example #4
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:42:05,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'es', 'der', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'pass@@', '<unk>', '@', 'ierte', '.', '</s>']
2025-05-27 01:42:05,084 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:42:05,084 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:42:05,084 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von dem , was es der letzten 2<unk> @ 5 Jahren pass<unk> @ ierte .
2025-05-27 01:42:38,850 - INFO - joeynmt.training - Epoch   9, Step:    27600, Batch Loss:     0.911888, Batch Acc: 0.753370, Tokens per Sec:     5665, Lr: 0.000300
2025-05-27 01:43:13,891 - INFO - joeynmt.training - Epoch   9, Step:    27700, Batch Loss:     0.814948, Batch Acc: 0.754273, Tokens per Sec:     5476, Lr: 0.000300
2025-05-27 01:43:50,721 - INFO - joeynmt.training - Epoch   9, Step:    27800, Batch Loss:     0.785214, Batch Acc: 0.756039, Tokens per Sec:     5221, Lr: 0.000300
2025-05-27 01:44:25,496 - INFO - joeynmt.training - Epoch   9, Step:    27900, Batch Loss:     0.791951, Batch Acc: 0.753276, Tokens per Sec:     5519, Lr: 0.000300
2025-05-27 01:45:01,609 - INFO - joeynmt.training - Epoch   9, Step:    28000, Batch Loss:     0.826181, Batch Acc: 0.752928, Tokens per Sec:     5393, Lr: 0.000300
2025-05-27 01:45:01,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:45:01,610 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:49:12,470 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 250.8494[sec], evaluation: 0.0000[sec]
2025-05-27 01:49:12,477 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 01:49:12,561 - INFO - joeynmt.helpers - delete models/bpe_2k_model/26000.ckpt
2025-05-27 01:49:12,564 - INFO - joeynmt.training - Example #0
2025-05-27 01:49:12,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:49:12,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:49:12,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ger', 'Jahre', 'lang', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'le', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'le', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ver@@', '<unk>', '@', 'k@@', '<unk>', '@', 'r@@', '<unk>', '@', 'au@@', '<unk>', '@', 'ft', '.', '</s>']
2025-05-27 01:49:12,564 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:49:12,564 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:49:12,564 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ger Jahre lang habe ich diese zwei Di<unk> @ as zeigen , um zu zeigen , dass die M<unk> @ oo<unk> @ le zeigen , dass die M<unk> @ oo<unk> @ le , die die letzten drei Millionen Jahre , die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , die die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ver<unk> @ k<unk> @ r<unk> @ au<unk> @ ft .
2025-05-27 01:49:12,564 - INFO - joeynmt.training - Example #1
2025-05-27 01:49:12,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:49:12,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:49:12,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'die', 'sch@@', '<unk>', '@', 'ät@@', '<unk>', '@', 'ze', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', ',', 'die', 'nicht', 'die', 'T@@', '<unk>', '@', 'at@@', '<unk>', '@', 'sa@@', '<unk>', '@', 'che', ',', '</s>']
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich die sch<unk> @ ät<unk> @ ze dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die T<unk> @ at<unk> @ sa<unk> @ che , die nicht die T<unk> @ at<unk> @ sa<unk> @ che ,
2025-05-27 01:49:12,565 - INFO - joeynmt.training - Example #2
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'es', 'sch@@', '<unk>', '@', 'ö@@', '<unk>', '@', 'n', ',', 'dass', 'wir', 'uns', 'die', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'mer@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', 'ver@@', '<unk>', '@', 'wen@@', '<unk>', '@', 'det', '.', '</s>']
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ es sch<unk> @ ö<unk> @ n , dass wir uns die G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ mer<unk> @ -<unk> @ Sy<unk> @ stem ver<unk> @ wen<unk> @ det .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - Example #3
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Hypothesis: Es hat in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - Example #4
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:49:12,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Vi@@', '<unk>', '@', 'el@@', '<unk>', '@', 'f@@', '<unk>', '@', 'alt', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:49:12,565 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Vi<unk> @ el<unk> @ f<unk> @ alt , die ich Ihnen zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren passiert ist .
2025-05-27 01:49:45,893 - INFO - joeynmt.training - Epoch   9, Step:    28100, Batch Loss:     0.763622, Batch Acc: 0.752997, Tokens per Sec:     5750, Lr: 0.000300
2025-05-27 01:49:54,568 - INFO - joeynmt.training - Epoch   9: total training loss 2634.38
2025-05-27 01:49:54,568 - INFO - joeynmt.training - EPOCH 10
2025-05-27 01:50:19,450 - INFO - joeynmt.training - Epoch  10, Step:    28200, Batch Loss:     0.833991, Batch Acc: 0.765009, Tokens per Sec:     5712, Lr: 0.000300
2025-05-27 01:50:53,221 - INFO - joeynmt.training - Epoch  10, Step:    28300, Batch Loss:     0.795856, Batch Acc: 0.763157, Tokens per Sec:     5692, Lr: 0.000300
2025-05-27 01:51:27,703 - INFO - joeynmt.training - Epoch  10, Step:    28400, Batch Loss:     0.767973, Batch Acc: 0.761238, Tokens per Sec:     5589, Lr: 0.000300
2025-05-27 01:52:04,323 - INFO - joeynmt.training - Epoch  10, Step:    28500, Batch Loss:     0.844464, Batch Acc: 0.760559, Tokens per Sec:     5266, Lr: 0.000300
2025-05-27 01:52:04,325 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:52:04,325 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 01:55:47,081 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 222.7450[sec], evaluation: 0.0000[sec]
2025-05-27 01:55:47,159 - INFO - joeynmt.helpers - delete models/bpe_2k_model/26500.ckpt
2025-05-27 01:55:47,164 - INFO - joeynmt.training - Example #0
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'und', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ ig Jahr habe ich diese zwei Di<unk> @ as zeigen , um zu zeigen , dass die M<unk> @ oo<unk> @ l<unk> @ k<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre , die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , die die letzten drei Millionen Jahre , und die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - Example #1
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'der', 'ern@@', '<unk>', '@', 'st', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ische', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'als', 'sehen', '.', '</s>']
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich der ern<unk> @ st dieses spe<unk> @ zi<unk> @ f<unk> @ ische Problem , weil es nicht die D<unk> @ am<unk> @ als sehen .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - Example #2
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ser', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'op@@', '<unk>', '@', 'f', 'von', 'uns', ',', 'das', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'en@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', 'kl@@', '<unk>', '@', 'op@@', '<unk>', '@', 'er@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ ser K<unk> @ l<unk> @ op<unk> @ f von uns , das kl<unk> @ op<unk> @ p<unk> @ en<unk> @ -<unk> @ Sy<unk> @ stem kl<unk> @ op<unk> @ er<unk> @ -<unk> @ Sy<unk> @ stem .
2025-05-27 01:55:47,165 - INFO - joeynmt.training - Example #3
2025-05-27 01:55:47,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 01:55:47,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 01:55:47,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'et@@', '<unk>', '@', 'zen', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 01:55:47,166 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 01:55:47,166 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 01:55:47,166 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ et<unk> @ zen in den W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 01:55:47,166 - INFO - joeynmt.training - Example #4
2025-05-27 01:55:47,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 01:55:47,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 01:55:47,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'sch@@', '<unk>', '@', 'l@@', '<unk>', '@', 'imm@@', '<unk>', '@', 'te', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'es', 'passiert', 'passiert', 'ist', '.', '</s>']
2025-05-27 01:55:47,166 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 01:55:47,166 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 01:55:47,166 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine sch<unk> @ l<unk> @ imm<unk> @ te Ver<unk> @ si<unk> @ on von dem , was es passiert passiert ist .
2025-05-27 01:56:24,461 - INFO - joeynmt.training - Epoch  10, Step:    28600, Batch Loss:     0.901613, Batch Acc: 0.759166, Tokens per Sec:     5314, Lr: 0.000300
2025-05-27 01:56:59,657 - INFO - joeynmt.training - Epoch  10, Step:    28700, Batch Loss:     0.802926, Batch Acc: 0.761199, Tokens per Sec:     5485, Lr: 0.000300
2025-05-27 01:57:35,434 - INFO - joeynmt.training - Epoch  10, Step:    28800, Batch Loss:     0.839471, Batch Acc: 0.758038, Tokens per Sec:     5380, Lr: 0.000300
2025-05-27 01:58:10,378 - INFO - joeynmt.training - Epoch  10, Step:    28900, Batch Loss:     0.763685, Batch Acc: 0.763197, Tokens per Sec:     5542, Lr: 0.000300
2025-05-27 01:58:45,431 - INFO - joeynmt.training - Epoch  10, Step:    29000, Batch Loss:     0.752918, Batch Acc: 0.757803, Tokens per Sec:     5488, Lr: 0.000300
2025-05-27 01:58:45,432 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 01:58:45,432 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:02:15,486 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 210.0429[sec], evaluation: 0.0000[sec]
2025-05-27 02:02:15,566 - INFO - joeynmt.helpers - delete models/bpe_2k_model/27000.ckpt
2025-05-27 02:02:15,572 - INFO - joeynmt.training - Example #0
2025-05-27 02:02:15,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 02:02:15,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 02:02:15,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'le', ',', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ge@@', '<unk>', '@', 'zeigt', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'le', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'der', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'etwa', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 02:02:15,572 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 02:02:15,572 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 02:02:15,572 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Di<unk> @ as zeigen , dass die zwei Di<unk> @ as zeigen , dass die M<unk> @ oo<unk> @ le , die die die letzten drei Millionen Jahre ge<unk> @ zeigt , dass die M<unk> @ oo<unk> @ le der U<unk> @ S<unk> @ A , der die die letzten drei Millionen Jahre , etwa der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 02:02:15,572 - INFO - joeynmt.training - Example #1
2025-05-27 02:02:15,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 02:02:15,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 02:02:15,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'Auf@@', '<unk>', '@', 'ga@@', '<unk>', '@', 'be', 'dieses', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'elle', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'als', 'sehen', '.', '</s>']
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die Auf<unk> @ ga<unk> @ be dieses spe<unk> @ zi<unk> @ elle Problem , weil es nicht die D<unk> @ am<unk> @ als sehen .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - Example #2
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'es', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'syste@@', '<unk>', '@', 'ms', '.', '</s>']
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ sk<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ es S<unk> @ in<unk> @ n des K<unk> @ li<unk> @ ma<unk> @ syste<unk> @ ms .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - Example #3
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'et@@', '<unk>', '@', 'zen', 'im', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ et<unk> @ zen im W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - Example #4
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 02:02:15,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Vi@@', '<unk>', '@', 'el@@', '<unk>', '@', 'f@@', '<unk>', '@', 'alt', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 02:02:15,573 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Vi<unk> @ el<unk> @ f<unk> @ alt , die ich Ihnen zei<unk> @ ge , ist eine Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahren passiert ist .
2025-05-27 02:02:51,658 - INFO - joeynmt.training - Epoch  10, Step:    29100, Batch Loss:     0.806346, Batch Acc: 0.759458, Tokens per Sec:     5295, Lr: 0.000300
2025-05-27 02:03:25,594 - INFO - joeynmt.training - Epoch  10, Step:    29200, Batch Loss:     0.768358, Batch Acc: 0.758752, Tokens per Sec:     5710, Lr: 0.000300
2025-05-27 02:04:00,473 - INFO - joeynmt.training - Epoch  10, Step:    29300, Batch Loss:     0.825232, Batch Acc: 0.759466, Tokens per Sec:     5556, Lr: 0.000300
2025-05-27 02:04:37,365 - INFO - joeynmt.training - Epoch  10, Step:    29400, Batch Loss:     0.828431, Batch Acc: 0.756910, Tokens per Sec:     5138, Lr: 0.000300
2025-05-27 02:05:11,537 - INFO - joeynmt.training - Epoch  10, Step:    29500, Batch Loss:     0.802224, Batch Acc: 0.757043, Tokens per Sec:     5553, Lr: 0.000300
2025-05-27 02:05:11,538 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 02:05:11,538 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:08:58,459 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.73, generation: 226.9099[sec], evaluation: 0.0000[sec]
2025-05-27 02:08:58,461 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 02:08:58,538 - INFO - joeynmt.helpers - delete models/bpe_2k_model/25000.ckpt
2025-05-27 02:08:58,541 - INFO - joeynmt.training - Example #0
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'bei@@', '<unk>', '@', 'den', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'en@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'al', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'os@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'etwa', 'etwa', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', 'war', '.', '</s>']
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese bei<unk> @ den Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ ss<unk> @ en<unk> @ zi<unk> @ al zeigen , dass die M<unk> @ os<unk> @ k<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre , etwa etwa die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen war .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - Example #1
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigen@@', '<unk>', '@', 'tlich', 'der', 'Ge@@', '<unk>', '@', 'gen@@', '<unk>', '@', 'stän@@', '<unk>', '@', 'de', 'des', 'spe@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'ellen', 'Proble@@', '<unk>', '@', 'me', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'ing', 'des', 'E@@', '<unk>', '@', 'is', 'zu', 'sehen', '.', '</s>']
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigen<unk> @ tlich der Ge<unk> @ gen<unk> @ stän<unk> @ de des spe<unk> @ zi<unk> @ ellen Proble<unk> @ me , weil es nicht die D<unk> @ ing des E<unk> @ is zu sehen .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - Example #2
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 02:08:58,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'e', 'ist', 'in', 'gew@@', '<unk>', '@', 'ie@@', '<unk>', '@', 'sen', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ne', ',', 'die', 'sich', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'e', 'zu', 'unser@@', '<unk>', '@', 'em', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'mer@@', '<unk>', '@', 't', '.', '</s>']
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ k<unk> @ at<unk> @ ur<unk> @ e ist in gew<unk> @ ie<unk> @ sen S<unk> @ in<unk> @ ne , die sich in gew<unk> @ is<unk> @ se K<unk> @ l<unk> @ im<unk> @ e zu unser<unk> @ em G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ mer<unk> @ t .
2025-05-27 02:08:58,542 - INFO - joeynmt.training - Example #3
2025-05-27 02:08:58,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 02:08:58,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 02:08:58,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'sich', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 02:08:58,543 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 02:08:58,543 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 02:08:58,543 - INFO - joeynmt.training - 	Hypothesis: Es hat sich in den W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 02:08:58,543 - INFO - joeynmt.training - Example #4
2025-05-27 02:08:58,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 02:08:58,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 02:08:58,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Vi@@', '<unk>', '@', 'el@@', '<unk>', '@', 'f@@', '<unk>', '@', 'alt', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', 'besch@@', '<unk>', '@', 'le@@', '<unk>', '@', 'un@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'te', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-27 02:08:58,543 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 02:08:58,543 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 02:08:58,543 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Vi<unk> @ el<unk> @ f<unk> @ alt , die ich Ihnen zeigen , ist eine besch<unk> @ le<unk> @ un<unk> @ ig<unk> @ te Ver<unk> @ si<unk> @ on von 2<unk> @ 5 Jahren .
2025-05-27 02:09:33,249 - INFO - joeynmt.training - Epoch  10, Step:    29600, Batch Loss:     0.846237, Batch Acc: 0.759130, Tokens per Sec:     5503, Lr: 0.000300
2025-05-27 02:10:09,273 - INFO - joeynmt.training - Epoch  10, Step:    29700, Batch Loss:     0.880997, Batch Acc: 0.759606, Tokens per Sec:     5337, Lr: 0.000300
2025-05-27 02:10:45,296 - INFO - joeynmt.training - Epoch  10, Step:    29800, Batch Loss:     0.843844, Batch Acc: 0.758311, Tokens per Sec:     5325, Lr: 0.000300
2025-05-27 02:11:18,593 - INFO - joeynmt.training - Epoch  10, Step:    29900, Batch Loss:     0.838979, Batch Acc: 0.758754, Tokens per Sec:     5619, Lr: 0.000300
2025-05-27 02:11:53,014 - INFO - joeynmt.training - Epoch  10, Step:    30000, Batch Loss:     0.932093, Batch Acc: 0.757128, Tokens per Sec:     5487, Lr: 0.000300
2025-05-27 02:11:53,015 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 02:11:53,015 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:15:37,310 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.61, acc:   0.72, generation: 224.2840[sec], evaluation: 0.0000[sec]
2025-05-27 02:15:37,314 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 02:15:37,393 - INFO - joeynmt.helpers - delete models/bpe_2k_model/28500.ckpt
2025-05-27 02:15:37,398 - INFO - joeynmt.training - Example #0
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'letz@@', '<unk>', '@', 'tes', 'Jahr', 'lie@@', '<unk>', '@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'zeigen', ',', 'dass', 'die', 'P@@', '<unk>', '@', 'o@@', '<unk>', '@', 'ss@@', '<unk>', '@', 'en@@', '<unk>', '@', 'heit', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', '<unk>', '@', 'gef@@', '<unk>', '@', 'äh@@', '<unk>', '@', 'r', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'r@@', '<unk>', '@', 'at@@', '<unk>', '@', 't', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Hypothesis: Und letz<unk> @ tes Jahr lie<unk> @ ß ich diese zwei Di<unk> @ as zeigen , dass die P<unk> @ o<unk> @ ss<unk> @ en<unk> @ heit , die in den letzten drei Millionen Jahren un<unk> @ gef<unk> @ äh<unk> @ r die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ r<unk> @ at<unk> @ t , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - Example #1
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Gr@@', '<unk>', '@', 'und', 'des', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'dieses', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ik@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'D@@', '<unk>', '@', 'am@@', '<unk>', '@', 'e', 'des', 'E@@', '<unk>', '@', 'is', '.', '</s>']
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Gr<unk> @ und des S<unk> @ in<unk> @ n dieses Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ ik<unk> @ -<unk> @ Problem , weil es nicht die D<unk> @ am<unk> @ e des E<unk> @ is .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - Example #2
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 'se', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', 'des', 'K@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma@@', '<unk>', '@', '-@@', '<unk>', '@', 'Sy@@', '<unk>', '@', 'stem', '.', '</s>']
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ se K<unk> @ l<unk> @ im<unk> @ a des K<unk> @ li<unk> @ ma<unk> @ -<unk> @ Sy<unk> @ stem .
2025-05-27 02:15:37,399 - INFO - joeynmt.training - Example #3
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 02:15:37,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'etzt', 'in', 'der', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 02:15:37,400 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 02:15:37,400 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 02:15:37,400 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ etzt in der W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 02:15:37,400 - INFO - joeynmt.training - Example #4
2025-05-27 02:15:37,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 02:15:37,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 02:15:37,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', 'sch@@', '<unk>', '@', 'le@@', '<unk>', '@', 'chte', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'die', 'letzten', '2@@', '<unk>', '@', '5', 'Jahre', 'ge@@', '<unk>', '@', 'scha@@', '<unk>', '@', 'h', '.', '</s>']
2025-05-27 02:15:37,400 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 02:15:37,400 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 02:15:37,400 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zeigen werde , ist eine sch<unk> @ le<unk> @ chte Ver<unk> @ si<unk> @ on von dem , was die letzten 2<unk> @ 5 Jahre ge<unk> @ scha<unk> @ h .
2025-05-27 02:16:12,681 - INFO - joeynmt.training - Epoch  10, Step:    30100, Batch Loss:     0.769602, Batch Acc: 0.753999, Tokens per Sec:     5474, Lr: 0.000300
2025-05-27 02:16:48,872 - INFO - joeynmt.training - Epoch  10, Step:    30200, Batch Loss:     0.812343, Batch Acc: 0.759730, Tokens per Sec:     5374, Lr: 0.000300
2025-05-27 02:17:23,590 - INFO - joeynmt.training - Epoch  10, Step:    30300, Batch Loss:     0.772324, Batch Acc: 0.759821, Tokens per Sec:     5541, Lr: 0.000300
2025-05-27 02:17:59,054 - INFO - joeynmt.training - Epoch  10, Step:    30400, Batch Loss:     0.895122, Batch Acc: 0.756916, Tokens per Sec:     5509, Lr: 0.000300
2025-05-27 02:18:32,622 - INFO - joeynmt.training - Epoch  10, Step:    30500, Batch Loss:     0.807960, Batch Acc: 0.758220, Tokens per Sec:     5670, Lr: 0.000300
2025-05-27 02:18:32,623 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 02:18:32,623 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:21:48,273 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.61, acc:   0.73, generation: 195.6392[sec], evaluation: 0.0000[sec]
2025-05-27 02:21:48,277 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 02:21:48,362 - INFO - joeynmt.helpers - delete models/bpe_2k_model/29000.ckpt
2025-05-27 02:21:48,364 - INFO - joeynmt.training - Example #0
2025-05-27 02:21:48,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 02:21:48,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 02:21:48,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or', 'kur@@', '<unk>', '@', 'z@@', '<unk>', '@', 'em', 'zei@@', '<unk>', '@', 'gte', 'ich', 'diese', 'zwei', 'Di@@', '<unk>', '@', 'as', 'sehen', ',', 'um', 'die', 'bei@@', '<unk>', '@', 'den', 'Di@@', '<unk>', '@', 'as', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'oo@@', '<unk>', '@', 'l@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'und', 'etwa', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', 'Prozent', 'ge@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ro@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pen', '.', '</s>']
2025-05-27 02:21:48,364 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 02:21:48,364 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 02:21:48,364 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or kur<unk> @ z<unk> @ em zei<unk> @ gte ich diese zwei Di<unk> @ as sehen , um die bei<unk> @ den Di<unk> @ as zu zeigen , dass die M<unk> @ oo<unk> @ l<unk> @ k<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre , und etwa die Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 Prozent ge<unk> @ k<unk> @ ro<unk> @ m<unk> @ pen .
2025-05-27 02:21:48,364 - INFO - joeynmt.training - Example #1
2025-05-27 02:21:48,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 02:21:48,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 02:21:48,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'wirklich', 'der', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ik@@', '<unk>', '@', '-@@', '<unk>', '@', 'Problem', ',', 'weil', 'es', 'nicht', 'die', 'T@@', '<unk>', '@', 'ra@@', '<unk>', '@', 'in@@', '<unk>', '@', 'er', 'des', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', 'zeigt', '.', '</s>']
2025-05-27 02:21:48,364 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 02:21:48,364 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 02:21:48,364 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist wirklich der Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ ik<unk> @ -<unk> @ Problem , weil es nicht die T<unk> @ ra<unk> @ in<unk> @ er des E<unk> @ is<unk> @ es zeigt .
2025-05-27 02:21:48,364 - INFO - joeynmt.training - Example #2
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'z@@', '<unk>', '@', 'eit', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'es', 'K@@', '<unk>', '@', 'l@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', ',', 'unser@@', '<unk>', '@', 'em', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Hypothesis: Die E<unk> @ is<unk> @ s<unk> @ z<unk> @ eit auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ es K<unk> @ l<unk> @ im<unk> @ a , unser<unk> @ em G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ a .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - Example #3
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'hat', 'in', 'den', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'k@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'den', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Hypothesis: Es hat in den W<unk> @ in<unk> @ ter und k<unk> @ ri<unk> @ m<unk> @ pt in den S<unk> @ omm<unk> @ er .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - Example #4
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 02:21:48,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'sehen', 'werde', ',', 'ist', 'eine', 'besch@@', '<unk>', '@', 'le@@', '<unk>', '@', 'un@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'te', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'dem', ',', 'was', 'es', 'passiert', 'ist', '.', '</s>']
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 02:21:48,365 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen sehen werde , ist eine besch<unk> @ le<unk> @ un<unk> @ ig<unk> @ te Ver<unk> @ si<unk> @ on von dem , was es passiert ist .
2025-05-27 02:22:24,627 - INFO - joeynmt.training - Epoch  10, Step:    30600, Batch Loss:     0.826974, Batch Acc: 0.758172, Tokens per Sec:     5280, Lr: 0.000300
2025-05-27 02:22:59,368 - INFO - joeynmt.training - Epoch  10, Step:    30700, Batch Loss:     0.761405, Batch Acc: 0.758119, Tokens per Sec:     5605, Lr: 0.000300
2025-05-27 02:23:33,621 - INFO - joeynmt.training - Epoch  10, Step:    30800, Batch Loss:     0.797926, Batch Acc: 0.758773, Tokens per Sec:     5554, Lr: 0.000300
2025-05-27 02:24:08,949 - INFO - joeynmt.training - Epoch  10, Step:    30900, Batch Loss:     0.876225, Batch Acc: 0.757709, Tokens per Sec:     5382, Lr: 0.000300
2025-05-27 02:24:43,672 - INFO - joeynmt.training - Epoch  10, Step:    31000, Batch Loss:     0.812278, Batch Acc: 0.757236, Tokens per Sec:     5573, Lr: 0.000300
2025-05-27 02:24:43,674 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 02:24:43,674 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:28:42,511 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.60, acc:   0.73, generation: 238.8266[sec], evaluation: 0.0000[sec]
2025-05-27 02:28:42,515 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 02:28:42,591 - INFO - joeynmt.helpers - delete models/bpe_2k_model/27500.ckpt
2025-05-27 02:28:42,597 - INFO - joeynmt.training - Example #0
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', '@@@', '@', 'or@@', '@@@', '@', 'ig', 'jaar', 'li@@', '@@@', '@', 'et', 'ik', 'deze', 'twee', 'di@@', '@@@', '@', 'a', '&apos;s', 'zien', 'om', 'aan', 'te', 't@@', '@@@', '@', 'onen', 'dat', 'de', 'p@@', '@@@', '@', 'oo@@', '@@@', '@', 'lij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', ',', 'die', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', '@@@', '@', 'te', 'had', 'van', 'het', 'va@@', '@@@', '@', 'st@@', '@@@', '@', 'el@@', '@@@', '@', 'and', 'van', 'de', 'V@@', '@@@', '@', 'S', ',', 'met', '4@@', '@@@', '@', '0', '%', 'ge@@', '@@@', '@', 'k@@', '@@@', '@', 'ro@@', '@@@', '@', 'm@@', '@@@', '@', 'pen', 'was', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zeigt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', ',', 'die', 'für', 'an@@', '@@@', '@', 'n@@', '@@@', '@', 'ä@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', '@@@', '@', 'ö@@', '@@@', '@', 'sse', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'aa@@', '@@@', '@', 'ten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Prozent', 'gesch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'or@@', '<unk>', '@', 'aus', 'wurde', 'ich', 'diesen', 'zwei', 'Di@@', '<unk>', '@', 'as', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'M@@', '<unk>', '@', 'ü@@', '<unk>', '@', 'l@@', '<unk>', '@', 'l@@', '<unk>', '@', 'sk@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'des', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'die', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', ',', 'die', 'die', 'die', 'Gr@@', '<unk>', '@', 'öß@@', '<unk>', '@', 'e', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'der', 'U@@', '<unk>', '@', 'S@@', '<unk>', '@', 'A', ',', 'mit', '4@@', '<unk>', '@', '0', '%', 'ver@@', '<unk>', '@', 'r@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ger@@', '<unk>', '@', 'n', '.', '</s>']
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Source:     V@@ or@@ ig jaar li@@ et ik deze twee di@@ a &apos;s zien om aan te t@@ onen dat de p@@ oo@@ lij@@ sk@@ a@@ p , die de af@@ gel@@ open drie miljoen jaar ongeveer de groot@@ te had van het va@@ st@@ el@@ and van de V@@ S , met 4@@ 0 % ge@@ k@@ ro@@ m@@ pen was .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Reference:  L@@ etz@@ tes Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zeigt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e , die für an@@ n@@ ä@@ her@@ n@@ d drei Millionen Jahre die Gr@@ ö@@ sse der unter@@ en 4@@ 8 St@@ aa@@ ten hatte , um 4@@ 0 Prozent gesch@@ ru@@ mp@@ ft ist .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ or<unk> @ aus wurde ich diesen zwei Di<unk> @ as , um zu zeigen , dass die M<unk> @ ü<unk> @ l<unk> @ l<unk> @ sk<unk> @ a<unk> @ p , die die letzten drei Millionen Jahre der Gr<unk> @ öß<unk> @ e des U<unk> @ S<unk> @ A , die die in den letzten drei Millionen Jahren , die die die Gr<unk> @ öß<unk> @ e der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % der U<unk> @ S<unk> @ A , mit 4<unk> @ 0 % ver<unk> @ r<unk> @ in<unk> @ ger<unk> @ n .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - Example #1
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', '@@@', '@', 'scha@@', '@@@', '@', 't', 'eigenlijk', 'de', 'ern@@', '@@@', '@', 'st', 'van', 'dit', 'spec@@', '@@@', '@', 'i@@', '@@@', '@', 'f@@', '@@@', '@', 'ie@@', '@@@', '@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', '@@@', '@', 'kte', 'van', 'het', 'ij@@', '@@@', '@', 's', 'laat', 'zien', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', '@@@', '@', 'ü@@', '@@@', '@', 'ckt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'ug', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'ft@@', '@@@', '@', 'igkeit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Proble@@', '@@@', '@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zeigt', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'der', 'Sp@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zi@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ik', 'dieses', 'The@@', '<unk>', '@', 'ma', ',', 'das', 'ist', ',', 'was', 'nicht', 'der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'en@@', '<unk>', '@', 'g@@', '<unk>', '@', 'än@@', '<unk>', '@', 'z@@', '<unk>', '@', 'lich', 'ist', ',', 'denn', 'es', 'nicht', 'der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'en@@', '<unk>', '@', 'ba@@', '<unk>', '@', 'h@@', '<unk>', '@', 'n', 'zeigt', '.', '</s>']
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Source:     Maar dit onder@@ scha@@ t eigenlijk de ern@@ st van dit spec@@ i@@ f@@ ie@@ ke probleem omdat het niet de di@@ kte van het ij@@ s laat zien .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Reference:  Aber dies dr@@ ü@@ ckt nicht star@@ k gen@@ ug die Er@@ n@@ st@@ ha@@ ft@@ igkeit dieses spe@@ zi@@ ellen Proble@@ ms aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zeigt .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist der Sp<unk> @ e<unk> @ zi<unk> @ f<unk> @ ik dieses The<unk> @ ma , das ist , was nicht der E<unk> @ is<unk> @ en<unk> @ g<unk> @ än<unk> @ z<unk> @ lich ist , denn es nicht der E<unk> @ is<unk> @ en<unk> @ ba<unk> @ h<unk> @ n zeigt .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - Example #2
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', '@@@', '@', 'sk@@', '@@@', '@', 'a@@', '@@@', '@', 'p', 'op', 'de', 'N@@', '@@@', '@', 'oor@@', '@@@', '@', 'd@@', '@@@', '@', 'p@@', '@@@', '@', 'ool', 'is', 'in', 'ze@@', '@@@', '@', 'ker@@', '@@@', '@', 'e', 'z@@', '@@@', '@', 'in', 'het', 'kl@@', '@@@', '@', 'op@@', '@@@', '@', 'p@@', '@@@', '@', 'end', 'har@@', '@@@', '@', 't', 'van', 'ons', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'aal', 'kl@@', '@@@', '@', 'im@@', '@@@', '@', 'aat@@', '@@@', '@', 'syste@@', '@@@', '@', 'em', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', '@@@', '@', 'is@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kti@@', '@@@', '@', 'sche', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'ap@@', '@@@', '@', 'p@@', '@@@', '@', 'e', 'das', 'sch@@', '@@@', '@', 'la@@', '@@@', '@', 'gende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'gl@@', '@@@', '@', 'ob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'ma@@', '@@@', '@', 'syste@@', '@@@', '@', 'ms', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'a@@', '<unk>', '@', 'p', 'auf', 'der', 'N@@', '<unk>', '@', 'or@@', '<unk>', '@', 'd@@', '<unk>', '@', 'po@@', '<unk>', '@', 'l', 'ist', 'in', 'gew@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'em', 'S@@', '<unk>', '@', 'in@@', '<unk>', '@', 'n', 'des', 'G@@', '<unk>', '@', 'lo@@', '<unk>', '@', 'b@@', '<unk>', '@', 'al', 'kl@@', '<unk>', '@', 'im@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Source:     De ij@@ sk@@ a@@ p op de N@@ oor@@ d@@ p@@ ool is in ze@@ ker@@ e z@@ in het kl@@ op@@ p@@ end har@@ t van ons gl@@ ob@@ aal kl@@ im@@ aat@@ syste@@ em .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Reference:  In gew@@ is@@ s@@ em S@@ in@@ ne ist die ar@@ kti@@ sche E@@ is@@ k@@ ap@@ p@@ e das sch@@ la@@ gende Her@@ z unser@@ es gl@@ ob@@ alen K@@ li@@ ma@@ syste@@ ms .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - 	Hypothesis: Der E<unk> @ is<unk> @ k<unk> @ a<unk> @ p auf der N<unk> @ or<unk> @ d<unk> @ po<unk> @ l ist in gew<unk> @ is<unk> @ s<unk> @ em S<unk> @ in<unk> @ n des G<unk> @ lo<unk> @ b<unk> @ al kl<unk> @ im<unk> @ a .
2025-05-27 02:28:42,598 - INFO - joeynmt.training - Example #3
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', '@@@', '@', 'et', 'uit', 'in', 'de', 'win@@', '@@@', '@', 'ter', 'en', 'k@@', '@@@', '@', 'ri@@', '@@@', '@', 'm@@', '@@@', '@', 'pt', 'in', 'de', 'z@@', '@@@', '@', 'om@@', '@@@', '@', 'er', '.']
2025-05-27 02:28:42,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', '@@@', '@', 'äch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'ru@@', '@@@', '@', 'mp@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'omm@@', '@@@', '@', 'er', '.']
2025-05-27 02:28:42,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', '<unk>', '@', 'et@@', '<unk>', '@', 'zen', 'im', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'und', 'K@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pt', 'in', 'der', 'S@@', '<unk>', '@', 'omm@@', '<unk>', '@', 'er', '.', '</s>']
2025-05-27 02:28:42,599 - INFO - joeynmt.training - 	Source:     Het z@@ et uit in de win@@ ter en k@@ ri@@ m@@ pt in de z@@ om@@ er .
2025-05-27 02:28:42,599 - INFO - joeynmt.training - 	Reference:  Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ ru@@ mp@@ ft im S@@ omm@@ er .
2025-05-27 02:28:42,599 - INFO - joeynmt.training - 	Hypothesis: Es s<unk> @ et<unk> @ zen im W<unk> @ in<unk> @ ter und K<unk> @ ri<unk> @ m<unk> @ pt in der S<unk> @ omm<unk> @ er .
2025-05-27 02:28:42,599 - INFO - joeynmt.training - Example #4
2025-05-27 02:28:42,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', '@@@', '@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'vers@@', '@@@', '@', 'n@@', '@@@', '@', 'elde', 'ver@@', '@@@', '@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', '@@@', '@', 'gel@@', '@@@', '@', 'open', '2@@', '@@@', '@', '5', 'jaar', 'is', 'gebeur@@', '@@@', '@', 'd', '.']
2025-05-27 02:28:42,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 02:28:42,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', '<unk>', '@', 'ste', 'Di@@', '<unk>', '@', 'a', ',', 'die', 'ich', 'Ihnen', 'zei@@', '<unk>', '@', 'ge', ',', 'ist', 'eine', 'sch@@', '<unk>', '@', 'l@@', '<unk>', '@', 'imm@@', '<unk>', '@', 'te', 'Ver@@', '<unk>', '@', 'si@@', '<unk>', '@', 'on', 'von', 'den', 'letzten', '2@@', '<unk>', '@', '5', 'Jahren', '.', '</s>']
2025-05-27 02:28:42,599 - INFO - joeynmt.training - 	Source:     De volgende di@@ a die ik laat zien is een vers@@ n@@ elde ver@@ sie van wat er de af@@ gel@@ open 2@@ 5 jaar is gebeur@@ d .
2025-05-27 02:28:42,599 - INFO - joeynmt.training - 	Reference:  Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letzten 2@@ 5 Jahren passiert ist .
2025-05-27 02:28:42,599 - INFO - joeynmt.training - 	Hypothesis: Die näch<unk> @ ste Di<unk> @ a , die ich Ihnen zei<unk> @ ge , ist eine sch<unk> @ l<unk> @ imm<unk> @ te Ver<unk> @ si<unk> @ on von den letzten 2<unk> @ 5 Jahren .
2025-05-27 02:29:19,753 - INFO - joeynmt.training - Epoch  10, Step:    31100, Batch Loss:     0.842844, Batch Acc: 0.752495, Tokens per Sec:     5196, Lr: 0.000300
2025-05-27 02:29:52,770 - INFO - joeynmt.training - Epoch  10, Step:    31200, Batch Loss:     0.813952, Batch Acc: 0.755899, Tokens per Sec:     5734, Lr: 0.000300
2025-05-27 02:30:10,426 - INFO - joeynmt.training - Epoch  10: total training loss 2589.55
2025-05-27 02:30:10,426 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-27 02:30:10,426 - INFO - joeynmt.training - Best validation result (greedy) at step    31000:   2.60 ppl.
2025-05-27 02:30:10,438 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 02:30:10,472 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 02:30:10,505 - INFO - joeynmt.helpers - Load model from /Users/merilinsilva/Documents/SemestersUZH/4thSem/MT/exercises/msousa_spareek_mt_exercise_04/mt-exercise-4/models/bpe_2k_model/31000.ckpt.
2025-05-27 02:30:10,508 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1997),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1997),
	loss_function=None)
2025-05-27 02:30:10,509 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-27 02:30:10,509 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 02:30:10,509 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:33:35,701 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 205.1812[sec], evaluation: 0.0000[sec]
2025-05-27 02:33:35,703 - INFO - joeynmt.prediction - Translations saved to: /Users/merilinsilva/Documents/SemestersUZH/4thSem/MT/exercises/msousa_spareek_mt_exercise_04/mt-exercise-4/models/bpe_2k_model/00031000.hyps.dev.
2025-05-27 02:33:35,704 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-27 02:33:35,704 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 02:33:35,704 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 02:38:00,612 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 264.8931[sec], evaluation: 0.0000[sec]
2025-05-27 02:38:00,615 - INFO - joeynmt.prediction - Translations saved to: /Users/merilinsilva/Documents/SemestersUZH/4thSem/MT/exercises/msousa_spareek_mt_exercise_04/mt-exercise-4/models/bpe_2k_model/00031000.hyps.test.
