2025-05-27 20:15:17,158 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 20:15:17,158 - INFO - joeynmt.helpers -                           cfg.name : word_level_model
2025-05-27 20:15:17,158 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 20:15:17,158 - INFO - joeynmt.helpers -                     cfg.data.train : data/my_lang_pair/train
2025-05-27 20:15:17,158 - INFO - joeynmt.helpers -                       cfg.data.dev : data/my_lang_pair/dev
2025-05-27 20:15:17,158 - INFO - joeynmt.helpers -                      cfg.data.test : data/my_lang_pair/test
2025-05-27 20:15:17,158 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -                 cfg.data.src.level : word
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 2000
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : space
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -                 cfg.data.trg.level : word
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 2000
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : space
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/word_level_model
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 20:15:17,159 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 20:15:17,160 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 20:15:17,161 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 20:15:17,161 - INFO - joeynmt.tokenizers - nl tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2025-05-27 20:15:17,161 - INFO - joeynmt.tokenizers - de tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2025-05-27 20:15:17,161 - INFO - joeynmt.data - Loading train set...
2025-05-27 20:15:17,276 - INFO - joeynmt.data - Building vocabulary...
2025-05-27 20:15:18,377 - INFO - joeynmt.data - Loading dev set...
2025-05-27 20:15:18,380 - INFO - joeynmt.data - Loading test set...
2025-05-27 20:15:18,382 - INFO - joeynmt.data - Data loaded.
2025-05-27 20:15:18,382 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-27 20:15:18,382 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-27 20:15:18,382 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-27 20:15:18,382 - INFO - joeynmt.data - First training example:
	[SRC] Al Gore over het afwenden van de klimaatcrisis
	[TRG] Al Gore : Die Abwendung der Klimakatastrophe
2025-05-27 20:15:18,382 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) de (7) een (8) het (9) van
2025-05-27 20:15:18,382 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) die (7) und (8) der (9) ist
2025-05-27 20:15:18,382 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2025-05-27 20:15:18,382 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2025-05-27 20:15:18,384 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 20:15:18,435 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 20:15:18,437 - INFO - joeynmt.model - Total params: 3925248
2025-05-27 20:15:18,438 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2025-05-27 20:15:18,438 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-27 20:15:18,438 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-27 20:15:18,438 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-27 20:15:18,439 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-27 20:15:18,439 - INFO - joeynmt.training - EPOCH 1
2025-05-27 20:15:32,398 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.947054, Batch Acc: 0.205763, Tokens per Sec:     5057, Lr: 0.000300
2025-05-27 20:15:46,125 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.871315, Batch Acc: 0.250533, Tokens per Sec:     4959, Lr: 0.000300
2025-05-27 20:16:00,174 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.649611, Batch Acc: 0.280527, Tokens per Sec:     4930, Lr: 0.000300
2025-05-27 20:16:15,626 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.617707, Batch Acc: 0.297708, Tokens per Sec:     4531, Lr: 0.000300
2025-05-27 20:16:31,381 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.415823, Batch Acc: 0.313694, Tokens per Sec:     4390, Lr: 0.000300
2025-05-27 20:16:31,381 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:16:31,381 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:16:58,563 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.56, ppl:  12.91, acc:   0.31, generation: 27.1770[sec], evaluation: 0.0000[sec]
2025-05-27 20:16:58,564 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:16:58,676 - INFO - joeynmt.training - Example #0
2025-05-27 20:16:58,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:16:58,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:16:58,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'ich', '<unk>', ',', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', 'zu', '<unk>', ',', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> ich <unk> , die <unk> <unk> , die <unk> zu <unk> , die <unk> <unk> , die <unk> <unk> .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - Example #1
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , die <unk> <unk> , die <unk> <unk> , die <unk> <unk> <unk> .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - Example #2
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> <unk> <unk> <unk> <unk> .
2025-05-27 20:16:58,677 - INFO - joeynmt.training - Example #3
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:16:58,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', '<unk>', '<unk>', 'und', '<unk>', '<unk>', 'und', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:16:58,678 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:16:58,678 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:16:58,678 - INFO - joeynmt.training - 	Hypothesis: Es <unk> <unk> <unk> und <unk> <unk> und <unk> <unk> .
2025-05-27 20:16:58,678 - INFO - joeynmt.training - Example #4
2025-05-27 20:16:58,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:16:58,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:16:58,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', ',', 'die', 'ich', '<unk>', ',', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:16:58,678 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:16:58,678 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:16:58,678 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> , die ich <unk> , die <unk> <unk> , die <unk> <unk> <unk> .
2025-05-27 20:17:14,411 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.407016, Batch Acc: 0.329707, Tokens per Sec:     4316, Lr: 0.000300
2025-05-27 20:17:30,367 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.413744, Batch Acc: 0.340078, Tokens per Sec:     4265, Lr: 0.000300
2025-05-27 20:17:46,534 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.497526, Batch Acc: 0.344837, Tokens per Sec:     4259, Lr: 0.000300
2025-05-27 20:18:02,045 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.532080, Batch Acc: 0.352463, Tokens per Sec:     4485, Lr: 0.000300
2025-05-27 20:18:18,081 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.163221, Batch Acc: 0.359586, Tokens per Sec:     4247, Lr: 0.000300
2025-05-27 20:18:18,081 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:18:18,081 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:18:42,928 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.51, acc:   0.35, generation: 24.8417[sec], evaluation: 0.0000[sec]
2025-05-27 20:18:42,929 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:18:43,044 - INFO - joeynmt.training - Example #0
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'ich', 'zwei', 'Jahre', ',', 'zwei', 'Jahre', '<unk>', ',', 'um', 'die', '<unk>', 'zu', 'sehen', ',', 'dass', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> ich zwei Jahre , zwei Jahre <unk> , um die <unk> zu sehen , dass die <unk> <unk> <unk> <unk> .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - Example #1
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', '<unk>', 'der', '<unk>', '<unk>', ',', 'weil', 'es', 'es', 'nicht', '<unk>', ',', 'weil', 'es', 'es', 'nicht', '<unk>', '.', '</s>']
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das <unk> der <unk> <unk> , weil es es nicht <unk> , weil es es nicht <unk> .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - Example #2
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:18:43,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:18:43,045 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , <unk> <unk> <unk> .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - Example #3
2025-05-27 20:18:43,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:18:43,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:18:43,046 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'war', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '.', '</s>']
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Hypothesis: Es war in der <unk> und <unk> in der <unk> .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - Example #4
2025-05-27 20:18:43,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:18:43,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:18:43,046 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', ',', 'die', 'ich', '<unk>', '<unk>', 'ist', 'ein', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:18:43,046 - INFO - joeynmt.training - 	Hypothesis: Die <unk> , die ich <unk> <unk> ist ein <unk> <unk> .
2025-05-27 20:18:59,540 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.296868, Batch Acc: 0.367044, Tokens per Sec:     4163, Lr: 0.000300
2025-05-27 20:19:16,023 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.024337, Batch Acc: 0.378654, Tokens per Sec:     4187, Lr: 0.000300
2025-05-27 20:19:32,470 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.139030, Batch Acc: 0.385601, Tokens per Sec:     4323, Lr: 0.000300
2025-05-27 20:19:48,893 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.195654, Batch Acc: 0.389631, Tokens per Sec:     4147, Lr: 0.000300
2025-05-27 20:20:06,504 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     1.959103, Batch Acc: 0.396630, Tokens per Sec:     3909, Lr: 0.000300
2025-05-27 20:20:06,504 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:20:06,504 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:20:22,045 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   8.99, acc:   0.37, generation: 15.5357[sec], evaluation: 0.0000[sec]
2025-05-27 20:20:22,046 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:20:22,161 - INFO - joeynmt.training - Example #0
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'ich', 'diese', 'zwei', 'Jahre', '<unk>', ',', 'um', 'um', 'zu', '<unk>', ',', 'um', 'die', '<unk>', ',', 'die', 'die', '<unk>', '<unk>', 'Millionen', 'Jahre', '<unk>', '.', '</s>']
2025-05-27 20:20:22,162 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:20:22,162 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:20:22,162 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> ich diese zwei Jahre <unk> , um um zu <unk> , um die <unk> , die die <unk> <unk> Millionen Jahre <unk> .
2025-05-27 20:20:22,162 - INFO - joeynmt.training - Example #1
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'des', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'der', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:20:22,162 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:20:22,162 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:20:22,162 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> des <unk> Problem , weil es nicht die <unk> der <unk> des <unk> <unk> .
2025-05-27 20:20:22,162 - INFO - joeynmt.training - Example #2
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:20:22,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'die', '<unk>', '<unk>', 'ist', ',', 'in', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf die <unk> <unk> ist , in <unk> <unk> , die <unk> <unk> <unk> .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - Example #3
2025-05-27 20:20:22,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:20:22,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:20:22,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '.', '</s>']
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Hypothesis: Und es <unk> aus der <unk> und <unk> in der <unk> .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - Example #4
2025-05-27 20:20:22,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:20:22,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:20:22,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'ich', '<unk>', 'die', 'ich', '<unk>', 'sehen', ',', 'was', 'es', 'ist', 'ein', '<unk>', '<unk>', '<unk>', ',', 'was', 'die', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'Jahr', 'ist', '.', '</s>']
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:20:22,163 - INFO - joeynmt.training - 	Hypothesis: Und die ich <unk> die ich <unk> sehen , was es ist ein <unk> <unk> <unk> , was die letzten letzten letzten letzten letzten letzten letzten letzten Jahr ist .
2025-05-27 20:20:37,866 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.061917, Batch Acc: 0.406243, Tokens per Sec:     4391, Lr: 0.000300
2025-05-27 20:20:53,928 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     1.954002, Batch Acc: 0.410384, Tokens per Sec:     4216, Lr: 0.000300
2025-05-27 20:21:10,457 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.102137, Batch Acc: 0.414232, Tokens per Sec:     4251, Lr: 0.000300
2025-05-27 20:21:27,245 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.969024, Batch Acc: 0.420329, Tokens per Sec:     4058, Lr: 0.000300
2025-05-27 20:21:44,186 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.784098, Batch Acc: 0.430869, Tokens per Sec:     4217, Lr: 0.000300
2025-05-27 20:21:44,186 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:21:44,186 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:22:06,232 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.09, ppl:   8.12, acc:   0.40, generation: 22.0405[sec], evaluation: 0.0000[sec]
2025-05-27 20:22:06,233 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:22:06,363 - INFO - joeynmt.training - Example #0
2025-05-27 20:22:06,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:22:06,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:22:06,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahren', 'ich', 'diese', 'zwei', 'Jahren', 'Jahren', ',', 'dass', 'ich', 'diese', 'zwei', 'Jahren', '<unk>', ',', 'die', '<unk>', ',', 'die', '<unk>', '<unk>', ',', 'die', 'letzten', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahren ich diese zwei Jahren Jahren , dass ich diese zwei Jahren <unk> , die <unk> , die <unk> <unk> , die letzten <unk> <unk> .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - Example #1
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', ',', 'die', '<unk>', 'des', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> , die <unk> des <unk> , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - Example #2
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'die', '<unk>', 'ist', 'in', '<unk>', '<unk>', ',', '</s>']
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:22:06,364 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf die <unk> ist in <unk> <unk> ,
2025-05-27 20:22:06,364 - INFO - joeynmt.training - Example #3
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:22:06,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:22:06,365 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:22:06,365 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:22:06,365 - INFO - joeynmt.training - 	Hypothesis: Das <unk> aus der <unk> und <unk> in den <unk> <unk> .
2025-05-27 20:22:06,365 - INFO - joeynmt.training - Example #4
2025-05-27 20:22:06,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:22:06,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:22:06,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', ',', 'die', 'ich', 'sehen', ',', 'die', 'ich', 'sehen', ',', 'was', 'es', 'ist', '.', '</s>']
2025-05-27 20:22:06,365 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:22:06,365 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:22:06,365 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> , die ich sehen , die ich sehen , was es ist .
2025-05-27 20:22:23,126 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.910597, Batch Acc: 0.430984, Tokens per Sec:     4151, Lr: 0.000300
2025-05-27 20:22:39,828 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.004709, Batch Acc: 0.429701, Tokens per Sec:     4257, Lr: 0.000300
2025-05-27 20:22:57,031 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.959687, Batch Acc: 0.436789, Tokens per Sec:     4060, Lr: 0.000300
2025-05-27 20:23:14,058 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.788157, Batch Acc: 0.441682, Tokens per Sec:     4138, Lr: 0.000300
2025-05-27 20:23:30,606 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.796472, Batch Acc: 0.446775, Tokens per Sec:     4074, Lr: 0.000300
2025-05-27 20:23:30,606 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:23:30,606 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:23:55,835 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.58, acc:   0.41, generation: 25.2235[sec], evaluation: 0.0000[sec]
2025-05-27 20:23:55,835 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:23:55,970 - INFO - joeynmt.training - Example #0
2025-05-27 20:23:55,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:23:55,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:23:55,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Jahre', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Jahre <unk> <unk> .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - Example #1
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', ',', 'die', '<unk>', 'des', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> , die <unk> des <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - Example #2
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> .
2025-05-27 20:23:55,972 - INFO - joeynmt.training - Example #3
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:23:55,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:23:55,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '.', '</s>']
2025-05-27 20:23:55,973 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:23:55,973 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:23:55,973 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in den <unk> und <unk> in den <unk> .
2025-05-27 20:23:55,973 - INFO - joeynmt.training - Example #4
2025-05-27 20:23:55,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:23:55,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:23:55,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'ich', 'sehen', ',', 'ist', 'eine', '<unk>', '<unk>', ',', 'was', 'wir', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', '.', '</s>']
2025-05-27 20:23:55,973 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:23:55,973 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:23:55,973 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> ich sehen , ist eine <unk> <unk> , was wir in den letzten 25 Jahren ist .
2025-05-27 20:24:13,236 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.964183, Batch Acc: 0.444731, Tokens per Sec:     4028, Lr: 0.000300
2025-05-27 20:24:30,102 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     1.841057, Batch Acc: 0.447178, Tokens per Sec:     4093, Lr: 0.000300
2025-05-27 20:24:33,862 - INFO - joeynmt.training - Epoch   1: total training loss 6085.25
2025-05-27 20:24:33,862 - INFO - joeynmt.training - EPOCH 2
2025-05-27 20:24:46,730 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:     1.913522, Batch Acc: 0.461464, Tokens per Sec:     4230, Lr: 0.000300
2025-05-27 20:25:03,387 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:     1.863148, Batch Acc: 0.462121, Tokens per Sec:     4121, Lr: 0.000300
2025-05-27 20:25:20,081 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:     1.771477, Batch Acc: 0.463930, Tokens per Sec:     4240, Lr: 0.000300
2025-05-27 20:25:20,082 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:25:20,082 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:25:48,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.15, acc:   0.42, generation: 28.7729[sec], evaluation: 0.0000[sec]
2025-05-27 20:25:48,861 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:25:48,988 - INFO - joeynmt.helpers - delete models/word_level_model/500.ckpt
2025-05-27 20:25:48,994 - INFO - joeynmt.training - Example #0
2025-05-27 20:25:48,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:25:48,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:25:48,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', '<unk>', ',', 'die', 'die', '<unk>', ',', 'die', 'die', '<unk>', 'der', 'USA', ',', 'die', '<unk>', 'der', 'USA', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die <unk> , die die <unk> , die die <unk> der USA , die <unk> der USA , mit 40 Prozent <unk> .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - Example #1
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'dass', 'die', '<unk>', 'dieses', '<unk>', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', 'sehen', '.', '</s>']
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , dass die <unk> dieses <unk> Problem ist , weil es nicht die <unk> des <unk> <unk> sehen .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - Example #2
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', ',', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> , <unk> <unk> .
2025-05-27 20:25:48,995 - INFO - joeynmt.training - Example #3
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:25:48,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '.', '</s>']
2025-05-27 20:25:48,996 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:25:48,996 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:25:48,996 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in den <unk> .
2025-05-27 20:25:48,996 - INFO - joeynmt.training - Example #4
2025-05-27 20:25:48,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:25:48,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:25:48,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'nächste', '<unk>', ',', 'die', 'ich', 'zeigen', ',', 'ist', 'eine', '<unk>', '<unk>', ',', 'was', 'es', 'in', 'den', 'letzten', '25', 'Jahren', '.', '</s>']
2025-05-27 20:25:48,996 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:25:48,996 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:25:48,996 - INFO - joeynmt.training - 	Hypothesis: Die nächste nächste <unk> , die ich zeigen , ist eine <unk> <unk> , was es in den letzten 25 Jahren .
2025-05-27 20:26:05,409 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:     1.839034, Batch Acc: 0.465876, Tokens per Sec:     4193, Lr: 0.000300
2025-05-27 20:26:21,410 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     1.839510, Batch Acc: 0.465294, Tokens per Sec:     4300, Lr: 0.000300
2025-05-27 20:26:37,942 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     1.725671, Batch Acc: 0.467714, Tokens per Sec:     4147, Lr: 0.000300
2025-05-27 20:26:54,626 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     1.725908, Batch Acc: 0.472300, Tokens per Sec:     3966, Lr: 0.000300
2025-05-27 20:27:11,374 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     1.790034, Batch Acc: 0.469632, Tokens per Sec:     4050, Lr: 0.000300
2025-05-27 20:27:11,375 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:27:11,375 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:27:35,299 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.43, generation: 23.9191[sec], evaluation: 0.0000[sec]
2025-05-27 20:27:35,301 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:27:35,431 - INFO - joeynmt.helpers - delete models/word_level_model/1000.ckpt
2025-05-27 20:27:35,433 - INFO - joeynmt.training - Example #0
2025-05-27 20:27:35,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:27:35,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:27:35,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'die', 'zwei', 'Jahre', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Jahre', '<unk>', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Jahre', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:27:35,433 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:27:35,433 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um die zwei Jahre <unk> , die die letzten drei Jahre <unk> <unk> , die die letzten drei Jahre <unk> <unk> <unk> .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - Example #1
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'die', '<unk>', 'des', '<unk>', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , die <unk> des <unk> <unk> , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - Example #2
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - Example #3
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:27:35,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:27:35,434 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:27:35,435 - INFO - joeynmt.training - 	Hypothesis: Und das <unk> aus der <unk> und <unk> in den Sommer .
2025-05-27 20:27:35,435 - INFO - joeynmt.training - Example #4
2025-05-27 20:27:35,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:27:35,435 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:27:35,435 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', ',', 'die', 'ich', 'zeigen', 'zeigen', ',', 'ist', 'ein', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', 'ist', '.', '</s>']
2025-05-27 20:27:35,435 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:27:35,435 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:27:35,435 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> , die ich zeigen zeigen , ist ein <unk> Version von dem letzten 25 Jahren ist .
2025-05-27 20:27:52,252 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     1.916763, Batch Acc: 0.469995, Tokens per Sec:     4151, Lr: 0.000300
2025-05-27 20:28:08,965 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     1.701838, Batch Acc: 0.475226, Tokens per Sec:     4168, Lr: 0.000300
2025-05-27 20:28:25,354 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     1.715238, Batch Acc: 0.474408, Tokens per Sec:     4131, Lr: 0.000300
2025-05-27 20:28:41,493 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     1.918915, Batch Acc: 0.472415, Tokens per Sec:     4183, Lr: 0.000300
2025-05-27 20:28:58,438 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     1.663006, Batch Acc: 0.479506, Tokens per Sec:     4175, Lr: 0.000300
2025-05-27 20:28:58,439 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:28:58,439 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:29:24,209 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.68, acc:   0.44, generation: 25.7645[sec], evaluation: 0.0000[sec]
2025-05-27 20:29:24,210 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:29:24,338 - INFO - joeynmt.helpers - delete models/word_level_model/1500.ckpt
2025-05-27 20:29:24,341 - INFO - joeynmt.training - Example #0
2025-05-27 20:29:24,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:29:24,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:29:24,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', ',', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', '.', '</s>']
2025-05-27 20:29:24,341 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:29:24,341 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:29:24,341 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> Jahre <unk> ich diese beiden <unk> , die <unk> , die letzten drei Millionen Jahre <unk> hatte .
2025-05-27 20:29:24,341 - INFO - joeynmt.training - Example #1
2025-05-27 20:29:24,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:29:24,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:29:24,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', 'des', '<unk>', '<unk>', 'sehen', '.', '</s>']
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> , weil es nicht die <unk> des <unk> <unk> des <unk> <unk> sehen .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - Example #2
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', ',', 'das', '<unk>', 'Herz', 'von', 'uns', '<unk>', '.', '</s>']
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> , das <unk> Herz von uns <unk> .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - Example #3
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den Sommer <unk> .
2025-05-27 20:29:24,342 - INFO - joeynmt.training - Example #4
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:29:24,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'zeigen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', '<unk>', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 20:29:24,343 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:29:24,343 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:29:24,343 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich zeigen zeigen , ist eine <unk> Version von <unk> , was in den letzten 25 Jahren passiert ist .
2025-05-27 20:29:41,092 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.805595, Batch Acc: 0.484696, Tokens per Sec:     4209, Lr: 0.000300
2025-05-27 20:29:57,834 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.809741, Batch Acc: 0.481913, Tokens per Sec:     4179, Lr: 0.000300
2025-05-27 20:30:14,592 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.629929, Batch Acc: 0.485855, Tokens per Sec:     4240, Lr: 0.000300
2025-05-27 20:30:31,061 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.730613, Batch Acc: 0.481600, Tokens per Sec:     4208, Lr: 0.000300
2025-05-27 20:30:46,963 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.703577, Batch Acc: 0.482177, Tokens per Sec:     4329, Lr: 0.000300
2025-05-27 20:30:46,964 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:30:46,964 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:31:13,003 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.44, generation: 26.0341[sec], evaluation: 0.0000[sec]
2025-05-27 20:31:13,004 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:31:13,138 - INFO - joeynmt.helpers - delete models/word_level_model/2000.ckpt
2025-05-27 20:31:13,143 - INFO - joeynmt.training - Example #0
2025-05-27 20:31:13,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:31:13,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:31:13,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', 'Folie', '<unk>', ',', 'um', 'die', '<unk>', ',', 'die', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', 'USA', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>']
2025-05-27 20:31:13,143 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:31:13,143 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:31:13,143 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei Folie <unk> , um die <unk> , die die <unk> , die die letzten drei Millionen Jahre der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> der <unk> <unk> der <unk> der <unk> der USA , die die letzten drei Millionen Jahre <unk>
2025-05-27 20:31:13,143 - INFO - joeynmt.training - Example #1
2025-05-27 20:31:13,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:31:13,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:31:13,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'die', '<unk>', 'des', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 20:31:13,143 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:31:13,143 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:31:13,143 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist die <unk> des <unk> , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 20:31:13,143 - INFO - joeynmt.training - Example #2
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - Example #3
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den Sommer .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - Example #4
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:31:13,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigt', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', '25', 'Jahre', 'passiert', '.', '</s>']
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:31:13,144 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigt , ist eine <unk> Version von dem <unk> 25 Jahre passiert .
2025-05-27 20:31:29,383 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.716186, Batch Acc: 0.485516, Tokens per Sec:     4129, Lr: 0.000300
2025-05-27 20:31:45,749 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.615575, Batch Acc: 0.481568, Tokens per Sec:     4048, Lr: 0.000300
2025-05-27 20:32:02,031 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.753421, Batch Acc: 0.488670, Tokens per Sec:     4195, Lr: 0.000300
2025-05-27 20:32:18,425 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.772323, Batch Acc: 0.490014, Tokens per Sec:     4303, Lr: 0.000300
2025-05-27 20:32:34,543 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.732348, Batch Acc: 0.485997, Tokens per Sec:     4258, Lr: 0.000300
2025-05-27 20:32:34,543 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:32:34,543 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:33:02,285 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.39, acc:   0.44, generation: 27.7362[sec], evaluation: 0.0000[sec]
2025-05-27 20:33:02,286 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:33:02,417 - INFO - joeynmt.helpers - delete models/word_level_model/2500.ckpt
2025-05-27 20:33:02,420 - INFO - joeynmt.training - Example #0
2025-05-27 20:33:02,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:33:02,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:33:02,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'die', '<unk>', ',', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'der', 'Größe', 'der', '<unk>', '<unk>', '<unk>', 'hatte', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um die <unk> , die <unk> , die letzten drei Millionen Jahre der Größe der <unk> <unk> <unk> hatte , mit 40 Prozent <unk> .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - Example #1
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'die', '<unk>', 'des', '<unk>', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , die <unk> des <unk> <unk> , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - Example #2
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '</s>']
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:33:02,421 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> ist in <unk> <unk> <unk> , <unk> <unk> ,
2025-05-27 20:33:02,421 - INFO - joeynmt.training - Example #3
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:33:02,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:33:02,422 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:33:02,422 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:33:02,422 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den Sommer .
2025-05-27 20:33:02,422 - INFO - joeynmt.training - Example #4
2025-05-27 20:33:02,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:33:02,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:33:02,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', '<unk>', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', '.', '</s>']
2025-05-27 20:33:02,422 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:33:02,422 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:33:02,422 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich <unk> , ist eine <unk> Version von dem <unk> , was in den letzten 25 Jahren ist .
2025-05-27 20:33:18,957 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.616884, Batch Acc: 0.493281, Tokens per Sec:     4174, Lr: 0.000300
2025-05-27 20:33:35,049 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.650430, Batch Acc: 0.491089, Tokens per Sec:     4352, Lr: 0.000300
2025-05-27 20:33:51,295 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.734021, Batch Acc: 0.491825, Tokens per Sec:     4213, Lr: 0.000300
2025-05-27 20:34:07,514 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.769227, Batch Acc: 0.489035, Tokens per Sec:     4259, Lr: 0.000300
2025-05-27 20:34:15,900 - INFO - joeynmt.training - Epoch   2: total training loss 4767.49
2025-05-27 20:34:15,900 - INFO - joeynmt.training - EPOCH 3
2025-05-27 20:34:23,044 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:     1.460586, Batch Acc: 0.504836, Tokens per Sec:     4588, Lr: 0.000300
2025-05-27 20:34:23,045 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:34:23,045 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:34:48,202 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.28, acc:   0.45, generation: 25.1515[sec], evaluation: 0.0000[sec]
2025-05-27 20:34:48,204 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:34:48,341 - INFO - joeynmt.helpers - delete models/word_level_model/3000.ckpt
2025-05-27 20:34:48,342 - INFO - joeynmt.training - Example #0
2025-05-27 20:34:48,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:34:48,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:34:48,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', ',', 'mit', '40', 'Prozent', 'der', '<unk>', '.', '</s>']
2025-05-27 20:34:48,342 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:34:48,342 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:34:48,342 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> der <unk> der <unk> der <unk> , mit 40 Prozent der <unk> .
2025-05-27 20:34:48,342 - INFO - joeynmt.training - Example #1
2025-05-27 20:34:48,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:34:48,343 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:34:48,343 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:34:48,343 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 20:34:48,343 - INFO - joeynmt.training - Example #2
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', ',', '</s>']
2025-05-27 20:34:48,343 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:34:48,343 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:34:48,343 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> ,
2025-05-27 20:34:48,343 - INFO - joeynmt.training - Example #3
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:34:48,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:34:48,344 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:34:48,344 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:34:48,344 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den Sommer .
2025-05-27 20:34:48,344 - INFO - joeynmt.training - Example #4
2025-05-27 20:34:48,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:34:48,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:34:48,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahre', '<unk>', '.', '</s>']
2025-05-27 20:34:48,344 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:34:48,344 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:34:48,344 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahre <unk> .
2025-05-27 20:35:05,073 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:     1.662621, Batch Acc: 0.508342, Tokens per Sec:     4029, Lr: 0.000300
2025-05-27 20:35:21,916 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:     1.856469, Batch Acc: 0.511552, Tokens per Sec:     4053, Lr: 0.000300
2025-05-27 20:35:38,053 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:     1.563035, Batch Acc: 0.506826, Tokens per Sec:     4253, Lr: 0.000300
2025-05-27 20:35:54,888 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:     1.399613, Batch Acc: 0.506415, Tokens per Sec:     4148, Lr: 0.000300
2025-05-27 20:36:11,567 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:     1.662792, Batch Acc: 0.503529, Tokens per Sec:     4171, Lr: 0.000300
2025-05-27 20:36:11,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:36:11,567 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:36:36,285 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.45, generation: 24.7125[sec], evaluation: 0.0000[sec]
2025-05-27 20:36:36,286 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:36:36,420 - INFO - joeynmt.helpers - delete models/word_level_model/3500.ckpt
2025-05-27 20:36:36,423 - INFO - joeynmt.training - Example #0
2025-05-27 20:36:36,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:36:36,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:36:36,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', '<unk>', 'hatte', '.', '</s>']
2025-05-27 20:36:36,423 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> , um den letzten drei Millionen Jahre <unk> , die die letzten drei Millionen Jahre Jahre <unk> hatte .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - Example #1
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - Example #2
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', ',', '</s>']
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:36:36,424 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> ,
2025-05-27 20:36:36,424 - INFO - joeynmt.training - Example #3
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:36:36,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:36:36,425 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:36:36,425 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:36:36,425 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in den Sommer .
2025-05-27 20:36:36,425 - INFO - joeynmt.training - Example #4
2025-05-27 20:36:36,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:36:36,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:36:36,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', 'passiert', '.', '</s>']
2025-05-27 20:36:36,425 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:36:36,425 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:36:36,425 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem <unk> , was in den letzten 25 Jahren ist passiert .
2025-05-27 20:36:53,183 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:     1.612296, Batch Acc: 0.506971, Tokens per Sec:     4054, Lr: 0.000300
2025-05-27 20:37:09,679 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:     1.544679, Batch Acc: 0.508838, Tokens per Sec:     4113, Lr: 0.000300
2025-05-27 20:37:26,282 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     1.511218, Batch Acc: 0.509166, Tokens per Sec:     4226, Lr: 0.000300
2025-05-27 20:37:42,702 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     1.723399, Batch Acc: 0.504177, Tokens per Sec:     4206, Lr: 0.000300
2025-05-27 20:37:59,055 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     1.498725, Batch Acc: 0.506595, Tokens per Sec:     4224, Lr: 0.000300
2025-05-27 20:37:59,056 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:37:59,056 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:38:22,975 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.18, acc:   0.46, generation: 23.9144[sec], evaluation: 0.0000[sec]
2025-05-27 20:38:22,977 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:38:23,100 - INFO - joeynmt.helpers - delete models/word_level_model/4000.ckpt
2025-05-27 20:38:23,107 - INFO - joeynmt.training - Example #0
2025-05-27 20:38:23,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:38:23,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:38:23,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', 'die', '<unk>', 'drei', 'Millionen', 'Jahre', '<unk>', '.', '</s>']
2025-05-27 20:38:23,107 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:38:23,107 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:38:23,107 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre <unk> hatte , die die <unk> drei Millionen Jahre <unk> .
2025-05-27 20:38:23,107 - INFO - joeynmt.training - Example #1
2025-05-27 20:38:23,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:38:23,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:38:23,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'dass', 'das', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 20:38:23,107 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:38:23,107 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:38:23,107 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , dass das <unk> Problem , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - Example #2
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', ',', 'in', 'einer', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> , in einer <unk> <unk> <unk> .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - Example #3
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den Sommer .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - Example #4
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:38:23,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:38:23,108 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:38:23,109 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:38:40,019 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     1.670156, Batch Acc: 0.508468, Tokens per Sec:     4068, Lr: 0.000300
2025-05-27 20:38:56,721 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     1.522695, Batch Acc: 0.508150, Tokens per Sec:     4033, Lr: 0.000300
2025-05-27 20:39:13,844 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     1.662781, Batch Acc: 0.510540, Tokens per Sec:     4095, Lr: 0.000300
2025-05-27 20:39:30,481 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     1.721910, Batch Acc: 0.505418, Tokens per Sec:     4143, Lr: 0.000300
2025-05-27 20:39:47,104 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     1.722326, Batch Acc: 0.506362, Tokens per Sec:     4128, Lr: 0.000300
2025-05-27 20:39:47,104 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:39:47,104 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:40:13,208 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.11, acc:   0.46, generation: 26.0993[sec], evaluation: 0.0000[sec]
2025-05-27 20:40:13,211 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:40:13,343 - INFO - joeynmt.helpers - delete models/word_level_model/4500.ckpt
2025-05-27 20:40:13,343 - INFO - joeynmt.training - Example #0
2025-05-27 20:40:13,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:40:13,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:40:13,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', '.', '</s>']
2025-05-27 20:40:13,343 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:40:13,343 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:40:13,343 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre <unk> hatte .
2025-05-27 20:40:13,343 - INFO - joeynmt.training - Example #1
2025-05-27 20:40:13,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:40:13,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:40:13,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'dass', 'das', '<unk>', 'dieses', '<unk>', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , dass das <unk> dieses <unk> Problem ist , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - Example #2
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , dass wir uns <unk> <unk> <unk> .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - Example #3
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den Sommer .
2025-05-27 20:40:13,344 - INFO - joeynmt.training - Example #4
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:40:13,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', '<unk>', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'es', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:40:13,345 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:40:13,345 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:40:13,345 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich <unk> , ist eine <unk> Version von dem , was es in den letzten 25 Jahren passiert .
2025-05-27 20:40:30,180 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     1.593884, Batch Acc: 0.507789, Tokens per Sec:     4108, Lr: 0.000300
2025-05-27 20:40:47,081 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     1.625890, Batch Acc: 0.508037, Tokens per Sec:     4071, Lr: 0.000300
2025-05-27 20:41:03,328 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     1.580833, Batch Acc: 0.512475, Tokens per Sec:     4268, Lr: 0.000300
2025-05-27 20:41:19,259 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     1.657618, Batch Acc: 0.505556, Tokens per Sec:     4344, Lr: 0.000300
2025-05-27 20:41:34,831 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     1.557027, Batch Acc: 0.511851, Tokens per Sec:     4530, Lr: 0.000300
2025-05-27 20:41:34,831 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:41:34,831 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:42:04,430 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.01, acc:   0.46, generation: 29.5935[sec], evaluation: 0.0000[sec]
2025-05-27 20:42:04,432 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:42:04,562 - INFO - joeynmt.helpers - delete models/word_level_model/5000.ckpt
2025-05-27 20:42:04,567 - INFO - joeynmt.training - Example #0
2025-05-27 20:42:04,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:42:04,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:42:04,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', '.', '</s>']
2025-05-27 20:42:04,567 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:42:04,567 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:42:04,567 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> hatte .
2025-05-27 20:42:04,567 - INFO - joeynmt.training - Example #1
2025-05-27 20:42:04,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:42:04,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:42:04,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', 'sehen', '.', '</s>']
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> sehen .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - Example #2
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , das <unk> Herz unserer <unk> <unk> .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - Example #3
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'den', '<unk>', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus den <unk> und <unk> in den Sommer .
2025-05-27 20:42:04,568 - INFO - joeynmt.training - Example #4
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:42:04,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', ',', 'dass', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahre', 'passiert', '.', '</s>']
2025-05-27 20:42:04,569 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:42:04,569 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:42:04,569 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen ist , dass eine <unk> Version von dem , was in den letzten 25 Jahre passiert .
2025-05-27 20:42:21,247 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     1.719117, Batch Acc: 0.508720, Tokens per Sec:     4014, Lr: 0.000300
2025-05-27 20:42:38,049 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     1.626216, Batch Acc: 0.506123, Tokens per Sec:     4117, Lr: 0.000300
2025-05-27 20:42:55,090 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     1.739759, Batch Acc: 0.510097, Tokens per Sec:     4095, Lr: 0.000300
2025-05-27 20:43:12,041 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     1.621578, Batch Acc: 0.506690, Tokens per Sec:     4008, Lr: 0.000300
2025-05-27 20:43:28,965 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.531501, Batch Acc: 0.508307, Tokens per Sec:     4044, Lr: 0.000300
2025-05-27 20:43:28,966 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:43:28,966 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:43:53,919 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.00, acc:   0.46, generation: 24.9475[sec], evaluation: 0.0000[sec]
2025-05-27 20:43:53,920 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:43:54,050 - INFO - joeynmt.helpers - delete models/word_level_model/5500.ckpt
2025-05-27 20:43:54,054 - INFO - joeynmt.training - Example #0
2025-05-27 20:43:54,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', 'hatte', '.', '</s>']
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre <unk> <unk> hatte .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - Example #1
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', ',', 'das', '<unk>', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist , das <unk> <unk> Problem , weil es nicht die <unk> des <unk> des <unk> <unk> .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - Example #2
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:43:54,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:43:54,055 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - Example #3
2025-05-27 20:43:54,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:43:54,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:43:54,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - Example #4
2025-05-27 20:43:54,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:43:54,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:43:54,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:43:54,056 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:44:10,593 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     1.560014, Batch Acc: 0.508953, Tokens per Sec:     4213, Lr: 0.000300
2025-05-27 20:44:24,971 - INFO - joeynmt.training - Epoch   3: total training loss 4429.59
2025-05-27 20:44:24,973 - INFO - joeynmt.training - EPOCH 4
2025-05-27 20:44:27,063 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:     1.481198, Batch Acc: 0.532102, Tokens per Sec:     4145, Lr: 0.000300
2025-05-27 20:44:44,449 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:     1.441219, Batch Acc: 0.534116, Tokens per Sec:     4047, Lr: 0.000300
2025-05-27 20:45:00,923 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:     1.524627, Batch Acc: 0.530565, Tokens per Sec:     4272, Lr: 0.000300
2025-05-27 20:45:17,398 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:     1.627902, Batch Acc: 0.528563, Tokens per Sec:     4220, Lr: 0.000300
2025-05-27 20:45:17,398 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:45:17,399 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:45:40,123 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.97, acc:   0.46, generation: 22.7192[sec], evaluation: 0.0000[sec]
2025-05-27 20:45:40,124 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:45:40,268 - INFO - joeynmt.helpers - delete models/word_level_model/6000.ckpt
2025-05-27 20:45:40,272 - INFO - joeynmt.training - Example #0
2025-05-27 20:45:40,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:45:40,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:45:40,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'hat', 'ich', 'diese', 'beiden', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', '<unk>', 'hatte', ',', 'die', 'die', '<unk>', 'der', '<unk>', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 20:45:40,272 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:45:40,272 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:45:40,272 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr hat ich diese beiden <unk> <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre Jahre <unk> hatte , die die <unk> der <unk> , mit 40 Prozent <unk> .
2025-05-27 20:45:40,272 - INFO - joeynmt.training - Example #1
2025-05-27 20:45:40,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:45:40,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:45:40,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:45:40,272 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:45:40,272 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:45:40,272 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - Example #2
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', 'das', '<unk>', '<unk>', 'unseres', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> auf der <unk> ist in <unk> Weise das <unk> <unk> unseres <unk> <unk> .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - Example #3
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> im Sommer .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - Example #4
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:45:40,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'zeige', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:45:40,273 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich zeige ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:45:56,594 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:     1.396728, Batch Acc: 0.526825, Tokens per Sec:     4239, Lr: 0.000300
2025-05-27 20:46:12,402 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:     1.636608, Batch Acc: 0.527505, Tokens per Sec:     4305, Lr: 0.000300
2025-05-27 20:46:28,741 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:     1.623051, Batch Acc: 0.524270, Tokens per Sec:     4306, Lr: 0.000300
2025-05-27 20:46:44,846 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:     1.411867, Batch Acc: 0.521216, Tokens per Sec:     4196, Lr: 0.000300
2025-05-27 20:47:01,227 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:     1.708321, Batch Acc: 0.520155, Tokens per Sec:     4165, Lr: 0.000300
2025-05-27 20:47:01,227 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:47:01,228 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:47:24,993 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.97, acc:   0.46, generation: 23.7604[sec], evaluation: 0.0000[sec]
2025-05-27 20:47:24,994 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:47:25,109 - INFO - joeynmt.helpers - delete models/word_level_model/6500.ckpt
2025-05-27 20:47:25,114 - INFO - joeynmt.training - Example #0
2025-05-27 20:47:25,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:47:25,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:47:25,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'drei', 'Millionen', 'Jahre', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', 'USA', ',', '<unk>', ',', '40', 'Prozent', '<unk>', 'war', '.', '</s>']
2025-05-27 20:47:25,114 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:47:25,114 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:47:25,114 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in drei Millionen Jahre <unk> der <unk> der <unk> der USA , <unk> , 40 Prozent <unk> war .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - Example #1
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', ',', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> , die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - Example #2
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', 'eine', 'Art', '<unk>', '<unk>', ',', 'die', 'uns', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , eine Art <unk> <unk> , die uns <unk> <unk> .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - Example #3
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:47:25,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:47:25,115 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer .
2025-05-27 20:47:25,116 - INFO - joeynmt.training - Example #4
2025-05-27 20:47:25,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:47:25,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:47:25,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 20:47:25,116 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:47:25,116 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:47:25,116 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 20:47:41,529 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:     1.640259, Batch Acc: 0.524326, Tokens per Sec:     4159, Lr: 0.000300
2025-05-27 20:47:57,748 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:     1.449440, Batch Acc: 0.524938, Tokens per Sec:     4217, Lr: 0.000300
2025-05-27 20:48:14,308 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:     1.617343, Batch Acc: 0.522712, Tokens per Sec:     4130, Lr: 0.000300
2025-05-27 20:48:31,104 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     1.507538, Batch Acc: 0.524746, Tokens per Sec:     4141, Lr: 0.000300
2025-05-27 20:48:47,377 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     1.564052, Batch Acc: 0.524452, Tokens per Sec:     4284, Lr: 0.000300
2025-05-27 20:48:47,377 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:48:47,377 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:49:09,391 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.90, acc:   0.47, generation: 22.0091[sec], evaluation: 0.0000[sec]
2025-05-27 20:49:09,392 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:49:09,505 - INFO - joeynmt.helpers - delete models/word_level_model/7000.ckpt
2025-05-27 20:49:09,509 - INFO - joeynmt.training - Example #0
2025-05-27 20:49:09,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:49:09,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:49:09,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', 'in', 'den', 'USA', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahre <unk> hatte , die in den USA , mit 40 Prozent <unk> .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - Example #1
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen', '.', '</s>']
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> sehen .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - Example #2
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> .
2025-05-27 20:49:09,510 - INFO - joeynmt.training - Example #3
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:49:09,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:49:09,511 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:49:09,511 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:49:09,511 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer <unk> und <unk> im Sommer .
2025-05-27 20:49:09,511 - INFO - joeynmt.training - Example #4
2025-05-27 20:49:09,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:49:09,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:49:09,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:49:09,511 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:49:09,511 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:49:09,511 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:49:26,441 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     1.515602, Batch Acc: 0.522363, Tokens per Sec:     4004, Lr: 0.000300
2025-05-27 20:49:42,571 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     1.614804, Batch Acc: 0.519777, Tokens per Sec:     4237, Lr: 0.000300
2025-05-27 20:49:59,465 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     1.581642, Batch Acc: 0.522948, Tokens per Sec:     4235, Lr: 0.000300
2025-05-27 20:50:16,694 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     1.423396, Batch Acc: 0.523623, Tokens per Sec:     3969, Lr: 0.000300
2025-05-27 20:50:33,506 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     1.460509, Batch Acc: 0.525476, Tokens per Sec:     4032, Lr: 0.000300
2025-05-27 20:50:33,507 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:50:33,507 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:51:01,202 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.86, acc:   0.47, generation: 27.6904[sec], evaluation: 0.0000[sec]
2025-05-27 20:51:01,203 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:51:01,316 - INFO - joeynmt.helpers - delete models/word_level_model/7500.ckpt
2025-05-27 20:51:01,320 - INFO - joeynmt.training - Example #0
2025-05-27 20:51:01,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:51:01,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:51:01,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '.', '</s>']
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre <unk> .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - Example #1
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', 'Problem', ',', 'dass', 'dieses', '<unk>', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', 'sehen', '.', '</s>']
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> Problem , dass dieses <unk> Problem ist , weil es nicht die <unk> des <unk> <unk> sehen .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - Example #2
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir uns <unk> <unk> <unk> .
2025-05-27 20:51:01,321 - INFO - joeynmt.training - Example #3
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:51:01,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:51:01,322 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:51:01,322 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:51:01,322 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer <unk> und <unk> im Sommer .
2025-05-27 20:51:01,322 - INFO - joeynmt.training - Example #4
2025-05-27 20:51:01,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:51:01,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:51:01,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:51:01,322 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:51:01,322 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:51:01,322 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:51:17,683 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:     1.556325, Batch Acc: 0.521890, Tokens per Sec:     4132, Lr: 0.000300
2025-05-27 20:51:34,499 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:     1.545576, Batch Acc: 0.519801, Tokens per Sec:     3970, Lr: 0.000300
2025-05-27 20:51:51,438 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:     1.595603, Batch Acc: 0.527946, Tokens per Sec:     4137, Lr: 0.000300
2025-05-27 20:52:08,549 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:     1.547367, Batch Acc: 0.521961, Tokens per Sec:     3832, Lr: 0.000300
2025-05-27 20:52:25,584 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:     1.532932, Batch Acc: 0.517754, Tokens per Sec:     3984, Lr: 0.000300
2025-05-27 20:52:25,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:52:25,584 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:52:48,685 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.47, generation: 23.0958[sec], evaluation: 0.0000[sec]
2025-05-27 20:52:48,687 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:52:48,797 - INFO - joeynmt.helpers - delete models/word_level_model/8000.ckpt
2025-05-27 20:52:48,800 - INFO - joeynmt.training - Example #0
2025-05-27 20:52:48,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:52:48,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:52:48,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', 'hatte', ',', 'die', 'die', '<unk>', 'der', 'USA', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 20:52:48,800 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:52:48,800 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:52:48,800 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in drei Millionen Jahre <unk> <unk> hatte , die die <unk> der USA , mit 40 Prozent <unk> .
2025-05-27 20:52:48,800 - INFO - joeynmt.training - Example #1
2025-05-27 20:52:48,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:52:48,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:52:48,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'des', '<unk>', 'sehen', '.', '</s>']
2025-05-27 20:52:48,800 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> des <unk> sehen .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - Example #2
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , das <unk> Herz unserer <unk> <unk> .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - Example #3
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer .
2025-05-27 20:52:48,801 - INFO - joeynmt.training - Example #4
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:52:48,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 20:52:48,802 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:52:48,802 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:52:48,802 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 20:53:06,602 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:     1.594032, Batch Acc: 0.525994, Tokens per Sec:     3921, Lr: 0.000300
2025-05-27 20:53:22,948 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     1.601572, Batch Acc: 0.520346, Tokens per Sec:     4273, Lr: 0.000300
2025-05-27 20:53:39,228 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     1.651411, Batch Acc: 0.525772, Tokens per Sec:     4315, Lr: 0.000300
2025-05-27 20:53:55,482 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     1.692723, Batch Acc: 0.521698, Tokens per Sec:     4317, Lr: 0.000300
2025-05-27 20:53:59,095 - INFO - joeynmt.training - Epoch   4: total training loss 4237.44
2025-05-27 20:53:59,095 - INFO - joeynmt.training - EPOCH 5
2025-05-27 20:54:12,050 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:     1.397210, Batch Acc: 0.543091, Tokens per Sec:     4012, Lr: 0.000300
2025-05-27 20:54:12,050 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:54:12,050 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:54:38,140 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.82, acc:   0.47, generation: 26.0844[sec], evaluation: 0.0000[sec]
2025-05-27 20:54:38,270 - INFO - joeynmt.helpers - delete models/word_level_model/8500.ckpt
2025-05-27 20:54:38,272 - INFO - joeynmt.training - Example #0
2025-05-27 20:54:38,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:54:38,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:54:38,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre <unk> hatte , die letzten drei Millionen Jahre <unk> <unk> .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - Example #1
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'das', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> das <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - Example #2
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir das <unk> Herz unseres <unk> <unk> <unk> .
2025-05-27 20:54:38,273 - INFO - joeynmt.training - Example #3
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:54:38,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:54:38,274 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:54:38,274 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:54:38,274 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 20:54:38,274 - INFO - joeynmt.training - Example #4
2025-05-27 20:54:38,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:54:38,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:54:38,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:54:38,274 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:54:38,274 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:54:38,274 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:54:54,693 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:     1.491959, Batch Acc: 0.539371, Tokens per Sec:     4110, Lr: 0.000300
2025-05-27 20:55:10,567 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:     1.512347, Batch Acc: 0.540303, Tokens per Sec:     4381, Lr: 0.000300
2025-05-27 20:55:27,452 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:     1.484612, Batch Acc: 0.546696, Tokens per Sec:     4125, Lr: 0.000300
2025-05-27 20:55:44,090 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:     1.508542, Batch Acc: 0.542567, Tokens per Sec:     4199, Lr: 0.000300
2025-05-27 20:56:00,146 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:     1.491174, Batch Acc: 0.540482, Tokens per Sec:     4325, Lr: 0.000300
2025-05-27 20:56:00,147 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:56:00,147 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:56:23,374 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.83, acc:   0.47, generation: 23.2217[sec], evaluation: 0.0000[sec]
2025-05-27 20:56:23,492 - INFO - joeynmt.helpers - delete models/word_level_model/9000.ckpt
2025-05-27 20:56:23,495 - INFO - joeynmt.training - Example #0
2025-05-27 20:56:23,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:56:23,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:56:23,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte', ',', 'die', 'die', '<unk>', ',', 'die', 'in', 'den', 'USA', ',', 'mit', '40', 'Prozent', '<unk>', 'war', '.', '</s>']
2025-05-27 20:56:23,495 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:56:23,495 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:56:23,495 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahren <unk> hatte , die die <unk> , die in den USA , mit 40 Prozent <unk> war .
2025-05-27 20:56:23,495 - INFO - joeynmt.training - Example #1
2025-05-27 20:56:23,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:56:23,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:56:23,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', ',', 'dass', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:56:23,495 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:56:23,495 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:56:23,495 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist , dass das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 20:56:23,495 - INFO - joeynmt.training - Example #2
2025-05-27 20:56:23,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:56:23,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:56:23,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', ',', 'dass', 'wir', 'unser', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:56:23,496 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:56:23,497 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:56:23,497 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise , dass wir unser <unk> <unk> <unk> .
2025-05-27 20:56:23,497 - INFO - joeynmt.training - Example #3
2025-05-27 20:56:23,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:56:23,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:56:23,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:56:23,497 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:56:23,497 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:56:23,497 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer <unk> und <unk> im Sommer .
2025-05-27 20:56:23,497 - INFO - joeynmt.training - Example #4
2025-05-27 20:56:23,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:56:23,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:56:23,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', '<unk>', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 20:56:23,498 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:56:23,498 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:56:23,498 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von <unk> , was in den letzten 25 Jahren passiert ist .
2025-05-27 20:56:40,480 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:     1.419707, Batch Acc: 0.539967, Tokens per Sec:     4195, Lr: 0.000300
2025-05-27 20:56:57,963 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:     1.409597, Batch Acc: 0.539598, Tokens per Sec:     4010, Lr: 0.000300
2025-05-27 20:57:14,174 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:     1.570217, Batch Acc: 0.537192, Tokens per Sec:     4276, Lr: 0.000300
2025-05-27 20:57:30,143 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     1.430240, Batch Acc: 0.534745, Tokens per Sec:     4345, Lr: 0.000300
2025-05-27 20:57:47,473 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     1.454189, Batch Acc: 0.535791, Tokens per Sec:     3957, Lr: 0.000300
2025-05-27 20:57:47,473 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:57:47,473 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:58:11,524 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.79, acc:   0.47, generation: 24.0459[sec], evaluation: 0.0000[sec]
2025-05-27 20:58:11,525 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:58:11,642 - INFO - joeynmt.helpers - delete models/word_level_model/9500.ckpt
2025-05-27 20:58:11,645 - INFO - joeynmt.training - Example #0
2025-05-27 20:58:11,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 20:58:11,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 20:58:11,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'die', '<unk>', 'zu', 'zeigen', ',', 'dass', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '.', '</s>']
2025-05-27 20:58:11,645 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 20:58:11,645 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 20:58:11,645 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um die <unk> zu zeigen , dass die letzten drei Millionen Jahre <unk> , die in den letzten drei Millionen Jahren <unk> .
2025-05-27 20:58:11,645 - INFO - joeynmt.training - Example #1
2025-05-27 20:58:11,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 20:58:11,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 20:58:11,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist tatsächlich die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - Example #2
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', 'ist', 'es', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '.', '</s>']
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , ist es , dass wir uns <unk> <unk> .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - Example #3
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 20:58:11,646 - INFO - joeynmt.training - Example #4
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:58:11,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'Ihnen', 'zeigen', 'ist', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 20:58:11,647 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 20:58:11,647 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 20:58:11,647 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen Ihnen zeigen ist , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 20:58:28,241 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     1.492771, Batch Acc: 0.534532, Tokens per Sec:     4121, Lr: 0.000300
2025-05-27 20:58:43,421 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     1.481459, Batch Acc: 0.543453, Tokens per Sec:     4685, Lr: 0.000300
2025-05-27 20:59:01,804 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     1.397313, Batch Acc: 0.536141, Tokens per Sec:     3719, Lr: 0.000300
2025-05-27 20:59:19,984 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:     1.466286, Batch Acc: 0.534212, Tokens per Sec:     3818, Lr: 0.000300
2025-05-27 20:59:38,388 - INFO - joeynmt.training - Epoch   5, Step:    12500, Batch Loss:     1.514025, Batch Acc: 0.536776, Tokens per Sec:     3783, Lr: 0.000300
2025-05-27 20:59:38,388 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:59:38,388 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:00:04,151 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.76, acc:   0.47, generation: 25.7573[sec], evaluation: 0.0000[sec]
2025-05-27 21:00:04,152 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:00:04,262 - INFO - joeynmt.helpers - delete models/word_level_model/10000.ckpt
2025-05-27 21:00:04,264 - INFO - joeynmt.training - Example #0
2025-05-27 21:00:04,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:00:04,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:00:04,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte', ',', 'die', '<unk>', ',', 'die', '<unk>', ',', 'die', 'in', 'den', 'USA', ',', 'um', '40', '%', '<unk>', '.', '</s>']
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese zwei <unk> , um zu zeigen , dass die <unk> , die in drei Millionen Jahren <unk> hatte , die <unk> , die <unk> , die in den USA , um 40 % <unk> .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - Example #1
2025-05-27 21:00:04,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:00:04,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:00:04,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - Example #2
2025-05-27 21:00:04,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:00:04,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:00:04,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinn', ',', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '.', '</s>']
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinn , das <unk> Herz unserer <unk> .
2025-05-27 21:00:04,265 - INFO - joeynmt.training - Example #3
2025-05-27 21:00:04,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:00:04,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:00:04,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:00:04,266 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:00:04,266 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:00:04,266 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:00:04,266 - INFO - joeynmt.training - Example #4
2025-05-27 21:00:04,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:00:04,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:00:04,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:00:04,266 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:00:04,266 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:00:04,266 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:00:22,986 - INFO - joeynmt.training - Epoch   5, Step:    12600, Batch Loss:     1.603810, Batch Acc: 0.532779, Tokens per Sec:     3644, Lr: 0.000300
2025-05-27 21:00:40,399 - INFO - joeynmt.training - Epoch   5, Step:    12700, Batch Loss:     1.502693, Batch Acc: 0.534007, Tokens per Sec:     3927, Lr: 0.000300
2025-05-27 21:00:58,954 - INFO - joeynmt.training - Epoch   5, Step:    12800, Batch Loss:     1.513678, Batch Acc: 0.532090, Tokens per Sec:     3654, Lr: 0.000300
2025-05-27 21:01:16,671 - INFO - joeynmt.training - Epoch   5, Step:    12900, Batch Loss:     1.562356, Batch Acc: 0.533376, Tokens per Sec:     3962, Lr: 0.000300
2025-05-27 21:01:35,088 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:     1.395227, Batch Acc: 0.536347, Tokens per Sec:     3705, Lr: 0.000300
2025-05-27 21:01:35,088 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:01:35,088 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:02:04,504 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.75, acc:   0.47, generation: 29.4109[sec], evaluation: 0.0000[sec]
2025-05-27 21:02:04,505 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:02:04,619 - INFO - joeynmt.helpers - delete models/word_level_model/11500.ckpt
2025-05-27 21:02:04,623 - INFO - joeynmt.training - Example #0
2025-05-27 21:02:04,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:02:04,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:02:04,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'alt', 'war', '.', '</s>']
2025-05-27 21:02:04,623 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:02:04,623 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:02:04,623 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre Jahre alt war .
2025-05-27 21:02:04,623 - INFO - joeynmt.training - Example #1
2025-05-27 21:02:04,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:02:04,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:02:04,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:02:04,623 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:02:04,623 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:02:04,623 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:02:04,623 - INFO - joeynmt.training - Example #2
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir uns <unk> <unk> .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - Example #3
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'im', 'Sommer', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Hypothesis: Es <unk> im Sommer in den <unk> und <unk> im Sommer .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - Example #4
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:02:04,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:02:04,624 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:02:23,767 - INFO - joeynmt.training - Epoch   5, Step:    13100, Batch Loss:     1.524462, Batch Acc: 0.528449, Tokens per Sec:     3538, Lr: 0.000300
2025-05-27 21:02:42,900 - INFO - joeynmt.training - Epoch   5, Step:    13200, Batch Loss:     1.540997, Batch Acc: 0.532690, Tokens per Sec:     3697, Lr: 0.000300
2025-05-27 21:03:02,227 - INFO - joeynmt.training - Epoch   5, Step:    13300, Batch Loss:     1.431038, Batch Acc: 0.531905, Tokens per Sec:     3569, Lr: 0.000300
2025-05-27 21:03:19,607 - INFO - joeynmt.training - Epoch   5, Step:    13400, Batch Loss:     1.553805, Batch Acc: 0.531379, Tokens per Sec:     3922, Lr: 0.000300
2025-05-27 21:03:38,664 - INFO - joeynmt.training - Epoch   5, Step:    13500, Batch Loss:     1.553774, Batch Acc: 0.531799, Tokens per Sec:     3641, Lr: 0.000300
2025-05-27 21:03:38,664 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:03:38,664 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:04:11,419 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.67, acc:   0.47, generation: 32.7494[sec], evaluation: 0.0000[sec]
2025-05-27 21:04:11,419 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:04:11,533 - INFO - joeynmt.helpers - delete models/word_level_model/11000.ckpt
2025-05-27 21:04:11,535 - INFO - joeynmt.training - Example #0
2025-05-27 21:04:11,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:04:11,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:04:11,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', 'die', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', 'der', '<unk>', '<unk>', ',', 'um', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> hatte , die die <unk> der <unk> der <unk> der <unk> der <unk> der <unk> <unk> , um 40 Prozent <unk> .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - Example #1
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'der', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> der <unk> dieses <unk> Problem , weil es nicht der <unk> des <unk> <unk> .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - Example #2
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir uns <unk> <unk> <unk> .
2025-05-27 21:04:11,536 - INFO - joeynmt.training - Example #3
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:04:11,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 21:04:11,537 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:04:11,537 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:04:11,537 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer .
2025-05-27 21:04:11,537 - INFO - joeynmt.training - Example #4
2025-05-27 21:04:11,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:04:11,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:04:11,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:04:11,537 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:04:11,537 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:04:11,537 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:04:30,293 - INFO - joeynmt.training - Epoch   5, Step:    13600, Batch Loss:     1.432890, Batch Acc: 0.529864, Tokens per Sec:     3602, Lr: 0.000300
2025-05-27 21:04:40,277 - INFO - joeynmt.training - Epoch   5: total training loss 4091.08
2025-05-27 21:04:40,277 - INFO - joeynmt.training - EPOCH 6
2025-05-27 21:04:49,872 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:     1.325755, Batch Acc: 0.557077, Tokens per Sec:     3730, Lr: 0.000300
2025-05-27 21:05:08,496 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:     1.419676, Batch Acc: 0.552479, Tokens per Sec:     3665, Lr: 0.000300
2025-05-27 21:05:27,137 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:     1.431365, Batch Acc: 0.549238, Tokens per Sec:     3593, Lr: 0.000300
2025-05-27 21:05:45,457 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:     1.576839, Batch Acc: 0.547788, Tokens per Sec:     3828, Lr: 0.000300
2025-05-27 21:05:45,457 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:05:45,457 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:06:13,369 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.74, acc:   0.47, generation: 27.9064[sec], evaluation: 0.0000[sec]
2025-05-27 21:06:13,503 - INFO - joeynmt.helpers - delete models/word_level_model/10500.ckpt
2025-05-27 21:06:13,506 - INFO - joeynmt.training - Example #0
2025-05-27 21:06:13,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:06:13,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:06:13,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', 'hatte', ',', 'mit', '40', '%', '<unk>', '.', '</s>']
2025-05-27 21:06:13,506 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:06:13,506 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in drei Millionen Jahre <unk> <unk> hatte , mit 40 % <unk> .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - Example #1
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - Example #2
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', 'das', '<unk>', '<unk>', 'unseres', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise das <unk> <unk> unseres <unk> <unk> .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - Example #3
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:06:13,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:06:13,507 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:06:13,508 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im Sommer .
2025-05-27 21:06:13,508 - INFO - joeynmt.training - Example #4
2025-05-27 21:06:13,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:06:13,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:06:13,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', 'ist', 'eine', '<unk>', '<unk>', 'der', 'letzten', '25', 'Jahre', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:06:13,508 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:06:13,508 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:06:13,508 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde ist eine <unk> <unk> der letzten 25 Jahre passiert ist .
2025-05-27 21:06:31,822 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:     1.308796, Batch Acc: 0.551777, Tokens per Sec:     3763, Lr: 0.000300
2025-05-27 21:06:48,597 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:     1.402634, Batch Acc: 0.549265, Tokens per Sec:     3994, Lr: 0.000300
2025-05-27 21:07:06,782 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:     1.493463, Batch Acc: 0.546930, Tokens per Sec:     3562, Lr: 0.000300
2025-05-27 21:07:26,071 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     1.541774, Batch Acc: 0.547333, Tokens per Sec:     3570, Lr: 0.000300
2025-05-27 21:07:44,362 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     1.430844, Batch Acc: 0.551178, Tokens per Sec:     3819, Lr: 0.000300
2025-05-27 21:07:44,364 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:07:44,364 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:08:10,497 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.47, generation: 26.1278[sec], evaluation: 0.0000[sec]
2025-05-27 21:08:10,608 - INFO - joeynmt.helpers - delete models/word_level_model/12000.ckpt
2025-05-27 21:08:10,610 - INFO - joeynmt.training - Example #0
2025-05-27 21:08:10,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:08:10,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:08:10,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', '<unk>', '<unk>', 'hatte', ',', 'die', 'die', 'Größe', 'der', '<unk>', 'der', 'USA', ',', 'um', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:08:10,610 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:08:10,610 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:08:10,610 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre Jahre <unk> <unk> hatte , die die Größe der <unk> der USA , um 40 Prozent <unk> .
2025-05-27 21:08:10,610 - INFO - joeynmt.training - Example #1
2025-05-27 21:08:10,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:08:10,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:08:10,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:08:10,610 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - Example #2
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne des <unk> <unk> .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - Example #3
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', '.', '</s>']
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> .
2025-05-27 21:08:10,611 - INFO - joeynmt.training - Example #4
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:08:10,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:08:10,612 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:08:10,612 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:08:10,612 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:08:28,923 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     1.314454, Batch Acc: 0.548385, Tokens per Sec:     3859, Lr: 0.000300
2025-05-27 21:08:47,957 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     1.394433, Batch Acc: 0.546212, Tokens per Sec:     3555, Lr: 0.000300
2025-05-27 21:09:06,771 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:     1.568596, Batch Acc: 0.546678, Tokens per Sec:     3731, Lr: 0.000300
2025-05-27 21:09:25,623 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:     1.402831, Batch Acc: 0.547916, Tokens per Sec:     3573, Lr: 0.000300
2025-05-27 21:09:44,531 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:     1.487994, Batch Acc: 0.544186, Tokens per Sec:     3761, Lr: 0.000300
2025-05-27 21:09:44,531 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:09:44,531 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:10:09,104 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.48, generation: 24.5679[sec], evaluation: 0.0000[sec]
2025-05-27 21:10:09,223 - INFO - joeynmt.helpers - delete models/word_level_model/12500.ckpt
2025-05-27 21:10:09,223 - INFO - joeynmt.training - Example #0
2025-05-27 21:10:09,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:10:09,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:10:09,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'die', 'Größe', 'der', '<unk>', 'der', 'Vereinigten', 'Staaten', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:10:09,223 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:10:09,223 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:10:09,223 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre lang die Größe der <unk> der Vereinigten Staaten , 40 Prozent <unk> .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - Example #1
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - Example #2
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk> <unk> .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - Example #3
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:10:09,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:10:09,224 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:10:09,225 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:10:09,225 - INFO - joeynmt.training - Example #4
2025-05-27 21:10:09,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:10:09,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:10:09,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:10:09,225 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:10:09,225 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:10:09,225 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:10:26,897 - INFO - joeynmt.training - Epoch   6, Step:    15100, Batch Loss:     1.534470, Batch Acc: 0.548737, Tokens per Sec:     3833, Lr: 0.000300
2025-05-27 21:10:46,460 - INFO - joeynmt.training - Epoch   6, Step:    15200, Batch Loss:     1.443508, Batch Acc: 0.545393, Tokens per Sec:     3537, Lr: 0.000300
2025-05-27 21:11:04,559 - INFO - joeynmt.training - Epoch   6, Step:    15300, Batch Loss:     1.440053, Batch Acc: 0.543101, Tokens per Sec:     3890, Lr: 0.000300
2025-05-27 21:11:23,904 - INFO - joeynmt.training - Epoch   6, Step:    15400, Batch Loss:     1.522365, Batch Acc: 0.543958, Tokens per Sec:     3655, Lr: 0.000300
2025-05-27 21:11:42,193 - INFO - joeynmt.training - Epoch   6, Step:    15500, Batch Loss:     1.474207, Batch Acc: 0.542205, Tokens per Sec:     3775, Lr: 0.000300
2025-05-27 21:11:42,193 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:11:42,193 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:12:09,386 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.47, generation: 27.1874[sec], evaluation: 0.0000[sec]
2025-05-27 21:12:09,501 - INFO - joeynmt.helpers - delete models/word_level_model/13000.ckpt
2025-05-27 21:12:09,504 - INFO - joeynmt.training - Example #0
2025-05-27 21:12:09,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:12:09,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:12:09,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', 'die', 'Größe', 'der', '<unk>', 'der', 'Vereinigten', 'Staaten', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> hatte , die die Größe der <unk> der Vereinigten Staaten , 40 Prozent <unk> .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - Example #1
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> <unk> , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - Example #2
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', 'dass', 'wir', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , dass wir das <unk> Herz unserer <unk> <unk> .
2025-05-27 21:12:09,505 - INFO - joeynmt.training - Example #3
2025-05-27 21:12:09,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:12:09,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:12:09,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:12:09,506 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:12:09,506 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:12:09,506 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:12:09,506 - INFO - joeynmt.training - Example #4
2025-05-27 21:12:09,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:12:09,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:12:09,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'Ihnen', '<unk>', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahre', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:12:09,506 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:12:09,506 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:12:09,506 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen Ihnen <unk> , ist eine <unk> Version von dem , was in den letzten 25 Jahre passiert ist .
2025-05-27 21:12:27,928 - INFO - joeynmt.training - Epoch   6, Step:    15600, Batch Loss:     1.355862, Batch Acc: 0.545580, Tokens per Sec:     3799, Lr: 0.000300
2025-05-27 21:12:46,689 - INFO - joeynmt.training - Epoch   6, Step:    15700, Batch Loss:     1.249189, Batch Acc: 0.542416, Tokens per Sec:     3688, Lr: 0.000300
2025-05-27 21:13:04,913 - INFO - joeynmt.training - Epoch   6, Step:    15800, Batch Loss:     1.509515, Batch Acc: 0.545961, Tokens per Sec:     3712, Lr: 0.000300
2025-05-27 21:13:24,281 - INFO - joeynmt.training - Epoch   6, Step:    15900, Batch Loss:     1.347146, Batch Acc: 0.541042, Tokens per Sec:     3546, Lr: 0.000300
2025-05-27 21:13:43,850 - INFO - joeynmt.training - Epoch   6, Step:    16000, Batch Loss:     1.495125, Batch Acc: 0.543915, Tokens per Sec:     3479, Lr: 0.000300
2025-05-27 21:13:43,851 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:13:43,851 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:14:10,428 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.48, generation: 26.5721[sec], evaluation: 0.0000[sec]
2025-05-27 21:14:10,429 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:14:10,545 - INFO - joeynmt.helpers - delete models/word_level_model/14000.ckpt
2025-05-27 21:14:10,545 - INFO - joeynmt.training - Example #0
2025-05-27 21:14:10,545 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', 'hatte', ',', 'die', 'in', 'den', 'USA', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese beiden <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre <unk> <unk> hatte , die in den USA , 40 Prozent <unk> .
2025-05-27 21:14:10,546 - INFO - joeynmt.training - Example #1
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:14:10,546 - INFO - joeynmt.training - Example #2
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:14:10,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'die', '<unk>', 'von', 'uns', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:14:10,546 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir die <unk> von uns <unk> <unk> .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - Example #3
2025-05-27 21:14:10,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:14:10,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:14:10,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - Example #4
2025-05-27 21:14:10,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:14:10,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:14:10,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:14:10,547 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:14:29,225 - INFO - joeynmt.training - Epoch   6, Step:    16100, Batch Loss:     1.462472, Batch Acc: 0.539961, Tokens per Sec:     3739, Lr: 0.000300
2025-05-27 21:14:48,370 - INFO - joeynmt.training - Epoch   6, Step:    16200, Batch Loss:     1.446537, Batch Acc: 0.542476, Tokens per Sec:     3607, Lr: 0.000300
2025-05-27 21:15:07,728 - INFO - joeynmt.training - Epoch   6, Step:    16300, Batch Loss:     1.702852, Batch Acc: 0.542019, Tokens per Sec:     3546, Lr: 0.000300
2025-05-27 21:15:23,083 - INFO - joeynmt.training - Epoch   6: total training loss 3991.62
2025-05-27 21:15:23,084 - INFO - joeynmt.training - EPOCH 7
2025-05-27 21:15:26,273 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:     1.425776, Batch Acc: 0.581809, Tokens per Sec:     3651, Lr: 0.000300
2025-05-27 21:15:43,880 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:     1.354296, Batch Acc: 0.567799, Tokens per Sec:     4014, Lr: 0.000300
2025-05-27 21:15:43,881 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:15:43,881 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:16:15,003 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.69, acc:   0.48, generation: 31.1168[sec], evaluation: 0.0000[sec]
2025-05-27 21:16:15,116 - INFO - joeynmt.helpers - delete models/word_level_model/14500.ckpt
2025-05-27 21:16:15,119 - INFO - joeynmt.training - Example #0
2025-05-27 21:16:15,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:16:15,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:16:15,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte', 'ich', 'diese', 'Größe', 'der', 'Größe', 'der', '<unk>', '<unk>', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:16:15,119 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> , um zu zeigen , dass die <unk> , die in drei Millionen Jahren <unk> hatte ich diese Größe der Größe der <unk> <unk> , mit 40 Prozent <unk> .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - Example #1
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - Example #2
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'unser', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir unser <unk> <unk> <unk> <unk> .
2025-05-27 21:16:15,120 - INFO - joeynmt.training - Example #3
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:16:15,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 21:16:15,120 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:16:15,121 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:16:15,121 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im Sommer <unk> .
2025-05-27 21:16:15,121 - INFO - joeynmt.training - Example #4
2025-05-27 21:16:15,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:16:15,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:16:15,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'davon', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:16:15,121 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:16:15,121 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:16:15,121 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version davon , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:16:32,915 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:     1.313578, Batch Acc: 0.565490, Tokens per Sec:     3746, Lr: 0.000300
2025-05-27 21:16:51,153 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:     1.410201, Batch Acc: 0.564048, Tokens per Sec:     3775, Lr: 0.000300
2025-05-27 21:17:09,883 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     1.526321, Batch Acc: 0.560258, Tokens per Sec:     3687, Lr: 0.000300
2025-05-27 21:17:28,231 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     1.473422, Batch Acc: 0.561694, Tokens per Sec:     3764, Lr: 0.000300
2025-05-27 21:17:45,583 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     1.373765, Batch Acc: 0.557669, Tokens per Sec:     4026, Lr: 0.000300
2025-05-27 21:17:45,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:17:45,584 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:18:12,372 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.68, acc:   0.48, generation: 26.7828[sec], evaluation: 0.0000[sec]
2025-05-27 21:18:12,498 - INFO - joeynmt.helpers - delete models/word_level_model/15500.ckpt
2025-05-27 21:18:12,498 - INFO - joeynmt.training - Example #0
2025-05-27 21:18:12,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:18:12,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:18:12,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Größe', 'der', 'Größe', 'der', '<unk>', '<unk>', '<unk>', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre etwa die Größe der Größe der <unk> <unk> <unk> , mit 40 Prozent <unk> .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - Example #1
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - Example #2
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', '<unk>', 'ist', 'im', '<unk>', 'Sinne', ',', 'dass', 'wir', '<unk>', '<unk>', ',', '</s>']
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:18:12,499 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf <unk> ist im <unk> Sinne , dass wir <unk> <unk> ,
2025-05-27 21:18:12,499 - INFO - joeynmt.training - Example #3
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:18:12,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:18:12,500 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:18:12,500 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:18:12,500 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> im Sommer .
2025-05-27 21:18:12,500 - INFO - joeynmt.training - Example #4
2025-05-27 21:18:12,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:18:12,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:18:12,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:18:12,500 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:18:12,500 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:18:12,500 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:18:31,899 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     1.397144, Batch Acc: 0.562308, Tokens per Sec:     3543, Lr: 0.000300
2025-05-27 21:18:50,368 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     1.400017, Batch Acc: 0.560455, Tokens per Sec:     3676, Lr: 0.000300
2025-05-27 21:19:10,004 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:     1.336457, Batch Acc: 0.552059, Tokens per Sec:     3439, Lr: 0.000300
2025-05-27 21:19:29,357 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:     1.433621, Batch Acc: 0.555338, Tokens per Sec:     3592, Lr: 0.000300
2025-05-27 21:19:48,503 - INFO - joeynmt.training - Epoch   7, Step:    17500, Batch Loss:     1.334837, Batch Acc: 0.557028, Tokens per Sec:     3586, Lr: 0.000300
2025-05-27 21:19:48,505 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:19:48,505 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:20:17,591 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.69, acc:   0.48, generation: 29.0803[sec], evaluation: 0.0000[sec]
2025-05-27 21:20:17,707 - INFO - joeynmt.helpers - delete models/word_level_model/15000.ckpt
2025-05-27 21:20:17,712 - INFO - joeynmt.training - Example #0
2025-05-27 21:20:17,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:20:17,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:20:17,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'hat', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', ',', 'die', 'die', '<unk>', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:20:17,712 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:20:17,712 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:20:17,712 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr hat ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> <unk> , die die <unk> drei Millionen Jahre <unk> <unk> .
2025-05-27 21:20:17,712 - INFO - joeynmt.training - Example #1
2025-05-27 21:20:17,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:20:17,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:20:17,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:20:17,712 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:20:17,712 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:20:17,712 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - Example #2
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir die <unk> <unk> , die <unk> <unk> .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - Example #3
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:20:17,713 - INFO - joeynmt.training - Example #4
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:20:17,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'davon', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:20:17,713 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:20:17,714 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:20:17,714 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen Ihnen zeigen , ist eine <unk> Version davon , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:20:35,596 - INFO - joeynmt.training - Epoch   7, Step:    17600, Batch Loss:     1.503605, Batch Acc: 0.550090, Tokens per Sec:     3733, Lr: 0.000300
2025-05-27 21:20:54,318 - INFO - joeynmt.training - Epoch   7, Step:    17700, Batch Loss:     1.475731, Batch Acc: 0.551517, Tokens per Sec:     3805, Lr: 0.000300
2025-05-27 21:21:11,931 - INFO - joeynmt.training - Epoch   7, Step:    17800, Batch Loss:     1.417480, Batch Acc: 0.551598, Tokens per Sec:     4109, Lr: 0.000300
2025-05-27 21:21:29,537 - INFO - joeynmt.training - Epoch   7, Step:    17900, Batch Loss:     1.433716, Batch Acc: 0.555664, Tokens per Sec:     3796, Lr: 0.000300
2025-05-27 21:21:47,949 - INFO - joeynmt.training - Epoch   7, Step:    18000, Batch Loss:     1.390230, Batch Acc: 0.554557, Tokens per Sec:     3789, Lr: 0.000300
2025-05-27 21:21:47,949 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:21:47,949 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:22:16,142 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.48, generation: 28.1868[sec], evaluation: 0.0000[sec]
2025-05-27 21:22:16,142 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:22:16,260 - INFO - joeynmt.helpers - delete models/word_level_model/16500.ckpt
2025-05-27 21:22:16,260 - INFO - joeynmt.training - Example #0
2025-05-27 21:22:16,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:22:16,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:22:16,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Größe', 'der', '<unk>', 'der', '<unk>', 'der', 'USA', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre etwa die Größe der <unk> der <unk> der USA , mit 40 Prozent <unk> .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - Example #1
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'eigentlich', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist eigentlich der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - Example #2
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'die', '<unk>', 'unseres', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir die <unk> unseres <unk> <unk> <unk> .
2025-05-27 21:22:16,261 - INFO - joeynmt.training - Example #3
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:22:16,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', '<unk>', '.', '</s>']
2025-05-27 21:22:16,262 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:22:16,262 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:22:16,262 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im <unk> .
2025-05-27 21:22:16,262 - INFO - joeynmt.training - Example #4
2025-05-27 21:22:16,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:22:16,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:22:16,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'der', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:22:16,262 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:22:16,262 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:22:16,262 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version der letzten 25 Jahren passiert ist .
2025-05-27 21:22:35,140 - INFO - joeynmt.training - Epoch   7, Step:    18100, Batch Loss:     1.539516, Batch Acc: 0.552826, Tokens per Sec:     3677, Lr: 0.000300
2025-05-27 21:22:52,487 - INFO - joeynmt.training - Epoch   7, Step:    18200, Batch Loss:     1.431156, Batch Acc: 0.546925, Tokens per Sec:     3988, Lr: 0.000300
2025-05-27 21:23:09,105 - INFO - joeynmt.training - Epoch   7, Step:    18300, Batch Loss:     1.385249, Batch Acc: 0.548692, Tokens per Sec:     4211, Lr: 0.000300
2025-05-27 21:23:28,244 - INFO - joeynmt.training - Epoch   7, Step:    18400, Batch Loss:     1.464783, Batch Acc: 0.549875, Tokens per Sec:     3691, Lr: 0.000300
2025-05-27 21:23:47,332 - INFO - joeynmt.training - Epoch   7, Step:    18500, Batch Loss:     1.640520, Batch Acc: 0.552833, Tokens per Sec:     3582, Lr: 0.000300
2025-05-27 21:23:47,332 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:23:47,332 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:24:15,371 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.48, generation: 28.0340[sec], evaluation: 0.0000[sec]
2025-05-27 21:24:15,484 - INFO - joeynmt.helpers - delete models/word_level_model/17500.ckpt
2025-05-27 21:24:15,488 - INFO - joeynmt.training - Example #0
2025-05-27 21:24:15,488 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:24:15,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:24:15,488 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'der', 'Größe', 'der', 'USA', '<unk>', ',', '40', 'Prozent', '<unk>', 'hatte', '.', '</s>']
2025-05-27 21:24:15,488 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:24:15,488 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:24:15,488 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die letzten drei Millionen Jahre ungefähr die Größe der Größe der USA <unk> , 40 Prozent <unk> hatte .
2025-05-27 21:24:15,488 - INFO - joeynmt.training - Example #1
2025-05-27 21:24:15,488 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:24:15,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:24:15,488 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:24:15,488 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:24:15,488 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:24:15,488 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - Example #2
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'die', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir die <unk> <unk> <unk> .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - Example #3
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', '.', '</s>']
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - Example #4
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:24:15,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:24:15,489 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:24:32,424 - INFO - joeynmt.training - Epoch   7, Step:    18600, Batch Loss:     1.260007, Batch Acc: 0.550174, Tokens per Sec:     4093, Lr: 0.000300
2025-05-27 21:24:49,908 - INFO - joeynmt.training - Epoch   7, Step:    18700, Batch Loss:     1.420996, Batch Acc: 0.548930, Tokens per Sec:     4026, Lr: 0.000300
2025-05-27 21:25:08,934 - INFO - joeynmt.training - Epoch   7, Step:    18800, Batch Loss:     1.477695, Batch Acc: 0.557862, Tokens per Sec:     3611, Lr: 0.000300
2025-05-27 21:25:28,033 - INFO - joeynmt.training - Epoch   7, Step:    18900, Batch Loss:     1.502014, Batch Acc: 0.552609, Tokens per Sec:     3572, Lr: 0.000300
2025-05-27 21:25:47,322 - INFO - joeynmt.training - Epoch   7, Step:    19000, Batch Loss:     1.519915, Batch Acc: 0.547755, Tokens per Sec:     3529, Lr: 0.000300
2025-05-27 21:25:47,323 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:25:47,323 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:26:16,141 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.48, generation: 28.8129[sec], evaluation: 0.0000[sec]
2025-05-27 21:26:16,261 - INFO - joeynmt.helpers - delete models/word_level_model/17000.ckpt
2025-05-27 21:26:16,262 - INFO - joeynmt.training - Example #0
2025-05-27 21:26:16,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:26:16,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:26:16,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'der', '<unk>', 'der', '<unk>', 'der', 'USA', '<unk>', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:26:16,262 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:26:16,262 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:26:16,262 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese beiden <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre ungefähr die Größe der <unk> der <unk> der USA <unk> , 40 Prozent <unk> .
2025-05-27 21:26:16,262 - INFO - joeynmt.training - Example #1
2025-05-27 21:26:16,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:26:16,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:26:16,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'eigentlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:26:16,262 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:26:16,262 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist eigentlich die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - Example #2
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', ',', 'die', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise , die <unk> Herz unseres <unk> <unk> .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - Example #3
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'sich', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Hypothesis: Es <unk> sich in den <unk> und <unk> im Sommer .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - Example #4
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:26:16,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:26:16,263 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:26:16,264 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:26:34,998 - INFO - joeynmt.training - Epoch   7, Step:    19100, Batch Loss:     1.488465, Batch Acc: 0.551140, Tokens per Sec:     3759, Lr: 0.000300
2025-05-27 21:26:36,544 - INFO - joeynmt.training - Epoch   7: total training loss 3887.05
2025-05-27 21:26:36,544 - INFO - joeynmt.training - EPOCH 8
2025-05-27 21:26:53,889 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:     1.224990, Batch Acc: 0.572516, Tokens per Sec:     3657, Lr: 0.000300
2025-05-27 21:27:12,818 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.391822, Batch Acc: 0.570551, Tokens per Sec:     3681, Lr: 0.000300
2025-05-27 21:27:31,460 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     1.370146, Batch Acc: 0.568581, Tokens per Sec:     3695, Lr: 0.000300
2025-05-27 21:27:50,097 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     1.343236, Batch Acc: 0.569217, Tokens per Sec:     3668, Lr: 0.000300
2025-05-27 21:27:50,097 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:27:50,097 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:28:18,944 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.68, acc:   0.48, generation: 28.8413[sec], evaluation: 0.0000[sec]
2025-05-27 21:28:18,946 - INFO - joeynmt.training - Example #0
2025-05-27 21:28:18,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:28:18,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:28:18,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'hat', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'Größe', 'der', 'USA', '<unk>', ',', 'um', '40', 'Prozent', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:28:18,946 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:28:18,946 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:28:18,946 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr hat ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre , die Größe der USA <unk> , um 40 Prozent <unk> <unk> .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - Example #1
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist tatsächlich die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - Example #2
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir <unk> <unk> <unk> .
2025-05-27 21:28:18,947 - INFO - joeynmt.training - Example #3
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:28:18,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 21:28:18,947 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:28:18,948 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:28:18,948 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer <unk> .
2025-05-27 21:28:18,948 - INFO - joeynmt.training - Example #4
2025-05-27 21:28:18,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:28:18,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:28:18,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:28:18,948 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:28:18,948 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:28:18,948 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:28:37,657 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     1.344740, Batch Acc: 0.570222, Tokens per Sec:     3651, Lr: 0.000300
2025-05-27 21:28:56,120 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:     1.380884, Batch Acc: 0.567167, Tokens per Sec:     3721, Lr: 0.000300
2025-05-27 21:29:14,274 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:     1.440581, Batch Acc: 0.565876, Tokens per Sec:     3781, Lr: 0.000300
2025-05-27 21:29:31,105 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:     1.340414, Batch Acc: 0.566732, Tokens per Sec:     4088, Lr: 0.000300
2025-05-27 21:29:48,711 - INFO - joeynmt.training - Epoch   8, Step:    20000, Batch Loss:     1.206002, Batch Acc: 0.567265, Tokens per Sec:     3871, Lr: 0.000300
2025-05-27 21:29:48,713 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:29:48,713 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:30:13,751 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.48, generation: 25.0327[sec], evaluation: 0.0000[sec]
2025-05-27 21:30:13,753 - INFO - joeynmt.training - Example #0
2025-05-27 21:30:13,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:30:13,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:30:13,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', 'hatte', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', 'die', 'Größe', 'der', 'USA', '<unk>', ',', 'um', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:30:13,753 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:30:13,753 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:30:13,753 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die letzten drei Millionen Jahre <unk> <unk> hatte , die die letzten drei Millionen Jahre <unk> hatte , die die Größe der USA <unk> , um 40 Prozent <unk> .
2025-05-27 21:30:13,753 - INFO - joeynmt.training - Example #1
2025-05-27 21:30:13,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:30:13,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:30:13,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> <unk> , weil es nicht die <unk> des <unk> des <unk> zeigt .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - Example #2
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir uns <unk> <unk> <unk> .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - Example #3
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - Example #4
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:30:13,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:30:13,754 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:30:13,755 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:30:32,475 - INFO - joeynmt.training - Epoch   8, Step:    20100, Batch Loss:     1.433825, Batch Acc: 0.563670, Tokens per Sec:     3730, Lr: 0.000300
2025-05-27 21:30:51,210 - INFO - joeynmt.training - Epoch   8, Step:    20200, Batch Loss:     1.433300, Batch Acc: 0.566119, Tokens per Sec:     3713, Lr: 0.000300
2025-05-27 21:31:10,404 - INFO - joeynmt.training - Epoch   8, Step:    20300, Batch Loss:     1.527287, Batch Acc: 0.560180, Tokens per Sec:     3594, Lr: 0.000300
2025-05-27 21:31:29,605 - INFO - joeynmt.training - Epoch   8, Step:    20400, Batch Loss:     1.395698, Batch Acc: 0.565079, Tokens per Sec:     3596, Lr: 0.000300
2025-05-27 21:31:47,572 - INFO - joeynmt.training - Epoch   8, Step:    20500, Batch Loss:     1.365949, Batch Acc: 0.558253, Tokens per Sec:     3861, Lr: 0.000300
2025-05-27 21:31:47,574 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:31:47,574 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:32:16,159 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.48, generation: 28.5796[sec], evaluation: 0.0000[sec]
2025-05-27 21:32:16,277 - INFO - joeynmt.helpers - delete models/word_level_model/13500.ckpt
2025-05-27 21:32:16,282 - INFO - joeynmt.training - Example #0
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'hat', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'Jahren', '<unk>', '<unk>', ',', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:32:16,283 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:32:16,283 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:32:16,283 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr hat ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahren Jahren <unk> <unk> , <unk> <unk> .
2025-05-27 21:32:16,283 - INFO - joeynmt.training - Example #1
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'eigentlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:32:16,283 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:32:16,283 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:32:16,283 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist eigentlich die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:32:16,283 - INFO - joeynmt.training - Example #2
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:32:16,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', '<unk>', 'ist', 'in', '<unk>', 'Weise', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '.', '</s>']
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf <unk> ist in <unk> Weise das <unk> Herz unserer <unk> .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - Example #3
2025-05-27 21:32:16,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:32:16,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:32:16,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - Example #4
2025-05-27 21:32:16,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:32:16,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:32:16,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'der', 'letzten', '25', 'Jahre', 'passiert', '.', '</s>']
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:32:16,284 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version der letzten 25 Jahre passiert .
2025-05-27 21:32:34,794 - INFO - joeynmt.training - Epoch   8, Step:    20600, Batch Loss:     1.264614, Batch Acc: 0.563980, Tokens per Sec:     3711, Lr: 0.000300
2025-05-27 21:32:54,000 - INFO - joeynmt.training - Epoch   8, Step:    20700, Batch Loss:     1.389511, Batch Acc: 0.559361, Tokens per Sec:     3589, Lr: 0.000300
2025-05-27 21:33:13,198 - INFO - joeynmt.training - Epoch   8, Step:    20800, Batch Loss:     1.517212, Batch Acc: 0.564451, Tokens per Sec:     3547, Lr: 0.000300
2025-05-27 21:33:32,216 - INFO - joeynmt.training - Epoch   8, Step:    20900, Batch Loss:     1.362145, Batch Acc: 0.562706, Tokens per Sec:     3666, Lr: 0.000300
2025-05-27 21:33:51,358 - INFO - joeynmt.training - Epoch   8, Step:    21000, Batch Loss:     1.271239, Batch Acc: 0.564031, Tokens per Sec:     3554, Lr: 0.000300
2025-05-27 21:33:51,358 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:33:51,358 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:34:20,115 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.48, generation: 28.7507[sec], evaluation: 0.0000[sec]
2025-05-27 21:34:20,115 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:34:20,228 - INFO - joeynmt.helpers - delete models/word_level_model/20500.ckpt
2025-05-27 21:34:20,230 - INFO - joeynmt.training - Example #0
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor', 'Jahren', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'Jahren', 'der', 'Größe', 'der', '<unk>', '<unk>', '<unk>', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:34:20,230 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:34:20,230 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:34:20,230 - INFO - joeynmt.training - 	Hypothesis: Vor Jahren habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahren Jahren der Größe der <unk> <unk> <unk> , 40 Prozent <unk> .
2025-05-27 21:34:20,230 - INFO - joeynmt.training - Example #1
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', ',', 'dass', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:34:20,230 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:34:20,230 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:34:20,230 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist , dass das <unk> der <unk> dieses <unk> Problem ist , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:34:20,230 - INFO - joeynmt.training - Example #2
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:34:20,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinn', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinn , dass wir uns <unk> <unk> .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - Example #3
2025-05-27 21:34:20,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:34:20,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:34:20,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', '<unk>', '.', '</s>']
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im <unk> .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - Example #4
2025-05-27 21:34:20,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:34:20,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:34:20,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'Ihnen', 'zeigen', 'ist', 'eine', '<unk>', 'Version', 'der', 'letzten', '25', 'Jahre', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:34:20,231 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen Ihnen zeigen ist eine <unk> Version der letzten 25 Jahre passiert ist .
2025-05-27 21:34:39,707 - INFO - joeynmt.training - Epoch   8, Step:    21100, Batch Loss:     1.406570, Batch Acc: 0.559979, Tokens per Sec:     3529, Lr: 0.000300
2025-05-27 21:34:59,031 - INFO - joeynmt.training - Epoch   8, Step:    21200, Batch Loss:     1.378339, Batch Acc: 0.554321, Tokens per Sec:     3592, Lr: 0.000300
2025-05-27 21:35:18,438 - INFO - joeynmt.training - Epoch   8, Step:    21300, Batch Loss:     1.342445, Batch Acc: 0.558959, Tokens per Sec:     3631, Lr: 0.000300
2025-05-27 21:35:37,191 - INFO - joeynmt.training - Epoch   8, Step:    21400, Batch Loss:     1.442675, Batch Acc: 0.561000, Tokens per Sec:     3569, Lr: 0.000300
2025-05-27 21:35:55,288 - INFO - joeynmt.training - Epoch   8, Step:    21500, Batch Loss:     1.381035, Batch Acc: 0.554649, Tokens per Sec:     3774, Lr: 0.000300
2025-05-27 21:35:55,288 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:35:55,290 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:36:25,101 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.62, acc:   0.48, generation: 29.8056[sec], evaluation: 0.0000[sec]
2025-05-27 21:36:25,102 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:36:25,215 - INFO - joeynmt.helpers - delete models/word_level_model/19000.ckpt
2025-05-27 21:36:25,218 - INFO - joeynmt.training - Example #0
2025-05-27 21:36:25,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:36:25,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:36:25,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Größe', 'der', '<unk>', 'der', 'USA', ',', 'um', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahre , die die Größe der <unk> der USA , um 40 Prozent <unk> .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - Example #1
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - Example #2
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', 'dass', 'wir', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , dass wir das <unk> Herz unserer <unk> <unk> .
2025-05-27 21:36:25,219 - INFO - joeynmt.training - Example #3
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:36:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', '<unk>', '.', '</s>']
2025-05-27 21:36:25,220 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:36:25,220 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:36:25,220 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im <unk> .
2025-05-27 21:36:25,220 - INFO - joeynmt.training - Example #4
2025-05-27 21:36:25,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:36:25,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:36:25,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:36:25,220 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:36:25,220 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:36:25,220 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:36:43,139 - INFO - joeynmt.training - Epoch   8, Step:    21600, Batch Loss:     1.330656, Batch Acc: 0.559394, Tokens per Sec:     3828, Lr: 0.000300
2025-05-27 21:37:02,917 - INFO - joeynmt.training - Epoch   8, Step:    21700, Batch Loss:     1.451021, Batch Acc: 0.556918, Tokens per Sec:     3472, Lr: 0.000300
2025-05-27 21:37:21,676 - INFO - joeynmt.training - Epoch   8, Step:    21800, Batch Loss:     1.525355, Batch Acc: 0.556460, Tokens per Sec:     3601, Lr: 0.000300
2025-05-27 21:37:30,602 - INFO - joeynmt.training - Epoch   8: total training loss 3824.01
2025-05-27 21:37:30,602 - INFO - joeynmt.training - EPOCH 9
2025-05-27 21:37:40,788 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     1.432113, Batch Acc: 0.579570, Tokens per Sec:     3501, Lr: 0.000300
2025-05-27 21:38:00,536 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     1.506659, Batch Acc: 0.578392, Tokens per Sec:     3506, Lr: 0.000300
2025-05-27 21:38:00,537 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:38:00,537 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:38:31,210 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.69, acc:   0.48, generation: 30.6672[sec], evaluation: 0.0000[sec]
2025-05-27 21:38:31,211 - INFO - joeynmt.training - Example #0
2025-05-27 21:38:31,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:38:31,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:38:31,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', '<unk>', 'der', '<unk>', 'der', 'USA', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:38:31,211 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:38:31,211 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:38:31,211 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahre <unk> hatte , die <unk> der <unk> der USA , mit 40 Prozent <unk> .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - Example #1
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', ',', 'dass', 'das', '<unk>', 'dieses', '<unk>', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist , dass das <unk> dieses <unk> Problem ist , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - Example #2
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', 'dass', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , dass das <unk> Herz unseres <unk> <unk> <unk> .
2025-05-27 21:38:31,212 - INFO - joeynmt.training - Example #3
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:38:31,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', '<unk>', '.', '</s>']
2025-05-27 21:38:31,212 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:38:31,213 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:38:31,213 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im <unk> .
2025-05-27 21:38:31,213 - INFO - joeynmt.training - Example #4
2025-05-27 21:38:31,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:38:31,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:38:31,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:38:31,213 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:38:31,213 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:38:31,213 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:38:51,393 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     1.410864, Batch Acc: 0.581139, Tokens per Sec:     3449, Lr: 0.000300
2025-05-27 21:39:10,431 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:     1.338886, Batch Acc: 0.577764, Tokens per Sec:     3557, Lr: 0.000300
2025-05-27 21:39:29,326 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:     1.287171, Batch Acc: 0.582063, Tokens per Sec:     3625, Lr: 0.000300
2025-05-27 21:39:47,006 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:     1.293736, Batch Acc: 0.575558, Tokens per Sec:     4010, Lr: 0.000300
2025-05-27 21:40:04,745 - INFO - joeynmt.training - Epoch   9, Step:    22500, Batch Loss:     1.322926, Batch Acc: 0.573363, Tokens per Sec:     3805, Lr: 0.000300
2025-05-27 21:40:04,745 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:40:04,745 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:40:31,754 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.48, generation: 27.0043[sec], evaluation: 0.0000[sec]
2025-05-27 21:40:31,756 - INFO - joeynmt.training - Example #0
2025-05-27 21:40:31,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:40:31,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:40:31,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'drei', 'Millionen', 'Jahre', '<unk>', ',', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '.', '</s>']
2025-05-27 21:40:31,756 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:40:31,756 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:40:31,756 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese beiden <unk> , um zu zeigen , dass die <unk> , die in drei Millionen Jahre <unk> , die <unk> , die die letzten drei Millionen Jahre <unk> .
2025-05-27 21:40:31,756 - INFO - joeynmt.training - Example #1
2025-05-27 21:40:31,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:40:31,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:40:31,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'diese', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:40:31,756 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:40:31,756 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:40:31,756 - INFO - joeynmt.training - 	Hypothesis: Aber diese <unk> <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:40:31,756 - INFO - joeynmt.training - Example #2
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir das <unk> Herz unserer <unk> <unk> .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - Example #3
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - Example #4
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:40:31,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', '<unk>', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:40:31,757 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem <unk> <unk> , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:40:45,606 - INFO - joeynmt.training - Epoch   9, Step:    22600, Batch Loss:     1.260380, Batch Acc: 0.579355, Tokens per Sec:     5011, Lr: 0.000300
2025-05-27 21:40:59,456 - INFO - joeynmt.training - Epoch   9, Step:    22700, Batch Loss:     1.248754, Batch Acc: 0.571310, Tokens per Sec:     5049, Lr: 0.000300
2025-05-27 21:41:13,877 - INFO - joeynmt.training - Epoch   9, Step:    22800, Batch Loss:     1.374123, Batch Acc: 0.572937, Tokens per Sec:     4807, Lr: 0.000300
2025-05-27 21:41:27,729 - INFO - joeynmt.training - Epoch   9, Step:    22900, Batch Loss:     1.360959, Batch Acc: 0.572374, Tokens per Sec:     4933, Lr: 0.000300
2025-05-27 21:41:42,000 - INFO - joeynmt.training - Epoch   9, Step:    23000, Batch Loss:     1.334424, Batch Acc: 0.571972, Tokens per Sec:     4824, Lr: 0.000300
2025-05-27 21:41:42,001 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:41:42,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:42:04,965 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.68, acc:   0.48, generation: 22.9600[sec], evaluation: 0.0000[sec]
2025-05-27 21:42:04,965 - INFO - joeynmt.training - Example #0
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'hat', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', ',', 'die', 'die', 'Größe', 'der', 'USA', '<unk>', ',', 'um', '40', 'Prozent', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr hat ich diese zwei <unk> , um zu zeigen , dass die <unk> , die in den letzten drei Millionen Jahren <unk> , die die Größe der USA <unk> , um 40 Prozent <unk> <unk> .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - Example #1
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'eigentlich', 'das', '<unk>', 'des', '<unk>', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist eigentlich das <unk> des <unk> , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - Example #2
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir das <unk> Herz unseres <unk> <unk> <unk> .
2025-05-27 21:42:04,966 - INFO - joeynmt.training - Example #3
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:42:04,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:42:04,967 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:42:04,967 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:42:04,967 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> im Sommer .
2025-05-27 21:42:04,967 - INFO - joeynmt.training - Example #4
2025-05-27 21:42:04,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:42:04,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:42:04,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:42:04,967 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:42:04,967 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:42:04,967 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:42:19,381 - INFO - joeynmt.training - Epoch   9, Step:    23100, Batch Loss:     1.402016, Batch Acc: 0.569397, Tokens per Sec:     4765, Lr: 0.000300
2025-05-27 21:42:33,114 - INFO - joeynmt.training - Epoch   9, Step:    23200, Batch Loss:     1.308605, Batch Acc: 0.569887, Tokens per Sec:     5081, Lr: 0.000300
2025-05-27 21:42:47,095 - INFO - joeynmt.training - Epoch   9, Step:    23300, Batch Loss:     1.428866, Batch Acc: 0.568076, Tokens per Sec:     5114, Lr: 0.000300
2025-05-27 21:43:01,684 - INFO - joeynmt.training - Epoch   9, Step:    23400, Batch Loss:     1.302059, Batch Acc: 0.565662, Tokens per Sec:     4717, Lr: 0.000300
2025-05-27 21:43:15,902 - INFO - joeynmt.training - Epoch   9, Step:    23500, Batch Loss:     1.411760, Batch Acc: 0.563309, Tokens per Sec:     4877, Lr: 0.000300
2025-05-27 21:43:15,902 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:43:15,902 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:43:39,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.48, generation: 23.3355[sec], evaluation: 0.0000[sec]
2025-05-27 21:43:39,245 - INFO - joeynmt.training - Example #0
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', 'hatte', ',', 'die', 'die', 'Größe', 'der', 'Vereinigten', 'Staaten', ',', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> <unk> hatte , die die Größe der Vereinigten Staaten , mit 40 Prozent <unk> .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - Example #1
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'das', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist das <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> <unk> .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - Example #2
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:43:39,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', '<unk>', 'Sinn', ',', 'dass', 'wir', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , <unk> Sinn , dass wir das <unk> Herz unseres <unk> <unk> .
2025-05-27 21:43:39,245 - INFO - joeynmt.training - Example #3
2025-05-27 21:43:39,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:43:39,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:43:39,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'im', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 21:43:39,246 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:43:39,246 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:43:39,246 - INFO - joeynmt.training - 	Hypothesis: Es <unk> im Sommer <unk> .
2025-05-27 21:43:39,246 - INFO - joeynmt.training - Example #4
2025-05-27 21:43:39,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:43:39,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:43:39,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', 'werde', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:43:39,246 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:43:39,246 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:43:39,246 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen werde , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:43:53,385 - INFO - joeynmt.training - Epoch   9, Step:    23600, Batch Loss:     1.280369, Batch Acc: 0.567891, Tokens per Sec:     4921, Lr: 0.000300
2025-05-27 21:44:07,294 - INFO - joeynmt.training - Epoch   9, Step:    23700, Batch Loss:     1.319405, Batch Acc: 0.565858, Tokens per Sec:     4969, Lr: 0.000300
2025-05-27 21:44:21,148 - INFO - joeynmt.training - Epoch   9, Step:    23800, Batch Loss:     1.519932, Batch Acc: 0.567037, Tokens per Sec:     5129, Lr: 0.000300
2025-05-27 21:44:35,077 - INFO - joeynmt.training - Epoch   9, Step:    23900, Batch Loss:     1.287274, Batch Acc: 0.566366, Tokens per Sec:     4842, Lr: 0.000300
2025-05-27 21:44:49,605 - INFO - joeynmt.training - Epoch   9, Step:    24000, Batch Loss:     1.376846, Batch Acc: 0.567238, Tokens per Sec:     4652, Lr: 0.000300
2025-05-27 21:44:49,605 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:44:49,605 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:45:11,035 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.47, generation: 21.4263[sec], evaluation: 0.0000[sec]
2025-05-27 21:45:11,037 - INFO - joeynmt.training - Example #0
2025-05-27 21:45:11,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:45:11,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:45:11,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'der', '<unk>', 'der', '<unk>', 'der', 'USA', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre ungefähr die Größe der <unk> der <unk> der USA mit 40 Prozent <unk> .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - Example #1
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', ',', 'dass', 'das', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist , dass das <unk> Problem , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - Example #2
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', ',', 'dass', 'wir', 'die', '<unk>', 'eines', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise , dass wir die <unk> eines <unk> <unk> <unk> .
2025-05-27 21:45:11,038 - INFO - joeynmt.training - Example #3
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:45:11,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '.', '</s>']
2025-05-27 21:45:11,039 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:45:11,039 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:45:11,039 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer .
2025-05-27 21:45:11,039 - INFO - joeynmt.training - Example #4
2025-05-27 21:45:11,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:45:11,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:45:11,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:45:11,039 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:45:11,039 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:45:11,039 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:45:25,283 - INFO - joeynmt.training - Epoch   9, Step:    24100, Batch Loss:     1.372322, Batch Acc: 0.563597, Tokens per Sec:     4941, Lr: 0.000300
2025-05-27 21:45:39,488 - INFO - joeynmt.training - Epoch   9, Step:    24200, Batch Loss:     1.446041, Batch Acc: 0.565300, Tokens per Sec:     4837, Lr: 0.000300
2025-05-27 21:45:53,300 - INFO - joeynmt.training - Epoch   9, Step:    24300, Batch Loss:     1.497882, Batch Acc: 0.569746, Tokens per Sec:     4886, Lr: 0.000300
2025-05-27 21:46:07,201 - INFO - joeynmt.training - Epoch   9, Step:    24400, Batch Loss:     1.364942, Batch Acc: 0.564769, Tokens per Sec:     4878, Lr: 0.000300
2025-05-27 21:46:21,365 - INFO - joeynmt.training - Epoch   9, Step:    24500, Batch Loss:     1.408469, Batch Acc: 0.559865, Tokens per Sec:     4828, Lr: 0.000300
2025-05-27 21:46:21,365 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:46:21,365 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:46:42,075 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.67, acc:   0.48, generation: 20.7062[sec], evaluation: 0.0000[sec]
2025-05-27 21:46:42,077 - INFO - joeynmt.training - Example #0
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'hatte', 'ich', 'diese', 'Größe', 'der', '<unk>', 'der', 'USA', 'mit', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:46:42,077 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:46:42,077 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:46:42,077 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese beiden <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre , hatte ich diese Größe der <unk> der USA mit 40 Prozent <unk> .
2025-05-27 21:46:42,077 - INFO - joeynmt.training - Example #1
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:46:42,077 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:46:42,077 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:46:42,077 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:46:42,077 - INFO - joeynmt.training - Example #2
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:46:42,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', '<unk>', 'ist', 'in', '<unk>', 'Sinn', ',', 'ist', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf <unk> ist in <unk> Sinn , ist das <unk> Herz unseres <unk> <unk> .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - Example #3
2025-05-27 21:46:42,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:46:42,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:46:42,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', 'Sommer', '.', '</s>']
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im Sommer .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - Example #4
2025-05-27 21:46:42,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:46:42,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:46:42,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:46:42,078 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:46:53,482 - INFO - joeynmt.training - Epoch   9: total training loss 3741.95
2025-05-27 21:46:53,482 - INFO - joeynmt.training - EPOCH 10
2025-05-27 21:46:56,111 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:     1.224704, Batch Acc: 0.598530, Tokens per Sec:     5072, Lr: 0.000300
2025-05-27 21:47:10,332 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:     1.214281, Batch Acc: 0.588730, Tokens per Sec:     4751, Lr: 0.000300
2025-05-27 21:47:24,114 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:     1.363160, Batch Acc: 0.586771, Tokens per Sec:     5114, Lr: 0.000300
2025-05-27 21:47:38,611 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:     1.351242, Batch Acc: 0.584469, Tokens per Sec:     4683, Lr: 0.000300
2025-05-27 21:47:52,691 - INFO - joeynmt.training - Epoch  10, Step:    25000, Batch Loss:     1.279871, Batch Acc: 0.584425, Tokens per Sec:     4929, Lr: 0.000300
2025-05-27 21:47:52,692 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:47:52,692 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:48:14,055 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.74, acc:   0.47, generation: 21.3593[sec], evaluation: 0.0000[sec]
2025-05-27 21:48:14,057 - INFO - joeynmt.training - Example #0
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte', ',', 'die', '<unk>', 'der', '<unk>', 'der', 'USA', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese beiden <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> hatte , die <unk> der <unk> der USA , 40 Prozent <unk> .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - Example #1
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'eigentlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist eigentlich die <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> <unk> zeigt .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - Example #2
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:48:14,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', ',', '<unk>', '<unk>', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist , <unk> <unk> das <unk> Herz unseres <unk> <unk> .
2025-05-27 21:48:14,057 - INFO - joeynmt.training - Example #3
2025-05-27 21:48:14,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:48:14,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:48:14,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 21:48:14,058 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:48:14,058 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:48:14,058 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer <unk> .
2025-05-27 21:48:14,058 - INFO - joeynmt.training - Example #4
2025-05-27 21:48:14,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:48:14,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:48:14,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', '.', '</s>']
2025-05-27 21:48:14,058 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:48:14,058 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:48:14,058 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert .
2025-05-27 21:48:27,952 - INFO - joeynmt.training - Epoch  10, Step:    25100, Batch Loss:     1.194388, Batch Acc: 0.583854, Tokens per Sec:     5052, Lr: 0.000300
2025-05-27 21:48:42,119 - INFO - joeynmt.training - Epoch  10, Step:    25200, Batch Loss:     1.407678, Batch Acc: 0.581447, Tokens per Sec:     4911, Lr: 0.000300
2025-05-27 21:48:55,825 - INFO - joeynmt.training - Epoch  10, Step:    25300, Batch Loss:     1.440406, Batch Acc: 0.583267, Tokens per Sec:     5098, Lr: 0.000300
2025-05-27 21:49:09,668 - INFO - joeynmt.training - Epoch  10, Step:    25400, Batch Loss:     1.339720, Batch Acc: 0.580191, Tokens per Sec:     4974, Lr: 0.000300
2025-05-27 21:49:23,793 - INFO - joeynmt.training - Epoch  10, Step:    25500, Batch Loss:     1.439089, Batch Acc: 0.578511, Tokens per Sec:     5112, Lr: 0.000300
2025-05-27 21:49:23,793 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:49:23,793 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:49:44,302 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.72, acc:   0.48, generation: 20.5051[sec], evaluation: 0.0000[sec]
2025-05-27 21:49:44,306 - INFO - joeynmt.training - Example #0
2025-05-27 21:49:44,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:49:44,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:49:44,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', '<unk>', '<unk>', 'hatte', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre , die <unk> <unk> hatte , 40 Prozent <unk> .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - Example #1
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'Problem', ',', 'dass', 'das', '<unk>', 'Problem', 'ist', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> Problem , dass das <unk> Problem ist , weil es nicht die <unk> des <unk> <unk> .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - Example #2
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'die', '<unk>', 'unseres', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir die <unk> unseres <unk> <unk> <unk> .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - Example #3
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:49:44,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:49:44,307 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:49:44,308 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer <unk> .
2025-05-27 21:49:44,308 - INFO - joeynmt.training - Example #4
2025-05-27 21:49:44,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:49:44,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:49:44,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeigen', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:49:44,308 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:49:44,308 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:49:44,308 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeigen , ist eine <unk> Version von dem letzten 25 Jahren passiert ist .
2025-05-27 21:49:58,053 - INFO - joeynmt.training - Epoch  10, Step:    25600, Batch Loss:     1.303102, Batch Acc: 0.579682, Tokens per Sec:     4916, Lr: 0.000300
2025-05-27 21:50:12,425 - INFO - joeynmt.training - Epoch  10, Step:    25700, Batch Loss:     1.334252, Batch Acc: 0.577054, Tokens per Sec:     4742, Lr: 0.000300
2025-05-27 21:50:26,726 - INFO - joeynmt.training - Epoch  10, Step:    25800, Batch Loss:     1.315962, Batch Acc: 0.577725, Tokens per Sec:     4806, Lr: 0.000300
2025-05-27 21:50:40,901 - INFO - joeynmt.training - Epoch  10, Step:    25900, Batch Loss:     1.435112, Batch Acc: 0.574684, Tokens per Sec:     4901, Lr: 0.000300
2025-05-27 21:50:54,881 - INFO - joeynmt.training - Epoch  10, Step:    26000, Batch Loss:     1.425241, Batch Acc: 0.580387, Tokens per Sec:     4899, Lr: 0.000300
2025-05-27 21:50:54,882 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:50:54,882 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:51:13,925 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.47, generation: 19.0393[sec], evaluation: 0.0000[sec]
2025-05-27 21:51:13,927 - INFO - joeynmt.training - Example #0
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'der', 'Größe', 'der', '<unk>', 'der', 'Vereinigten', 'Staaten', '<unk>', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> der Größe der <unk> der Vereinigten Staaten <unk> , 40 Prozent <unk> .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - Example #1
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'Problem', ',', 'dass', 'das', '<unk>', 'Problem', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> Problem , dass das <unk> Problem nicht die <unk> des <unk> <unk> .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - Example #2
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:51:13,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinne', ',', 'dass', 'wir', 'uns', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinne , dass wir uns <unk> <unk> <unk> .
2025-05-27 21:51:13,927 - INFO - joeynmt.training - Example #3
2025-05-27 21:51:13,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:51:13,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:51:13,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'in', 'den', 'Sommer', '<unk>', '.', '</s>']
2025-05-27 21:51:13,928 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:51:13,928 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:51:13,928 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> in den Sommer <unk> .
2025-05-27 21:51:13,928 - INFO - joeynmt.training - Example #4
2025-05-27 21:51:13,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:51:13,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:51:13,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:51:13,928 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:51:13,928 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:51:13,928 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeige , ist eine <unk> Version von dem letzten 25 Jahren passiert ist .
2025-05-27 21:51:27,928 - INFO - joeynmt.training - Epoch  10, Step:    26100, Batch Loss:     1.358384, Batch Acc: 0.577987, Tokens per Sec:     5051, Lr: 0.000210
2025-05-27 21:51:42,276 - INFO - joeynmt.training - Epoch  10, Step:    26200, Batch Loss:     1.274606, Batch Acc: 0.582263, Tokens per Sec:     4728, Lr: 0.000210
2025-05-27 21:51:56,363 - INFO - joeynmt.training - Epoch  10, Step:    26300, Batch Loss:     1.373843, Batch Acc: 0.576921, Tokens per Sec:     4831, Lr: 0.000210
2025-05-27 21:52:10,436 - INFO - joeynmt.training - Epoch  10, Step:    26400, Batch Loss:     1.318066, Batch Acc: 0.584585, Tokens per Sec:     4962, Lr: 0.000210
2025-05-27 21:52:24,259 - INFO - joeynmt.training - Epoch  10, Step:    26500, Batch Loss:     1.280023, Batch Acc: 0.584202, Tokens per Sec:     5026, Lr: 0.000210
2025-05-27 21:52:24,259 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:52:24,259 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:52:46,323 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.48, generation: 22.0596[sec], evaluation: 0.0000[sec]
2025-05-27 21:52:46,411 - INFO - joeynmt.helpers - delete models/word_level_model/16000.ckpt
2025-05-27 21:52:46,416 - INFO - joeynmt.training - Example #0
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'zwei', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'der', 'Größe', 'der', '<unk>', 'der', 'USA', ',', '40', 'Prozent', '<unk>', '.', '</s>']
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese zwei <unk> , um zu zeigen , dass die <unk> , die die letzten drei Millionen Jahre <unk> der Größe der <unk> der USA , 40 Prozent <unk> .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - Example #1
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', 'ist', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'denn', 'es', 'geht', 'nicht', 'die', '<unk>', 'des', '<unk>', '.', '</s>']
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> ist der <unk> dieses <unk> Problem , denn es geht nicht die <unk> des <unk> .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - Example #2
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Sinn', ',', 'dass', 'wir', 'die', '<unk>', 'unseres', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Sinn , dass wir die <unk> unseres <unk> <unk> <unk> .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - Example #3
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:52:46,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', 'im', '<unk>', '.', '</s>']
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:52:46,416 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> im <unk> .
2025-05-27 21:52:46,417 - INFO - joeynmt.training - Example #4
2025-05-27 21:52:46,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:52:46,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:52:46,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:52:46,417 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:52:46,417 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:52:46,417 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:53:00,275 - INFO - joeynmt.training - Epoch  10, Step:    26600, Batch Loss:     1.269103, Batch Acc: 0.579297, Tokens per Sec:     4829, Lr: 0.000210
2025-05-27 21:53:14,368 - INFO - joeynmt.training - Epoch  10, Step:    26700, Batch Loss:     1.319947, Batch Acc: 0.584435, Tokens per Sec:     4793, Lr: 0.000210
2025-05-27 21:53:27,877 - INFO - joeynmt.training - Epoch  10, Step:    26800, Batch Loss:     1.243501, Batch Acc: 0.582078, Tokens per Sec:     5195, Lr: 0.000210
2025-05-27 21:53:42,002 - INFO - joeynmt.training - Epoch  10, Step:    26900, Batch Loss:     1.275631, Batch Acc: 0.583920, Tokens per Sec:     4856, Lr: 0.000210
2025-05-27 21:53:56,053 - INFO - joeynmt.training - Epoch  10, Step:    27000, Batch Loss:     1.180650, Batch Acc: 0.582157, Tokens per Sec:     4969, Lr: 0.000210
2025-05-27 21:53:56,053 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:53:56,053 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:54:19,108 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.60, acc:   0.48, generation: 23.0503[sec], evaluation: 0.0000[sec]
2025-05-27 21:54:19,108 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 21:54:19,201 - INFO - joeynmt.helpers - delete models/word_level_model/26500.ckpt
2025-05-27 21:54:19,202 - INFO - joeynmt.training - Example #0
2025-05-27 21:54:19,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;s', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-27 21:54:19,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-27 21:54:19,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'zeigte', 'ich', 'diese', 'beiden', '<unk>', ',', 'um', 'zu', 'zeigen', ',', 'dass', 'die', '<unk>', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', ',', 'die', 'die', 'Größe', 'der', 'Vereinigten', 'Staaten', ',', '40', 'Prozent', '<unk>', 'hatte', '.', '</s>']
2025-05-27 21:54:19,202 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia &apos;s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-27 21:54:19,202 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-27 21:54:19,202 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr zeigte ich diese beiden <unk> , um zu zeigen , dass die <unk> , die letzten drei Millionen Jahre , die die Größe der Vereinigten Staaten , 40 Prozent <unk> hatte .
2025-05-27 21:54:19,202 - INFO - joeynmt.training - Example #1
2025-05-27 21:54:19,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-27 21:54:19,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-27 21:54:19,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', 'ist', 'eigentlich', 'der', '<unk>', 'dieses', '<unk>', 'Problem', ',', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'zeigt', '.', '</s>']
2025-05-27 21:54:19,202 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> ist eigentlich der <unk> dieses <unk> Problem , weil es nicht die <unk> des <unk> zeigt .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - Example #2
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', ',', 'die', '<unk>', 'in', '<unk>', 'Weise', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '.', '</s>']
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise , die <unk> in <unk> Weise das <unk> Herz unserer <unk> .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - Example #3
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', 'Sommer', 'und', '<unk>', '<unk>', '.', '</s>']
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den Sommer und <unk> <unk> .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - Example #4
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 21:54:19,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', ',', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.', '</s>']
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Reference:  Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-27 21:54:19,203 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie , die ich Ihnen zeige , ist eine <unk> Version von dem , was in den letzten 25 Jahren passiert ist .
2025-05-27 21:54:33,077 - INFO - joeynmt.training - Epoch  10, Step:    27100, Batch Loss:     1.358493, Batch Acc: 0.583675, Tokens per Sec:     4855, Lr: 0.000210
2025-05-27 21:54:47,135 - INFO - joeynmt.training - Epoch  10, Step:    27200, Batch Loss:     1.323018, Batch Acc: 0.576265, Tokens per Sec:     4898, Lr: 0.000210
2025-05-27 21:55:01,292 - INFO - joeynmt.training - Epoch  10, Step:    27300, Batch Loss:     1.268424, Batch Acc: 0.578988, Tokens per Sec:     5018, Lr: 0.000210
2025-05-27 21:55:02,869 - INFO - joeynmt.training - Epoch  10: total training loss 3633.48
2025-05-27 21:55:02,869 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-27 21:55:02,869 - INFO - joeynmt.training - Best validation result (greedy) at step    27000:   5.60 ppl.
2025-05-27 21:55:02,879 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 21:55:02,914 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 21:55:02,949 - INFO - joeynmt.helpers - Load model from /Users/merilinsilva/Documents/SemestersUZH/4thSem/MT/exercises/msousa_spareek_mt_exercise_04/mt-exercise-4/models/word_level_model/27000.ckpt.
2025-05-27 21:55:02,951 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2025-05-27 21:55:02,951 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-27 21:55:02,951 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:55:02,951 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:55:22,386 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 19.4312[sec], evaluation: 0.0000[sec]
2025-05-27 21:55:22,389 - INFO - joeynmt.prediction - Translations saved to: /Users/merilinsilva/Documents/SemestersUZH/4thSem/MT/exercises/msousa_spareek_mt_exercise_04/mt-exercise-4/models/word_level_model/00027000.hyps.dev.
2025-05-27 21:55:22,389 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-27 21:55:22,389 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 21:55:22,389 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 21:55:53,504 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 31.1092[sec], evaluation: 0.0000[sec]
2025-05-27 21:55:53,506 - INFO - joeynmt.prediction - Translations saved to: /Users/merilinsilva/Documents/SemestersUZH/4thSem/MT/exercises/msousa_spareek_mt_exercise_04/mt-exercise-4/models/word_level_model/00027000.hyps.test.
